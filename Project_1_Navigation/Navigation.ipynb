{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# please do not modify the line below\n",
    "env = UnityEnvironment(file_name=\"/data/Banana_Linux_NoVis/Banana.x86_64\")\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "\n",
    "#from unityagents import UnityEnvironment\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = UnityEnvironment(file_name=\"./data/Banana_Linux_NoVis/Banana.x86_64\")\n",
    "#env = UnityEnvironment(file_name=\"Banana_Linux/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [ 1.          0.          0.          0.          0.84408134  0.          0.\n",
      "  1.          0.          0.0748472   0.          1.          0.          0.\n",
      "  0.25755     1.          0.          0.          0.          0.74177343\n",
      "  0.          1.          0.          0.          0.25854847  0.          0.\n",
      "  1.          0.          0.09355672  0.          1.          0.          0.\n",
      "  0.31969345  0.          0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nenv_info = env.reset(train_mode=False)[brain_name] # reset the environment\\nstate = env_info.vector_observations[0]            # get the current state\\nscore = 0                                          # initialize the score\\nwhile True:\\n    action = np.random.randint(action_size)        # select an action\\n    env_info = env.step(action)[brain_name]        # send the action to the environment\\n    next_state = env_info.vector_observations[0]   # get the next state\\n    reward = env_info.rewards[0]                   # get the reward\\n    done = env_info.local_done[0]                  # see if episode has finished\\n    score += reward                                # update the score\\n    state = next_state                             # roll over the state to next time step\\n    if done:                                       # exit loop if episode finished\\n        break\\n    \\nprint(\"Score: {}\".format(score))\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install -U git+https://github.com/szagoruyko/pytorchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/szagoruyko/pytorchviz\n",
      "  Cloning https://github.com/szagoruyko/pytorchviz to /tmp/pip-req-build-_h72d_7f\n",
      "Requirement already satisfied, skipping upgrade: torch in /opt/conda/lib/python3.6/site-packages (from torchviz==0.0.1) (0.4.0)\n",
      "Collecting graphviz (from torchviz==0.0.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/94/cd/7b37f2b658995033879719e1ea4c9f171bf7a14c16b79220bd19f9eda3fe/graphviz-0.13-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: torchviz\n",
      "  Running setup.py bdist_wheel for torchviz ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-ol3xdvps/wheels/b9/b9/85/ef34936f58754cb23840fd869be1367b5d525e29915a2a4fe9\n",
      "Successfully built torchviz\n",
      "Installing collected packages: graphviz, torchviz\n",
      "Successfully installed graphviz-0.13 torchviz-0.0.1\n",
      "Collecting torchsummary\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/18/1474d06f721b86e6a9b9d7392ad68bed711a02f3b61ac43f13c719db50a6/torchsummary-1.5.1-py3-none-any.whl\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U git+https://github.com/szagoruyko/pytorchviz\n",
    "!{sys.executable} -m pip install -U torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "---------------------------------------------------------------------\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks\n",
    "\n",
    "In this project, we'll make use of 2 neural networks\n",
    "- A simple feed forward neural network (2 hidden layers)\n",
    "- A dualing feed forward neural network (4 hidden layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 64]           2,112\n",
      "            Linear-2                [-1, 1, 32]           2,080\n",
      "            Linear-3                [-1, 1, 37]           1,221\n",
      "================================================================\n",
      "Total params: 5,413\n",
      "Trainable params: 5,413\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"363pt\" height=\"413pt\"\n",
       " viewBox=\"0.00 0.00 363.00 413.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 409)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-409 359,-409 359,4 -4,4\"/>\n",
       "<!-- 140610470344408 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140610470344408</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"259,-21 134,-21 134,0 259,0 259,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140610470344464 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140610470344464</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"125,-78 0,-78 0,-57 125,-57 125,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140610470344464&#45;&gt;140610470344408 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140610470344464&#45;&gt;140610470344408</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M87.3903,-56.9123C108.5443,-47.914 139.1165,-34.9094 162.5208,-24.9539\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"163.9109,-28.1661 171.743,-21.031 161.1709,-21.7246 163.9109,-28.1661\"/>\n",
       "</g>\n",
       "<!-- 140610470344632 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140610470344632</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"89.5,-149 35.5,-149 35.5,-114 89.5,-114 89.5,-149\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (37)</text>\n",
       "</g>\n",
       "<!-- 140610470344632&#45;&gt;140610470344464 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140610470344632&#45;&gt;140610470344464</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M62.5,-113.6724C62.5,-105.8405 62.5,-96.5893 62.5,-88.4323\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"66.0001,-88.2234 62.5,-78.2234 59.0001,-88.2235 66.0001,-88.2234\"/>\n",
       "</g>\n",
       "<!-- 140610470343624 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140610470343624</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"249.5,-78 143.5,-78 143.5,-57 249.5,-57 249.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward</text>\n",
       "</g>\n",
       "<!-- 140610470343624&#45;&gt;140610470344408 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140610470343624&#45;&gt;140610470344408</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M196.5,-56.7787C196.5,-49.6134 196.5,-39.9517 196.5,-31.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"200.0001,-31.1732 196.5,-21.1732 193.0001,-31.1732 200.0001,-31.1732\"/>\n",
       "</g>\n",
       "<!-- 140610470344688 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140610470344688</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"259,-142 134,-142 134,-121 259,-121 259,-142\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.5\" y=\"-128.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140610470344688&#45;&gt;140610470343624 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140610470344688&#45;&gt;140610470343624</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M196.5,-120.9317C196.5,-112.0913 196.5,-99.2122 196.5,-88.3135\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"200.0001,-88.2979 196.5,-78.2979 193.0001,-88.2979 200.0001,-88.2979\"/>\n",
       "</g>\n",
       "<!-- 140610470344744 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140610470344744</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"125,-206 0,-206 0,-185 125,-185 125,-206\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-192.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140610470344744&#45;&gt;140610470344688 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140610470344744&#45;&gt;140610470344688</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M84.6274,-184.9317C106.5459,-174.4632 140.3222,-158.3312 165.0291,-146.5309\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"166.8246,-149.5521 174.3398,-142.084 163.8077,-143.2356 166.8246,-149.5521\"/>\n",
       "</g>\n",
       "<!-- 140610470345024 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140610470345024</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"89.5,-277 35.5,-277 35.5,-242 89.5,-242 89.5,-277\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-249.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32)</text>\n",
       "</g>\n",
       "<!-- 140610470345024&#45;&gt;140610470344744 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140610470345024&#45;&gt;140610470344744</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M62.5,-241.6724C62.5,-233.8405 62.5,-224.5893 62.5,-216.4323\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"66.0001,-216.2234 62.5,-206.2234 59.0001,-216.2235 66.0001,-216.2234\"/>\n",
       "</g>\n",
       "<!-- 140610470344856 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140610470344856</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"249.5,-206 143.5,-206 143.5,-185 249.5,-185 249.5,-206\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.5\" y=\"-192.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward</text>\n",
       "</g>\n",
       "<!-- 140610470344856&#45;&gt;140610470344688 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140610470344856&#45;&gt;140610470344688</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M196.5,-184.9317C196.5,-176.0913 196.5,-163.2122 196.5,-152.3135\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"200.0001,-152.2979 196.5,-142.2979 193.0001,-152.2979 200.0001,-152.2979\"/>\n",
       "</g>\n",
       "<!-- 140610470345080 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140610470345080</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"259,-270 134,-270 134,-249 259,-249 259,-270\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.5\" y=\"-256.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140610470345080&#45;&gt;140610470344856 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140610470345080&#45;&gt;140610470344856</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M196.5,-248.9317C196.5,-240.0913 196.5,-227.2122 196.5,-216.3135\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"200.0001,-216.2979 196.5,-206.2979 193.0001,-216.2979 200.0001,-216.2979\"/>\n",
       "</g>\n",
       "<!-- 140610470345136 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140610470345136</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"197,-334 72,-334 72,-313 197,-313 197,-334\"/>\n",
       "<text text-anchor=\"middle\" x=\"134.5\" y=\"-320.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140610470345136&#45;&gt;140610470345080 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140610470345136&#45;&gt;140610470345080</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M144.738,-312.9317C154.0158,-303.3546 167.8854,-289.0376 178.9331,-277.6336\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"181.5954,-279.9156 186.0395,-270.2979 176.5677,-275.045 181.5954,-279.9156\"/>\n",
       "</g>\n",
       "<!-- 140610470345360 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140610470345360</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"161.5,-405 107.5,-405 107.5,-370 161.5,-370 161.5,-405\"/>\n",
       "<text text-anchor=\"middle\" x=\"134.5\" y=\"-377.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64)</text>\n",
       "</g>\n",
       "<!-- 140610470345360&#45;&gt;140610470345136 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140610470345360&#45;&gt;140610470345136</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134.5,-369.6724C134.5,-361.8405 134.5,-352.5893 134.5,-344.4323\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"138.0001,-344.2234 134.5,-334.2234 131.0001,-344.2235 138.0001,-344.2234\"/>\n",
       "</g>\n",
       "<!-- 140610470345248 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140610470345248</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"302,-334 215,-334 215,-313 302,-313 302,-334\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.5\" y=\"-320.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140610470345248&#45;&gt;140610470345080 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140610470345248&#45;&gt;140610470345080</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M248.262,-312.9317C238.9842,-303.3546 225.1146,-289.0376 214.0669,-277.6336\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"216.4323,-275.045 206.9605,-270.2979 211.4046,-279.9156 216.4323,-275.045\"/>\n",
       "</g>\n",
       "<!-- 140610470345416 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140610470345416</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"292,-405 225,-405 225,-370 292,-370 292,-405\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.5\" y=\"-377.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64, 32)</text>\n",
       "</g>\n",
       "<!-- 140610470345416&#45;&gt;140610470345248 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140610470345416&#45;&gt;140610470345248</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M258.5,-369.6724C258.5,-361.8405 258.5,-352.5893 258.5,-344.4323\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"262.0001,-344.2234 258.5,-334.2234 255.0001,-344.2235 262.0001,-344.2234\"/>\n",
       "</g>\n",
       "<!-- 140610470344912 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140610470344912</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"355,-206 268,-206 268,-185 355,-185 355,-206\"/>\n",
       "<text text-anchor=\"middle\" x=\"311.5\" y=\"-192.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140610470344912&#45;&gt;140610470344688 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140610470344912&#45;&gt;140610470344688</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M292.5101,-184.9317C273.9491,-174.6021 245.4801,-158.7585 224.3571,-147.0031\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"225.9581,-143.8886 215.5181,-142.084 222.5541,-150.0052 225.9581,-143.8886\"/>\n",
       "</g>\n",
       "<!-- 140610470345192 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>140610470345192</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"345,-277 278,-277 278,-242 345,-242 345,-277\"/>\n",
       "<text text-anchor=\"middle\" x=\"311.5\" y=\"-249.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 64)</text>\n",
       "</g>\n",
       "<!-- 140610470345192&#45;&gt;140610470344912 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>140610470345192&#45;&gt;140610470344912</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M311.5,-241.6724C311.5,-233.8405 311.5,-224.5893 311.5,-216.4323\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"315.0001,-216.2234 311.5,-206.2234 308.0001,-216.2235 315.0001,-216.2234\"/>\n",
       "</g>\n",
       "<!-- 140610470344520 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>140610470344520</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"355,-78 268,-78 268,-57 355,-57 355,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"311.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140610470344520&#45;&gt;140610470344408 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>140610470344520&#45;&gt;140610470344408</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M290.1389,-56.9123C272.3071,-48.074 246.6774,-35.3705 226.7383,-25.4877\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"228.2609,-22.336 217.7467,-21.031 225.1522,-28.6079 228.2609,-22.336\"/>\n",
       "</g>\n",
       "<!-- 140610470344800 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>140610470344800</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"345,-149 278,-149 278,-114 345,-114 345,-149\"/>\n",
       "<text text-anchor=\"middle\" x=\"311.5\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (37, 32)</text>\n",
       "</g>\n",
       "<!-- 140610470344800&#45;&gt;140610470344520 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>140610470344800&#45;&gt;140610470344520</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M311.5,-113.6724C311.5,-105.8405 311.5,-96.5893 311.5,-88.4323\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"315.0001,-88.2234 311.5,-78.2234 308.0001,-88.2235 315.0001,-88.2234\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe26d22f0f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.qNetwork import QNetwork\n",
    "QNetwork(state_size, action_size,0).show_model_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 64]           2,432\n",
      "            Linear-2               [-1, 1, 128]           8,320\n",
      "            Linear-3                [-1, 1, 64]           8,256\n",
      "            Linear-4                [-1, 1, 32]           2,080\n",
      "            Linear-5                 [-1, 1, 1]              33\n",
      "            Linear-6                 [-1, 1, 4]             132\n",
      "================================================================\n",
      "Total params: 21,253\n",
      "Trainable params: 21,253\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.08\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"582pt\" height=\"896pt\"\n",
       " viewBox=\"0.00 0.00 582.31 896.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.939203 0.939203) rotate(0) translate(4 950)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-950 616,-950 616,4 -4,4\"/>\n",
       "<!-- 140637751654832 -->\n",
       "<g id=\"node1\" class=\"node\"><title>140637751654832</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"432.5,-21 319.5,-21 319.5,-0 432.5,-0 432.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"376\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddBackward1</text>\n",
       "</g>\n",
       "<!-- 140637751654888 -->\n",
       "<g id=\"node2\" class=\"node\"><title>140637751654888</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"486,-192 358,-192 358,-171 486,-171 486,-192\"/>\n",
       "<text text-anchor=\"middle\" x=\"422\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140637751654888&#45;&gt;140637751654832 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>140637751654888&#45;&gt;140637751654832</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M421.76,-170.903C420.966,-149.724 417.563,-97.6389 403,-57 399.57,-47.4289 394.059,-37.6283 388.907,-29.586\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"391.661,-27.4095 383.171,-21.0717 385.855,-31.3207 391.661,-27.4095\"/>\n",
       "</g>\n",
       "<!-- 140637751655056 -->\n",
       "<g id=\"node3\" class=\"node\"><title>140637751655056</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"486,-306 358,-306 358,-285 486,-285 486,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"422\" y=\"-292.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140637751655056&#45;&gt;140637751654888 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>140637751655056&#45;&gt;140637751654888</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M422,-284.951C422,-266.684 422,-226.455 422,-202.198\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"425.5,-202.025 422,-192.025 418.5,-202.025 425.5,-202.025\"/>\n",
       "</g>\n",
       "<!-- 140637751655336 -->\n",
       "<g id=\"node4\" class=\"node\"><title>140637751655336</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"612,-363 484,-363 484,-342 612,-342 612,-363\"/>\n",
       "<text text-anchor=\"middle\" x=\"548\" y=\"-349.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140637751655336&#45;&gt;140637751655056 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>140637751655336&#45;&gt;140637751655056</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M526.052,-341.92C505.94,-333.141 475.941,-320.046 453.314,-310.169\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"454.684,-306.948 444.119,-306.155 451.883,-313.363 454.684,-306.948\"/>\n",
       "</g>\n",
       "<!-- 140637751655504 -->\n",
       "<g id=\"node5\" class=\"node\"><title>140637751655504</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"575,-434 521,-434 521,-399 575,-399 575,-434\"/>\n",
       "<text text-anchor=\"middle\" x=\"548\" y=\"-406.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140637751655504&#45;&gt;140637751655336 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>140637751655504&#45;&gt;140637751655336</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M548,-398.885C548,-390.994 548,-381.505 548,-373.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"551.5,-373.018 548,-363.018 544.5,-373.018 551.5,-373.018\"/>\n",
       "</g>\n",
       "<!-- 140637751655112 -->\n",
       "<g id=\"node6\" class=\"node\"><title>140637751655112</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"360,-363 252,-363 252,-342 360,-342 360,-363\"/>\n",
       "<text text-anchor=\"middle\" x=\"306\" y=\"-349.4\" font-family=\"Times,serif\" font-size=\"12.00\">ReluBackward</text>\n",
       "</g>\n",
       "<!-- 140637751655112&#45;&gt;140637751655056 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>140637751655112&#45;&gt;140637751655056</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M326.206,-341.92C344.474,-333.258 371.602,-320.396 392.33,-310.567\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"394.1,-313.602 401.637,-306.155 391.101,-307.277 394.1,-313.602\"/>\n",
       "</g>\n",
       "<!-- 140637751722224 -->\n",
       "<g id=\"node35\" class=\"node\"><title>140637751722224</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"254,-306 126,-306 126,-285 254,-285 254,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"190\" y=\"-292.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140637751655112&#45;&gt;140637751722224 -->\n",
       "<g id=\"edge37\" class=\"edge\"><title>140637751655112&#45;&gt;140637751722224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M285.794,-341.92C267.526,-333.258 240.398,-320.396 219.67,-310.567\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"220.899,-307.277 210.363,-306.155 217.9,-313.602 220.899,-307.277\"/>\n",
       "</g>\n",
       "<!-- 140637751655560 -->\n",
       "<g id=\"node7\" class=\"node\"><title>140637751655560</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"370,-427 242,-427 242,-406 370,-406 370,-427\"/>\n",
       "<text text-anchor=\"middle\" x=\"306\" y=\"-413.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140637751655560&#45;&gt;140637751655112 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>140637751655560&#45;&gt;140637751655112</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M306,-405.812C306,-397.218 306,-384.388 306,-373.585\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"309.5,-373.324 306,-363.324 302.5,-373.324 309.5,-373.324\"/>\n",
       "</g>\n",
       "<!-- 140637751655616 -->\n",
       "<g id=\"node8\" class=\"node\"><title>140637751655616</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"234,-491 106,-491 106,-470 234,-470 234,-491\"/>\n",
       "<text text-anchor=\"middle\" x=\"170\" y=\"-477.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140637751655616&#45;&gt;140637751655560 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>140637751655616&#45;&gt;140637751655560</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M190.952,-469.948C213.548,-459.647 249.738,-443.149 275.491,-431.409\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"277.153,-434.497 284.8,-427.165 274.249,-428.128 277.153,-434.497\"/>\n",
       "</g>\n",
       "<!-- 140637751655896 -->\n",
       "<g id=\"node9\" class=\"node\"><title>140637751655896</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"197,-562 143,-562 143,-527 197,-527 197,-562\"/>\n",
       "<text text-anchor=\"middle\" x=\"170\" y=\"-534.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (32)</text>\n",
       "</g>\n",
       "<!-- 140637751655896&#45;&gt;140637751655616 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>140637751655896&#45;&gt;140637751655616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M170,-526.885C170,-518.994 170,-509.505 170,-501.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"173.5,-501.018 170,-491.018 166.5,-501.018 173.5,-501.018\"/>\n",
       "</g>\n",
       "<!-- 140637751655728 -->\n",
       "<g id=\"node10\" class=\"node\"><title>140637751655728</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"360,-491 252,-491 252,-470 360,-470 360,-491\"/>\n",
       "<text text-anchor=\"middle\" x=\"306\" y=\"-477.4\" font-family=\"Times,serif\" font-size=\"12.00\">ReluBackward</text>\n",
       "</g>\n",
       "<!-- 140637751655728&#45;&gt;140637751655560 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>140637751655728&#45;&gt;140637751655560</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M306,-469.812C306,-461.218 306,-448.388 306,-437.585\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"309.5,-437.324 306,-427.324 302.5,-437.324 309.5,-437.324\"/>\n",
       "</g>\n",
       "<!-- 140637751655952 -->\n",
       "<g id=\"node11\" class=\"node\"><title>140637751655952</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"370,-555 242,-555 242,-534 370,-534 370,-555\"/>\n",
       "<text text-anchor=\"middle\" x=\"306\" y=\"-541.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140637751655952&#45;&gt;140637751655728 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>140637751655952&#45;&gt;140637751655728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M306,-533.812C306,-525.218 306,-512.388 306,-501.585\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"309.5,-501.324 306,-491.324 302.5,-501.324 309.5,-501.324\"/>\n",
       "</g>\n",
       "<!-- 140637751656008 -->\n",
       "<g id=\"node12\" class=\"node\"><title>140637751656008</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"234,-619 106,-619 106,-598 234,-598 234,-619\"/>\n",
       "<text text-anchor=\"middle\" x=\"170\" y=\"-605.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140637751656008&#45;&gt;140637751655952 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>140637751656008&#45;&gt;140637751655952</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M190.952,-597.948C213.548,-587.647 249.738,-571.149 275.491,-559.409\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"277.153,-562.497 284.8,-555.165 274.249,-556.128 277.153,-562.497\"/>\n",
       "</g>\n",
       "<!-- 140637751656288 -->\n",
       "<g id=\"node13\" class=\"node\"><title>140637751656288</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"197,-690 143,-690 143,-655 197,-655 197,-690\"/>\n",
       "<text text-anchor=\"middle\" x=\"170\" y=\"-662.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (64)</text>\n",
       "</g>\n",
       "<!-- 140637751656288&#45;&gt;140637751656008 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>140637751656288&#45;&gt;140637751656008</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M170,-654.885C170,-646.994 170,-637.505 170,-629.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"173.5,-629.018 170,-619.018 166.5,-629.018 173.5,-629.018\"/>\n",
       "</g>\n",
       "<!-- 140637751656120 -->\n",
       "<g id=\"node14\" class=\"node\"><title>140637751656120</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"360,-619 252,-619 252,-598 360,-598 360,-619\"/>\n",
       "<text text-anchor=\"middle\" x=\"306\" y=\"-605.4\" font-family=\"Times,serif\" font-size=\"12.00\">ReluBackward</text>\n",
       "</g>\n",
       "<!-- 140637751656120&#45;&gt;140637751655952 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>140637751656120&#45;&gt;140637751655952</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M306,-597.812C306,-589.218 306,-576.388 306,-565.585\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"309.5,-565.324 306,-555.324 302.5,-565.324 309.5,-565.324\"/>\n",
       "</g>\n",
       "<!-- 140637751656344 -->\n",
       "<g id=\"node15\" class=\"node\"><title>140637751656344</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"369,-683 241,-683 241,-662 369,-662 369,-683\"/>\n",
       "<text text-anchor=\"middle\" x=\"305\" y=\"-669.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140637751656344&#45;&gt;140637751656120 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>140637751656344&#45;&gt;140637751656120</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M305.156,-661.812C305.295,-653.218 305.502,-640.388 305.676,-629.585\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"309.18,-629.379 305.842,-619.324 302.181,-629.266 309.18,-629.379\"/>\n",
       "</g>\n",
       "<!-- 140637751722056 -->\n",
       "<g id=\"node16\" class=\"node\"><title>140637751722056</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"233,-747 105,-747 105,-726 233,-726 233,-747\"/>\n",
       "<text text-anchor=\"middle\" x=\"169\" y=\"-733.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140637751722056&#45;&gt;140637751656344 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>140637751722056&#45;&gt;140637751656344</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M189.952,-725.948C212.548,-715.647 248.738,-699.149 274.491,-687.409\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"276.153,-690.497 283.8,-683.165 273.249,-684.128 276.153,-690.497\"/>\n",
       "</g>\n",
       "<!-- 140637751722280 -->\n",
       "<g id=\"node17\" class=\"node\"><title>140637751722280</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"196,-818 142,-818 142,-783 196,-783 196,-818\"/>\n",
       "<text text-anchor=\"middle\" x=\"169\" y=\"-790.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (128)</text>\n",
       "</g>\n",
       "<!-- 140637751722280&#45;&gt;140637751722056 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>140637751722280&#45;&gt;140637751722056</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169,-782.885C169,-774.994 169,-765.505 169,-757.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"172.5,-757.018 169,-747.018 165.5,-757.018 172.5,-757.018\"/>\n",
       "</g>\n",
       "<!-- 140637751722112 -->\n",
       "<g id=\"node18\" class=\"node\"><title>140637751722112</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"359,-747 251,-747 251,-726 359,-726 359,-747\"/>\n",
       "<text text-anchor=\"middle\" x=\"305\" y=\"-733.4\" font-family=\"Times,serif\" font-size=\"12.00\">ReluBackward</text>\n",
       "</g>\n",
       "<!-- 140637751722112&#45;&gt;140637751656344 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>140637751722112&#45;&gt;140637751656344</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M305,-725.812C305,-717.218 305,-704.388 305,-693.585\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.5,-693.324 305,-683.324 301.5,-693.324 308.5,-693.324\"/>\n",
       "</g>\n",
       "<!-- 140637751722336 -->\n",
       "<g id=\"node19\" class=\"node\"><title>140637751722336</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"368,-811 240,-811 240,-790 368,-790 368,-811\"/>\n",
       "<text text-anchor=\"middle\" x=\"304\" y=\"-797.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140637751722336&#45;&gt;140637751722112 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>140637751722336&#45;&gt;140637751722112</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M304.156,-789.812C304.295,-781.218 304.502,-768.388 304.676,-757.585\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.18,-757.379 304.842,-747.324 301.181,-757.266 308.18,-757.379\"/>\n",
       "</g>\n",
       "<!-- 140637751722392 -->\n",
       "<g id=\"node20\" class=\"node\"><title>140637751722392</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"305,-875 177,-875 177,-854 305,-854 305,-875\"/>\n",
       "<text text-anchor=\"middle\" x=\"241\" y=\"-861.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140637751722392&#45;&gt;140637751722336 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>140637751722392&#45;&gt;140637751722336</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M250.844,-853.812C260.404,-844.404 275.122,-829.919 286.65,-818.575\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"289.345,-820.833 294.017,-811.324 284.435,-815.844 289.345,-820.833\"/>\n",
       "</g>\n",
       "<!-- 140637751722616 -->\n",
       "<g id=\"node21\" class=\"node\"><title>140637751722616</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"268,-946 214,-946 214,-911 268,-911 268,-946\"/>\n",
       "<text text-anchor=\"middle\" x=\"241\" y=\"-918.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (64)</text>\n",
       "</g>\n",
       "<!-- 140637751722616&#45;&gt;140637751722392 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>140637751722616&#45;&gt;140637751722392</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M241,-910.885C241,-902.994 241,-893.505 241,-885.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"244.5,-885.018 241,-875.018 237.5,-885.018 244.5,-885.018\"/>\n",
       "</g>\n",
       "<!-- 140637751722504 -->\n",
       "<g id=\"node22\" class=\"node\"><title>140637751722504</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"411,-875 323,-875 323,-854 411,-854 411,-875\"/>\n",
       "<text text-anchor=\"middle\" x=\"367\" y=\"-861.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140637751722504&#45;&gt;140637751722336 -->\n",
       "<g id=\"edge21\" class=\"edge\"><title>140637751722504&#45;&gt;140637751722336</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M357.156,-853.812C347.596,-844.404 332.878,-829.919 321.35,-818.575\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"323.565,-815.844 313.983,-811.324 318.655,-820.833 323.565,-815.844\"/>\n",
       "</g>\n",
       "<!-- 140637751722672 -->\n",
       "<g id=\"node23\" class=\"node\"><title>140637751722672</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"400.5,-946 333.5,-946 333.5,-911 400.5,-911 400.5,-946\"/>\n",
       "<text text-anchor=\"middle\" x=\"367\" y=\"-918.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (64, 37)</text>\n",
       "</g>\n",
       "<!-- 140637751722672&#45;&gt;140637751722504 -->\n",
       "<g id=\"edge22\" class=\"edge\"><title>140637751722672&#45;&gt;140637751722504</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M367,-910.885C367,-902.994 367,-893.505 367,-885.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"370.5,-885.018 367,-875.018 363.5,-885.018 370.5,-885.018\"/>\n",
       "</g>\n",
       "<!-- 140637751722168 -->\n",
       "<g id=\"node24\" class=\"node\"><title>140637751722168</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"466,-747 378,-747 378,-726 466,-726 466,-747\"/>\n",
       "<text text-anchor=\"middle\" x=\"422\" y=\"-733.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140637751722168&#45;&gt;140637751656344 -->\n",
       "<g id=\"edge23\" class=\"edge\"><title>140637751722168&#45;&gt;140637751656344</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M403.975,-725.948C384.793,-715.784 354.223,-699.584 332.13,-687.876\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"333.713,-684.754 323.238,-683.165 330.435,-690.94 333.713,-684.754\"/>\n",
       "</g>\n",
       "<!-- 140637751722448 -->\n",
       "<g id=\"node25\" class=\"node\"><title>140637751722448</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"460,-818 386,-818 386,-783 460,-783 460,-818\"/>\n",
       "<text text-anchor=\"middle\" x=\"423\" y=\"-790.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (128, 64)</text>\n",
       "</g>\n",
       "<!-- 140637751722448&#45;&gt;140637751722168 -->\n",
       "<g id=\"edge24\" class=\"edge\"><title>140637751722448&#45;&gt;140637751722168</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M422.732,-782.885C422.605,-774.994 422.452,-765.505 422.319,-757.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"425.814,-756.96 422.154,-747.018 418.815,-757.073 425.814,-756.96\"/>\n",
       "</g>\n",
       "<!-- 140637751656176 -->\n",
       "<g id=\"node26\" class=\"node\"><title>140637751656176</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"467,-619 379,-619 379,-598 467,-598 467,-619\"/>\n",
       "<text text-anchor=\"middle\" x=\"423\" y=\"-605.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140637751656176&#45;&gt;140637751655952 -->\n",
       "<g id=\"edge25\" class=\"edge\"><title>140637751656176&#45;&gt;140637751655952</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M404.975,-597.948C385.793,-587.784 355.223,-571.584 333.13,-559.876\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"334.713,-556.754 324.238,-555.165 331.435,-562.94 334.713,-556.754\"/>\n",
       "</g>\n",
       "<!-- 140637751656400 -->\n",
       "<g id=\"node27\" class=\"node\"><title>140637751656400</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"461,-690 387,-690 387,-655 461,-655 461,-690\"/>\n",
       "<text text-anchor=\"middle\" x=\"424\" y=\"-662.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (64, 128)</text>\n",
       "</g>\n",
       "<!-- 140637751656400&#45;&gt;140637751656176 -->\n",
       "<g id=\"edge26\" class=\"edge\"><title>140637751656400&#45;&gt;140637751656176</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M423.732,-654.885C423.605,-646.994 423.452,-637.505 423.319,-629.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"426.814,-628.96 423.154,-619.018 419.815,-629.073 426.814,-628.96\"/>\n",
       "</g>\n",
       "<!-- 140637751655784 -->\n",
       "<g id=\"node28\" class=\"node\"><title>140637751655784</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"466,-491 378,-491 378,-470 466,-470 466,-491\"/>\n",
       "<text text-anchor=\"middle\" x=\"422\" y=\"-477.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140637751655784&#45;&gt;140637751655560 -->\n",
       "<g id=\"edge27\" class=\"edge\"><title>140637751655784&#45;&gt;140637751655560</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M404.129,-469.948C385.196,-459.829 355.073,-443.729 333.192,-432.034\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"334.551,-428.792 324.082,-427.165 331.252,-434.965 334.551,-428.792\"/>\n",
       "</g>\n",
       "<!-- 140637751656064 -->\n",
       "<g id=\"node29\" class=\"node\"><title>140637751656064</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"455.5,-562 388.5,-562 388.5,-527 455.5,-527 455.5,-562\"/>\n",
       "<text text-anchor=\"middle\" x=\"422\" y=\"-534.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (32, 64)</text>\n",
       "</g>\n",
       "<!-- 140637751656064&#45;&gt;140637751655784 -->\n",
       "<g id=\"edge28\" class=\"edge\"><title>140637751656064&#45;&gt;140637751655784</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M422,-526.885C422,-518.994 422,-509.505 422,-501.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"425.5,-501.018 422,-491.018 418.5,-501.018 425.5,-501.018\"/>\n",
       "</g>\n",
       "<!-- 140637751655392 -->\n",
       "<g id=\"node30\" class=\"node\"><title>140637751655392</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"466,-363 378,-363 378,-342 466,-342 466,-363\"/>\n",
       "<text text-anchor=\"middle\" x=\"422\" y=\"-349.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140637751655392&#45;&gt;140637751655056 -->\n",
       "<g id=\"edge29\" class=\"edge\"><title>140637751655392&#45;&gt;140637751655056</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M422,-341.92C422,-334.908 422,-325.144 422,-316.465\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"425.5,-316.341 422,-306.341 418.5,-316.341 425.5,-316.341\"/>\n",
       "</g>\n",
       "<!-- 140637751655672 -->\n",
       "<g id=\"node31\" class=\"node\"><title>140637751655672</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"451.5,-434 392.5,-434 392.5,-399 451.5,-399 451.5,-434\"/>\n",
       "<text text-anchor=\"middle\" x=\"422\" y=\"-406.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1, 32)</text>\n",
       "</g>\n",
       "<!-- 140637751655672&#45;&gt;140637751655392 -->\n",
       "<g id=\"edge30\" class=\"edge\"><title>140637751655672&#45;&gt;140637751655392</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M422,-398.885C422,-390.994 422,-381.505 422,-373.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"425.5,-373.018 422,-363.018 418.5,-373.018 425.5,-373.018\"/>\n",
       "</g>\n",
       "<!-- 140637751654944 -->\n",
       "<g id=\"node32\" class=\"node\"><title>140637751654944</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"394,-78 266,-78 266,-57 394,-57 394,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"330\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140637751654944&#45;&gt;140637751654832 -->\n",
       "<g id=\"edge31\" class=\"edge\"><title>140637751654944&#45;&gt;140637751654832</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M338.013,-56.9197C344.398,-49.2851 353.513,-38.3867 361.214,-29.1792\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"364.039,-31.2571 367.769,-21.3408 358.669,-26.7662 364.039,-31.2571\"/>\n",
       "</g>\n",
       "<!-- 140637751654720 -->\n",
       "<g id=\"node33\" class=\"node\"><title>140637751654720</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"385.5,-135 274.5,-135 274.5,-114 385.5,-114 385.5,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"330\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\">SubBackward1</text>\n",
       "</g>\n",
       "<!-- 140637751654720&#45;&gt;140637751654944 -->\n",
       "<g id=\"edge32\" class=\"edge\"><title>140637751654720&#45;&gt;140637751654944</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M330,-113.92C330,-106.908 330,-97.1442 330,-88.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"333.5,-88.3408 330,-78.3408 326.5,-88.3409 333.5,-88.3408\"/>\n",
       "</g>\n",
       "<!-- 140637751655840 -->\n",
       "<g id=\"node34\" class=\"node\"><title>140637751655840</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"394,-249 266,-249 266,-228 394,-228 394,-249\"/>\n",
       "<text text-anchor=\"middle\" x=\"330\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140637751655840&#45;&gt;140637751654720 -->\n",
       "<g id=\"edge33\" class=\"edge\"><title>140637751655840&#45;&gt;140637751654720</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M330,-227.951C330,-209.684 330,-169.455 330,-145.198\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"333.5,-145.025 330,-135.025 326.5,-145.025 333.5,-145.025\"/>\n",
       "</g>\n",
       "<!-- 140637751722224&#45;&gt;140637751655840 -->\n",
       "<g id=\"edge34\" class=\"edge\"><title>140637751722224&#45;&gt;140637751655840</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M214.386,-284.92C236.933,-276.062 270.662,-262.812 295.878,-252.905\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"297.396,-256.069 305.424,-249.155 294.836,-249.554 297.396,-256.069\"/>\n",
       "</g>\n",
       "<!-- 140637751722784 -->\n",
       "<g id=\"node41\" class=\"node\"><title>140637751722784</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"248,-249 126,-249 126,-228 248,-228 248,-249\"/>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\">MeanBackward1</text>\n",
       "</g>\n",
       "<!-- 140637751722224&#45;&gt;140637751722784 -->\n",
       "<g id=\"edge42\" class=\"edge\"><title>140637751722224&#45;&gt;140637751722784</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M189.477,-284.92C189.095,-277.908 188.562,-268.144 188.089,-259.465\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"191.576,-259.135 187.537,-249.341 184.587,-259.517 191.576,-259.135\"/>\n",
       "</g>\n",
       "<!-- 140637751722840 -->\n",
       "<g id=\"node36\" class=\"node\"><title>140637751722840</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"128,-363 0,-363 0,-342 128,-342 128,-363\"/>\n",
       "<text text-anchor=\"middle\" x=\"64\" y=\"-349.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140637751722840&#45;&gt;140637751722224 -->\n",
       "<g id=\"edge35\" class=\"edge\"><title>140637751722840&#45;&gt;140637751722224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M85.9475,-341.92C106.06,-333.141 136.059,-320.046 158.686,-310.169\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"160.117,-313.363 167.881,-306.155 157.316,-306.948 160.117,-313.363\"/>\n",
       "</g>\n",
       "<!-- 140637751722952 -->\n",
       "<g id=\"node37\" class=\"node\"><title>140637751722952</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"91,-434 37,-434 37,-399 91,-399 91,-434\"/>\n",
       "<text text-anchor=\"middle\" x=\"64\" y=\"-406.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (4)</text>\n",
       "</g>\n",
       "<!-- 140637751722952&#45;&gt;140637751722840 -->\n",
       "<g id=\"edge36\" class=\"edge\"><title>140637751722952&#45;&gt;140637751722840</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M64,-398.885C64,-390.994 64,-381.505 64,-373.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"67.5001,-373.018 64,-363.018 60.5001,-373.018 67.5001,-373.018\"/>\n",
       "</g>\n",
       "<!-- 140637751722728 -->\n",
       "<g id=\"node38\" class=\"node\"><title>140637751722728</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"234,-363 146,-363 146,-342 234,-342 234,-363\"/>\n",
       "<text text-anchor=\"middle\" x=\"190\" y=\"-349.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140637751722728&#45;&gt;140637751722224 -->\n",
       "<g id=\"edge38\" class=\"edge\"><title>140637751722728&#45;&gt;140637751722224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M190,-341.92C190,-334.908 190,-325.144 190,-316.465\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"193.5,-316.341 190,-306.341 186.5,-316.341 193.5,-316.341\"/>\n",
       "</g>\n",
       "<!-- 140637751723008 -->\n",
       "<g id=\"node39\" class=\"node\"><title>140637751723008</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"219.5,-434 160.5,-434 160.5,-399 219.5,-399 219.5,-434\"/>\n",
       "<text text-anchor=\"middle\" x=\"190\" y=\"-406.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (4, 32)</text>\n",
       "</g>\n",
       "<!-- 140637751723008&#45;&gt;140637751722728 -->\n",
       "<g id=\"edge39\" class=\"edge\"><title>140637751723008&#45;&gt;140637751722728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M190,-398.885C190,-390.994 190,-381.505 190,-373.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"193.5,-373.018 190,-363.018 186.5,-373.018 193.5,-373.018\"/>\n",
       "</g>\n",
       "<!-- 140637751656232 -->\n",
       "<g id=\"node40\" class=\"node\"><title>140637751656232</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"277,-192 149,-192 149,-171 277,-171 277,-192\"/>\n",
       "<text text-anchor=\"middle\" x=\"213\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140637751656232&#45;&gt;140637751654720 -->\n",
       "<g id=\"edge40\" class=\"edge\"><title>140637751656232&#45;&gt;140637751654720</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M233.38,-170.92C251.889,-162.219 279.415,-149.279 300.358,-139.434\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"301.9,-142.577 309.461,-135.155 298.922,-136.242 301.9,-142.577\"/>\n",
       "</g>\n",
       "<!-- 140637751722784&#45;&gt;140637751656232 -->\n",
       "<g id=\"edge41\" class=\"edge\"><title>140637751722784&#45;&gt;140637751656232</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M191.529,-227.92C194.954,-220.675 199.768,-210.49 203.97,-201.601\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"207.238,-202.877 208.348,-192.341 200.91,-199.886 207.238,-202.877\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe8c73ab978>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.duelingQNetwork import DuelingQNetwork\n",
    "DuelingQNetwork(state_size, action_size,0).show_model_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Prioritized Experience) ReplayBuffer\n",
    "In this project, we'll make use of a (Prioritized Experience) ReplayBuffer.  \n",
    "Basically it is a pool of records with size N from which we'll sample.  \n",
    "\n",
    "The (Prioritized Experience) ReplayBuffer, which i'll use contains out of 3 objects:\n",
    " - A record\n",
    " - A queue\n",
    " - A Replay Buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record\n",
    "The record is the lowest level in our Replay Buffer. It represents an item in a list.  \n",
    "Each item contains the next attributes:\n",
    " - state\n",
    " - action\n",
    " - reward\n",
    " - next_state\n",
    " - done\n",
    "\n",
    "Extra parameters:\n",
    " - delta\n",
    " \n",
    "### Delta\n",
    "Delta is the basis value to prioritize the records in our Replay Buffer.  \n",
    "Delta itself, is the absolute difference between the expected value and predicted value.  \n",
    "If both values differ a lot from each other then we might want to give that record a higher probability to be sampled  \n",
    "(in comparison, we don't want to waste time on records where the predicted value is near the expected value)\n",
    "\n",
    "### importance_sampling_weight\n",
    "A weight which we'll use during training\n",
    "        \n",
    "\n",
    "### Example of a record & prioritize_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 1,\n",
       " 'action': 2,\n",
       " 'reward': 3,\n",
       " 'next_state': 4,\n",
       " 'done': 5,\n",
       " 'delta': 0.3,\n",
       " 'importance_sampling_weight': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example record:\n",
    "from model.queue import Record\n",
    "\n",
    "record = Record(state = 1, action = 2, reward = 3, next_state = 4, done = 5, delta = 0.3)\n",
    "record.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue\n",
    "\n",
    "Queue is a list of records with a maximum size N  \n",
    "The Queue is responsable for:\n",
    " - Storing records in its memory\n",
    " - Maniging the sum of deltas (denominator)\n",
    " - Returning a sample (with or without respect to the delta values)\n",
    " - calculating the importance_sampling_weight\n",
    " \n",
    "Parameters:\n",
    " - buffer_size: the maximum size of a queue\n",
    " - min_prob: a small value, to avoid that we have 0\n",
    " \n",
    "\n",
    "\n",
    "## Get_sample( sample_size, prioritize_perc, importance_sampling_weight_perc)\n",
    "Get_sample is a method, which will return a sample back from the queue  \n",
    "If the **queue_size < sample_size**, we'll return everything everything back  \n",
    "Else we will return N samples back, where N equals the batch size.  \n",
    "\n",
    "\n",
    "Also if the supplied **prioritize_perc** value > 0, then we will sample from an uniform distribution  \n",
    "otherwise, we'll sample with respect to delta  \n",
    "(records which were trained before and differed a lot from the expected value, will have now a larger probability)\n",
    " - If prioritize_perc == 0 then: Each record has an equal chance to be sampled\n",
    " - If prioritize_perc == 1 then: we'll sample with respect to the delta value\n",
    "              \n",
    "Last but not least, we'll update the record's **importance sampling weight**.  \n",
    "This controls the impact during learning.  \n",
    "Basically, records which have a high probability, (and thus have a higher change to be sampled more often then other records) will have a lower weight | impact during the backpropagation phase! when the value goes to 1\n",
    " - If importance sampling weight == 0 then: each error weight is 1\n",
    " - If importance sampling weight == 1 then: the backpropagation impact of records with a high probabilty is less then records with a low probability\n",
    " \n",
    "### min_prob\n",
    "Each record contains a minimum probability, this prevent us from dividing by 0\n",
    "\n",
    "### Calculating the probability\n",
    "\\begin{equation*}\n",
    "p   = (delta + min\\_prob)^{prioritize\\_perc}\n",
    "\\end{equation*}\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "# Current queue records: #\n",
      "##########################\n",
      "{'state': 2, 'action': 2, 'reward': 2, 'next_state': 2, 'done': 2, 'delta': 2, 'importance_sampling_weight': 0}\n",
      "{'state': 3, 'action': 3, 'reward': 3, 'next_state': 3, 'done': 3, 'delta': 3, 'importance_sampling_weight': 0}\n",
      "{'state': 4, 'action': 4, 'reward': 4, 'next_state': 4, 'done': 4, 'delta': 4, 'importance_sampling_weight': 0}\n",
      "\n",
      "\n",
      "###############\n",
      "# Experimants #\n",
      "###############\n",
      "------- Edit the delta values ---\n",
      "{'state': 2, 'action': 2, 'reward': 2, 'next_state': 2, 'done': 2, 'delta': 0.4, 'importance_sampling_weight': 0}\n",
      "{'state': 3, 'action': 3, 'reward': 3, 'next_state': 3, 'done': 3, 'delta': 0, 'importance_sampling_weight': 0}\n",
      "{'state': 4, 'action': 4, 'reward': 4, 'next_state': 4, 'done': 4, 'delta': 0.1, 'importance_sampling_weight': 0}\n",
      "\n",
      "\n",
      "###########################################################\n",
      "# Impact, prioritize_perc, importance_sampling_weight_perc#\n",
      "###########################################################\n",
      "-- Get 2 samples, prioritize_perc= 0,  importance_sampling_weight_perc= 0):\n",
      "- prioritize_perc= 0: equal distribution: record with state 3 should be sampled\n",
      " \n",
      "{'state': 3, 'action': 3, 'reward': 3, 'next_state': 3, 'done': 3, 'delta': 0, 'importance_sampling_weight': 1.0}\n",
      "{'state': 2, 'action': 2, 'reward': 2, 'next_state': 2, 'done': 2, 'delta': 0.4, 'importance_sampling_weight': 1.0}\n",
      "\n",
      "\n",
      "-- Get 2 samples, prioritize_perc= 1,  importance_sampling_weight_perc= 1):\n",
      "- prioritize_perc= 1: only records with state 2 and 4 should be visible\n",
      "- prioritize_perc= 0: The heigher the value of delta, the lower the value of importance_sampling_weight\n",
      " \n",
      "{'state': 2, 'action': 2, 'reward': 2, 'next_state': 2, 'done': 2, 'delta': 0.4, 'importance_sampling_weight': 0.26829268292682923}\n",
      "{'state': 4, 'action': 4, 'reward': 4, 'next_state': 4, 'done': 4, 'delta': 0.1, 'importance_sampling_weight': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# example record:\n",
    "from model.queue import Queue\n",
    "\n",
    "# qreate a queue with size 3\n",
    "queue = Queue(buffer_size = 3, min_prob = 0.01)\n",
    "\n",
    "# add 5 items to the queue\n",
    "for i in range(5):\n",
    "    record = Record(state = i, action = i, reward = i, next_state = i, done = i, delta = i)\n",
    "    queue.add_record(record)\n",
    "\n",
    "print('##########################')\n",
    "print('# Current queue records: #')\n",
    "print('##########################')\n",
    "for q in queue.queue:\n",
    "    print(q.__dict__)\n",
    "    \n",
    "\n",
    "print('\\n\\n###############')\n",
    "print('# Experimants #')\n",
    "print('###############')\n",
    "print('------- Edit the delta values ---')\n",
    "# re arrange the delta values\n",
    "record = queue.queue[0]\n",
    "record.set_delta(0.4)\n",
    "\n",
    "record = queue.queue[1]\n",
    "record.set_delta(0)\n",
    "\n",
    "record = queue.queue[2]\n",
    "record.set_delta(0.1)\n",
    "\n",
    "for q in queue.queue:\n",
    "    print(q.__dict__)\n",
    "    \n",
    "print('\\n\\n###########################################################')\n",
    "print('# Impact, prioritize_perc, importance_sampling_weight_perc#')\n",
    "print('###########################################################')\n",
    "print(f'-- Get 2 samples, prioritize_perc= 0,  importance_sampling_weight_perc= 0):')\n",
    "print(\"- prioritize_perc= 0: equal distribution: record with state 3 should be sampled\")\n",
    "print(\" \")\n",
    "for q in  queue.get_sample(sample_size= 2, prioritize_perc= 0, importance_sampling_weight_perc= 0):\n",
    "    print(f'{q.__dict__}')\n",
    "    \n",
    "print(f'\\n\\n-- Get 2 samples, prioritize_perc= 1,  importance_sampling_weight_perc= 1):')\n",
    "print(\"- prioritize_perc= 1: only records with state 2 and 4 should be visible\")\n",
    "print(\"- prioritize_perc= 0: The heigher the value of delta, the lower the value of importance_sampling_weight\")\n",
    "print(' ')\n",
    "for q in queue.get_sample(sample_size= 2, prioritize_perc= 1, importance_sampling_weight_perc= 1):\n",
    "    print(f'{q.__dict__}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReplayBuffer\n",
    "\n",
    "The replay buffer is the outher shell of our sampling pool.\n",
    "it will:\n",
    " - create the queue\n",
    " - controll prioritization of the records\n",
    " - controll importance sampling weight\n",
    " - create batches \n",
    " - handles the importance sampling weight decay \n",
    "\n",
    "parameters:\n",
    " - action size: Amount of actions which we can take (4: up, left, right, down)\n",
    " - Memory - buffer_size: The size of the buffer | QUEUE (e.g.: 1000 examples)\n",
    " - batch_size: The size of 1 Batch (whih contains random elements)\n",
    " - experience: A nicer way to use a n-tuple (Quintuple)\n",
    " \n",
    "### add_record\n",
    " - add an example in to the Memory (QUEUE)\n",
    " \n",
    "### sample( s)\n",
    " - Sample gives you the data back of 1 batch\n",
    " - In this case, Sample is a tuple of 5 elements and each element contains a tensor of size n (n == batch_size)\n",
    " - E.g.\n",
    "     - (tensor([[ 7.], [ 9.],  [ 1.]]), # states  \n",
    "        tensor([[ 7],  [ 9],   [ 1]]),  # actions  \n",
    "        tensor([[ 0.], [ 10.], [  0.]]),# rewards  \n",
    "        tensor([[ 8.], [ 10.], [  2.]]),# next_state  \n",
    "        tensor([[ 0.], [ 1.],  [ 0.]]) )# dones  \n",
    "        \n",
    " - Each sample will be taken randomly out of the memory queue.\n",
    "  - This means that an instance can occure in multiple batches.\n",
    "  - An instance | record will only be removed out of the memory queue when:\n",
    "      - The queue has reached its maximum capacity (buffer size)\n",
    "      - If this is the case it will remove the oldest record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 9.],\n",
       "         [ 5.],\n",
       "         [ 7.]]), tensor([[ 9],\n",
       "         [ 5],\n",
       "         [ 7]]), tensor([[ 10.],\n",
       "         [  0.],\n",
       "         [  0.]]), tensor([[ 10.],\n",
       "         [  6.],\n",
       "         [  8.]]), tensor([[ 1.],\n",
       "         [ 0.],\n",
       "         [ 0.]]), [<model.queue.Record at 0x7fe8c73cb4e0>,\n",
       "  <model.queue.Record at 0x7fe8c73cb3c8>,\n",
       "  <model.queue.Record at 0x7fe8c73cb438>])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-----------------------#\n",
    "# Test the ReplayBuffer #\n",
    "#-----------------------#\n",
    "from model.replayBuffer import ReplayBuffer\n",
    "test_buffer = ReplayBuffer(action_size = 4, \n",
    "                           buffer_size = 10, \n",
    "                           batch_size = 3, \n",
    "                           seed = 0, \n",
    "                           importance_sampling_weight_perc= 1, \n",
    "                           prioritize_perc = 1)\n",
    "\n",
    "for i in range(10):\n",
    "    test_buffer.add_record(state = i, action=i, reward=0, next_state=i+1, done=0, delta = i+1/10)\n",
    "else:\n",
    "    test_buffer.add_record(state = i, action=i, reward=10, next_state=i+1, done=1, delta = i+1/10)\n",
    "    \n",
    "test_buffer.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the agent\n",
    "\n",
    "## Steps:\n",
    " - **initialize an Agent: agent = Agent(state_size=state_size, action_size=action_size, seed=0)**\n",
    "  - *Environment provides us a state*\n",
    " - **Given a state, get an action: action = __agent.act__(state, eps)**\n",
    "  - *Perform the action in the environment & get the state, action, reward, next_state, done values back*\n",
    " - **Save the environment data in the buffer & update the NN: __agent.step__(state, action, reward, next_state, done)**\n",
    "  - *update the old state  *\n",
    " ...  \n",
    " - **Given a state, get an action: action = __agent.act__(state, eps)**\n",
    "  - *Perform the action in the environment & get the state, action, reward, next_state, done values back*\n",
    " - **Save the environment data in the buffer & update the NN: __agent.step__(state, action, reward, next_state, done)**\n",
    "  - *update the old state*\n",
    "  \n",
    "  \n",
    "## Initialize\n",
    " - state_size: The state in which we are ( variables of the parameters: 37 )\n",
    " - action_size: Amount of actions which we can take (4: up, left, right, down)\n",
    "\n",
    " - 2 Small neural nets\n",
    "  - qnetwork_local: will be updated via backpropagation\n",
    "  - qnetwork_target: will updated via qnetwork_local\n",
    "  \n",
    " - memory | ReplayBuffer: a pool of previous experiences \n",
    " \n",
    " - set the step to 0\n",
    " \n",
    "## Step 1: act(state, eps=0.)\n",
    "  #### epsilon:\n",
    "  Epsilon is a number (between 0 and 1) which is responsable of taking random actions.  \n",
    "  The value of epsilon will be compared with a random generated value (also between 0 and 1)   \n",
    "  When the value of epsilon is larger then the random value, then we'll perform a random action  \n",
    "  otherwise, we'll take the action with the highest probability.  \n",
    "  Last but not least, in each step the value of epsilon might decrease a bit in such a way that we take  \n",
    "  more random actions in the beginning and relay more on the network at the end.\n",
    "  \n",
    "  #### steps\n",
    "  input: state\n",
    "  \n",
    "  - if a random number between 0 and 1, is smaller or equal then the epsilon value:  \n",
    "    --> return a random action  \n",
    "$$\\frac{eps\\_min}{eps\\_max}^{\\frac{episode\\_nr}{episodes\\_to\\_min\\_decay}}$$\n",
    "  - Else, pass the given state trough the local q-network\n",
    "  - get the probabilities of the possible actions, (from the network)\n",
    "  - return the action with the highest probability\n",
    "  \n",
    "  \n",
    "## Step 2: step(state, action, reward, next_state, done)\n",
    " \n",
    " Previously in step 1, we requested a (random) action from the agent.  \n",
    " And with this action we asked the environment for a reward value, a next_state and a done value,  \n",
    " given our current_state and action. Now in the second step, we'll\n",
    " - store the currente event into the replay memory buffer\n",
    "   - state\n",
    "   - action\n",
    "   - reward\n",
    "   - next_state\n",
    "   - delta\n",
    "    - Note that we aleady provide a small default delta value\n",
    " - Train the network each x steps\n",
    "   - If there is enough data in the replay memory buffer\n",
    "    - If so, go to Step 3\n",
    "    \n",
    "    \n",
    "    \n",
    "## Step 3: learn(experiences)\n",
    "Train the model each x steps, if there are enough examples in our replay buffer.\n",
    "\n",
    "- Get a batch of training records: states, actions, rewards, next_states, dones, records  \n",
    "- Use a DQN network or a DDQN network to define the next Q targets.  \n",
    " - DQN: Select the max action value of the target value  \n",
    "   e.g: for a batch (64 records ):  \n",
    "         - Predict the action to undertake (64 X 4) (if we've 4 actions)  \n",
    "        \n",
    "         tensor([[ 0.1045, -0.0075, -0.2736,  0.1418],  \n",
    "                 [ 0.1603, -0.0054,  0.1768,  0.1021],   \n",
    "                 [ 0.1830, -0.0304, -0.1600,  0.1432],  \n",
    "                 [ 0.1380,  0.0194, -0.1237,  0.0512]])  \n",
    "        \n",
    "         - Take the max value of each tensor (.max(1)) (of the TARGET NETWORK)\n",
    "         (tensor([ 0.1418,  0.1768,  0.1830,  0.1380]), tensor([ 3,  2,  0,  0]))  \n",
    "            \n",
    "         Result : Grep the max value  \n",
    "         Q_targets_next = tensor([[ 0.1418], [ 0.1768], [ 0.1830], [ 0.1380]])  \n",
    " - DDQN:  \n",
    "   e.g.: for a batch (64 records ):  \n",
    "            - Predict the action to undertake (64 X 4) (if we've 4 actions)  \n",
    "            \n",
    "             tensor([[ 0.1045, -0.0075, -0.2736,  0.1418],  \n",
    "                     [ 0.1603, -0.0054,  0.1768,  0.1021],  \n",
    "                     [ 0.1830, -0.0304, -0.1600,  0.1432],  \n",
    "                     [ 0.1380,  0.0194, -0.1237,  0.0512]])  \n",
    "             \n",
    "             - Take the probabilities of the MAX value of the LOCAL NETWORK !  \n",
    " - Compute the new *Q targets* \n",
    "  - Q_targets = rewards + (self.GAMMA * Q_targets_next * (1 - dones))\n",
    " - Get the expected Q values from the localnetwork (the expected actions)\n",
    " - Compute the loss between the expected Q values and Q targets\n",
    " - Update the weights + the adjust the record delta value (which might be used by the Replay Buffer)\n",
    " - Backpropagate\n",
    " - Update the target network\n",
    "             \n",
    "\n",
    "\n",
    "### HypterParameters\n",
    "```\n",
    " - BUFFER_SIZE = 100000                 # replay buffer size\n",
    " - BATCH_SIZE = 128                     # minibatch size\n",
    " - PRIORITIZE_PERC = 0.0                # 0: each record has a equal chance to be sampled, \n",
    "                                          1: sample with respect to delta\n",
    "   \n",
    " - IMPORTANCE_SAMPLING_WEIGHT_PERC = 0  # starting value, 0 each record has a weight of 1\n",
    " - B_VALUE_TO_MINIMUM_DECAY = 1000      # episodes until minimum\n",
    " - CALCULATE_B_XTH_PERCENTAGE = 0.999   # at the xthe episode of B_VALUE_TO_MINIMUM_DECAY\n",
    " - CALCULATE_B_XTH_VALUE = 0.0001       # it should have the value of y\n",
    "  \n",
    " - DELTA_INIT = 0.01                    # Initial Delta value of a new record\n",
    " - GAMMA = 0.99                         #  Gamma value\n",
    " - TAU = 0.02                           # How much are we going to update the target value\n",
    " - LR = 0.001                           # Starting learning rate (there is a exp-decay of 0.999\n",
    " - UPDATE_EVERY = 8                     # learn every x frames\n",
    " - DDQN = True                          # Use DQN or DDQN\n",
    " - DUELING = True                       # Use a Dueling NN or a normal one\n",
    "\n",
    " - EPISODE= 1                           # starting episode\n",
    " - EPSILON_TO_MINIMUM_DECAY = 20        # amount of episodes until minimum value\n",
    " - EPSILON_INIT = 1.                    # Starting value of epsilon\n",
    " - EPSILON_MAX= 0.99                    # maximum value of epsilon\n",
    " - EPSILON_MIN= 0.1                     # minimum value of epsilon\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.agent import Agent\n",
    "\n",
    "NR_EPISODES = 1000\n",
    "\n",
    "SEED = 0\n",
    "BUFFER_SIZE = 100000   # replay buffer size\n",
    "BATCH_SIZE = 128 #64    # minibatch size\n",
    "PRIORITIZE_PERC = 0.0\n",
    "IMPORTANCE_SAMPLING_WEIGHT_PERC = 0 \n",
    "CALCULATE_B_XTH_PERCENTAGE = 0.999      # x perc of EPISODES_TO_MINIMUM_DECAY 0-1\n",
    "CALCULATE_B_XTH_VALUE = 0.0001           # should have value 0-1\n",
    "B_VALUE_TO_MINIMUM_DECAY = 1000\n",
    "DELTA_INIT = 0.01\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 0.02              # for soft update of target parameters\n",
    "LR = 0.001              # learning rate \n",
    "UPDATE_EVERY = 8        # how often to update the network\n",
    "DDQN = True\n",
    "DUELING = True\n",
    "EPISODE= 1\n",
    "EPSILON_TO_MINIMUM_DECAY = 20\n",
    "EPSILON_INIT = 1.\n",
    "EPSILON_MAX= 0.99\n",
    "EPSILON_MIN= 0.1\n",
    "\n",
    "\n",
    "agent = Agent(state_size = state_size,\n",
    "             action_size = action_size,\n",
    "             seed = SEED,\n",
    "             buffer_size = BUFFER_SIZE, \n",
    "             batch_size = BATCH_SIZE, \n",
    "             prioritize_perc = PRIORITIZE_PERC, \n",
    "             importance_sampling_weight_perc = IMPORTANCE_SAMPLING_WEIGHT_PERC,\n",
    "             calculate_b_xth_percentage = CALCULATE_B_XTH_PERCENTAGE,\n",
    "             calculate_b_value = CALCULATE_B_XTH_VALUE,\n",
    "             b_value_to_minimum_decay = B_VALUE_TO_MINIMUM_DECAY,\n",
    "             delta_init = DELTA_INIT, \n",
    "             gamma = GAMMA, \n",
    "             tau = TAU, \n",
    "             lr = LR, \n",
    "             update_every = UPDATE_EVERY, \n",
    "             ddqn = DDQN,\n",
    "             dueling = DUELING ,\n",
    "             episode = EPISODE,\n",
    "             epsilon_to_minimum_decay= EPSILON_TO_MINIMUM_DECAY,\n",
    "             epsilon_init = EPSILON_INIT,\n",
    "             epsilon_max= EPSILON_MAX,\n",
    "             epsilon_min= EPSILON_MIN\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new Training session\n",
    "\n",
    "- Create a log file\n",
    "- create a list which will hold the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log the data\n",
    "agent_creation_timestamp = agent.get_creation_timestamp()\n",
    "agent_log_file = f\"./logs/agent_{agent_creation_timestamp}.txt\"\n",
    "agent_results_log_file = f\"./results/agent_{agent_creation_timestamp}.txt\"\n",
    "agent_results_file = f\"./results/agent_score_{agent_creation_timestamp}.csv\"\n",
    "\n",
    "# if file exist, remove it first\n",
    "if os.path.exists(agent_log_file):\n",
    "    os.remove(agent_log_file)\n",
    "\n",
    "# Write header\n",
    "with open(agent_log_file, 'w') as file:\n",
    "    file.write('Project: Banana Navigation\\n')\n",
    "    file.write(f'Date: {agent_creation_timestamp}\\n')\n",
    "    file.write('By: Dieter Verbeemen\\n\\n')\n",
    "    file.write('\\n\\n=====================Agent-PARAMETERS=========================\\n\\n')\n",
    "        \n",
    "    # write the data\n",
    "    for key, value in agent.__dict__.items():\n",
    "        file.write(f'{key}: {value}\\n')\n",
    "        \n",
    "        \n",
    "    file.write('\\n\\n=====================Brain-PARAMETERS=========================\\n\\n')\n",
    "        \n",
    "    # write the data\n",
    "    for key, value in brain.__dict__.items():\n",
    "        file.write(f'{key}: {value}\\n')\n",
    "        \n",
    "    file.write('\\n\\n==============================================================\\n\\n')\n",
    "    \n",
    "# set the score\n",
    "score_window = deque(maxlen = 100)\n",
    "score = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "Train the agent !\n",
    "- Loop over x episodes\n",
    " - Start a new game\n",
    " - Inform the agent that we're goin to start a new episode  \n",
    "   - This will update, epsilon, b-value, etc\n",
    " - Set the score to 0\n",
    " - Do until the episode is finished\n",
    "   - Environment, gives the agent a new state\n",
    "   - Agent, evaluates the state en gives us an action back\n",
    "   - Environment, executes the action\n",
    "    - Get the next state from the environment\n",
    "    - Get the a reward from the environment\n",
    "    - Get a boolean back wich says done or not from the environment\n",
    "   - Agent, evaluates all the new info and stores the data: state, action, reward, next_state, done values \n",
    "   - Agent, Train the networks if the criteria's are matched\n",
    "  - update the scores\n",
    "  - Stop the episode, if done is True\n",
    "  - Log the episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0\tCurrent_score: 1.0\tAverage score: 1.0\tloss: 0.3746587038040161\tweighted_loss: 0.3746587038040161\teps: 0.8916989192462339\tb_decay: 1.0010510043123588e-07\tLearning rate: 0.000999\n",
      "episode: 1\tCurrent_score: 1.0\tAverage score: 1.0\tloss: 0.25867733359336853\tweighted_loss: 0.25867733359336853\teps: 0.7951269625849016\tb_decay: 2.0021019087046454e-07\tLearning rate: 0.000998001\n",
      "episode: 2\tCurrent_score: 0.0\tAverage score: 0.667\tloss: 0.12543566524982452\tweighted_loss: 0.12543566524982452\teps: 0.7090138532004975\tb_decay: 3.003152712066637e-07\tLearning rate: 0.000997002999\n",
      "episode: 3\tCurrent_score: 2.0\tAverage score: 1.0\tloss: 0.0939178466796875\tweighted_loss: 0.0939178466796875\teps: 0.6322268866294916\tb_decay: 4.004203415508556e-07\tLearning rate: 0.000996005996001\n",
      "episode: 4\tCurrent_score: 1.0\tAverage score: 1.0\tloss: 0.09493505954742432\tweighted_loss: 0.09493505954742432\teps: 0.5637560315259289\tb_decay: 5.005254019030403e-07\tLearning rate: 0.000995009990004999\n",
      "episode: 5\tCurrent_score: 1.0\tAverage score: 1.0\tloss: 0.0928816944360733\tweighted_loss: 0.0928816944360733\teps: 0.5027006440302166\tb_decay: 6.006304522632178e-07\tLearning rate: 0.000994014980014994\n",
      "episode: 6\tCurrent_score: 3.0\tAverage score: 1.286\tloss: 0.08952728658914566\tweighted_loss: 0.08952728658914566\teps: 0.4482576209861299\tb_decay: 7.007354925203657e-07\tLearning rate: 0.0009930209650349789\n",
      "episode: 7\tCurrent_score: 1.0\tAverage score: 1.25\tloss: 0.10356181114912033\tweighted_loss: 0.10356181114912033\teps: 0.3997108361772199\tb_decay: 8.008405227855064e-07\tLearning rate: 0.0009920279440699439\n",
      "episode: 8\tCurrent_score: 2.0\tAverage score: 1.333\tloss: 0.14143943786621094\tweighted_loss: 0.14143943786621094\teps: 0.3564217206302355\tb_decay: 9.009455430586399e-07\tLearning rate: 0.0009910359161258739\n",
      "episode: 9\tCurrent_score: 4.0\tAverage score: 1.6\tloss: 0.1443985253572464\tweighted_loss: 0.1443985253572464\teps: 0.31782086308186414\tb_decay: 1.0010505533397662e-06\tLearning rate: 0.000990044880209748\n",
      "episode: 10\tCurrent_score: 1.0\tAverage score: 1.545\tloss: 0.19229093194007874\tweighted_loss: 0.19229093194007874\teps: 0.2834005201240035\tb_decay: 1.101155553517863e-06\tLearning rate: 0.0009890548353295382\n",
      "episode: 11\tCurrent_score: 3.0\tAverage score: 1.667\tloss: 0.23342829942703247\tweighted_loss: 0.23342829942703247\teps: 0.25270793750839454\tb_decay: 1.2012605437039525e-06\tLearning rate: 0.0009880657804942088\n",
      "episode: 12\tCurrent_score: 7.0\tAverage score: 2.077\tloss: 0.26730695366859436\tweighted_loss: 0.26730695366859436\teps: 0.2253393947611802\tb_decay: 1.3013655238980348e-06\tLearning rate: 0.0009870777147137145\n",
      "episode: 13\tCurrent_score: 3.0\tAverage score: 2.143\tloss: 0.2556387782096863\tweighted_loss: 0.2556387782096863\teps: 0.20093489477214488\tb_decay: 1.40147049410011e-06\tLearning rate: 0.0009860906369990009\n",
      "episode: 14\tCurrent_score: 2.0\tAverage score: 2.133\tloss: 0.3264356553554535\tweighted_loss: 0.3264356553554535\teps: 0.17917342850717732\tb_decay: 1.5015754541991555e-06\tLearning rate: 0.000985104546362002\n",
      "episode: 15\tCurrent_score: 7.0\tAverage score: 2.438\tloss: 0.3212241232395172\tweighted_loss: 0.3212241232395172\teps: 0.15976875255749237\tb_decay: 1.6016804043061939e-06\tLearning rate: 0.00098411944181564\n",
      "episode: 16\tCurrent_score: 9.0\tAverage score: 2.824\tloss: 0.3078787624835968\tweighted_loss: 0.3078787624835968\teps: 0.14246562398483492\tb_decay: 1.701785344421225e-06\tLearning rate: 0.0009831353223738242\n",
      "episode: 17\tCurrent_score: 7.0\tAverage score: 3.056\tloss: 0.3626077175140381\tweighted_loss: 0.3626077175140381\teps: 0.12703644293701763\tb_decay: 1.8018902745442489e-06\tLearning rate: 0.0009821521870514505\n",
      "episode: 18\tCurrent_score: 10.0\tAverage score: 3.421\tloss: 0.46034517884254456\tweighted_loss: 0.46034517884254456\teps: 0.11327825887182452\tb_decay: 1.9019951945642433e-06\tLearning rate: 0.000981170034864399\n",
      "episode: 19\tCurrent_score: 4.0\tAverage score: 3.45\tloss: 0.487263023853302\tweighted_loss: 0.487263023853302\teps: 0.10101010101010102\tb_decay: 2.0021001045922304e-06\tLearning rate: 0.0009801888648295347\n",
      "episode: 20\tCurrent_score: 12.0\tAverage score: 3.857\tloss: 0.564832329750061\tweighted_loss: 0.564832329750061\teps: 0.1\tb_decay: 2.1022050046282104e-06\tLearning rate: 0.000979208675964705\n",
      "episode: 21\tCurrent_score: 3.0\tAverage score: 3.818\tloss: 0.4553859233856201\tweighted_loss: 0.4553859233856201\teps: 0.1\tb_decay: 2.2023098945611608e-06\tLearning rate: 0.0009782294672887404\n",
      "episode: 22\tCurrent_score: 5.0\tAverage score: 3.87\tloss: 0.5441906452178955\tweighted_loss: 0.5441906452178955\teps: 0.1\tb_decay: 2.302414774502104e-06\tLearning rate: 0.0009772512378214517\n",
      "episode: 23\tCurrent_score: 9.0\tAverage score: 4.083\tloss: 0.5210310220718384\tweighted_loss: 0.5210310220718384\teps: 0.1\tb_decay: 2.40251964445104e-06\tLearning rate: 0.0009762739865836303\n",
      "episode: 24\tCurrent_score: 6.0\tAverage score: 4.16\tloss: 0.5662208199501038\tweighted_loss: 0.5662208199501038\teps: 0.1\tb_decay: 2.5026245044079687e-06\tLearning rate: 0.0009752977125970467\n",
      "episode: 25\tCurrent_score: 9.0\tAverage score: 4.346\tloss: 0.5804142951965332\tweighted_loss: 0.5804142951965332\teps: 0.1\tb_decay: 2.602729354261868e-06\tLearning rate: 0.0009743224148844496\n",
      "episode: 26\tCurrent_score: 10.0\tAverage score: 4.556\tloss: 0.5459449887275696\tweighted_loss: 0.5459449887275696\teps: 0.1\tb_decay: 2.7028341942347822e-06\tLearning rate: 0.0009733480924695652\n",
      "episode: 27\tCurrent_score: 13.0\tAverage score: 4.857\tloss: 0.5775395035743713\tweighted_loss: 0.5775395035743713\teps: 0.1\tb_decay: 2.8029390239936447e-06\tLearning rate: 0.0009723747443770956\n",
      "episode: 28\tCurrent_score: 15.0\tAverage score: 5.207\tloss: 0.5088741779327393\tweighted_loss: 0.5088741779327393\teps: 0.1\tb_decay: 2.9030438438715223e-06\tLearning rate: 0.0009714023696327184\n",
      "episode: 29\tCurrent_score: 9.0\tAverage score: 5.333\tloss: 0.6274975538253784\tweighted_loss: 0.6274975538253784\teps: 0.1\tb_decay: 3.0031486537573926e-06\tLearning rate: 0.0009704309672630857\n",
      "episode: 30\tCurrent_score: 8.0\tAverage score: 5.419\tloss: 0.5499036312103271\tweighted_loss: 0.5499036312103271\teps: 0.1\tb_decay: 3.1032534535402334e-06\tLearning rate: 0.0009694605362958226\n",
      "episode: 31\tCurrent_score: 12.0\tAverage score: 5.625\tloss: 0.6966543197631836\tweighted_loss: 0.6966543197631836\teps: 0.1\tb_decay: 3.203358243331067e-06\tLearning rate: 0.0009684910757595268\n",
      "episode: 32\tCurrent_score: 12.0\tAverage score: 5.818\tloss: 0.6464763879776001\tweighted_loss: 0.6464763879776001\teps: 0.1\tb_decay: 3.303463023018871e-06\tLearning rate: 0.0009675225846837673\n",
      "episode: 33\tCurrent_score: 7.0\tAverage score: 5.853\tloss: 0.5849443674087524\tweighted_loss: 0.5849443674087524\teps: 0.1\tb_decay: 3.403567792714668e-06\tLearning rate: 0.0009665550620990835\n",
      "episode: 34\tCurrent_score: 8.0\tAverage score: 5.914\tloss: 0.729957103729248\tweighted_loss: 0.729957103729248\teps: 0.1\tb_decay: 3.50367255252948e-06\tLearning rate: 0.0009655885070369844\n",
      "episode: 35\tCurrent_score: 6.0\tAverage score: 5.917\tloss: 0.8245804905891418\tweighted_loss: 0.8245804905891418\teps: 0.1\tb_decay: 3.60377730213024e-06\tLearning rate: 0.0009646229185299475\n",
      "episode: 36\tCurrent_score: 7.0\tAverage score: 5.946\tloss: 0.7591631412506104\tweighted_loss: 0.7591631412506104\teps: 0.1\tb_decay: 3.703882041850015e-06\tLearning rate: 0.0009636582956114176\n",
      "episode: 37\tCurrent_score: 10.0\tAverage score: 6.053\tloss: 0.741052508354187\tweighted_loss: 0.741052508354187\teps: 0.1\tb_decay: 3.8039867714667608e-06\tLearning rate: 0.0009626946373158062\n",
      "episode: 38\tCurrent_score: 1.0\tAverage score: 5.923\tloss: 0.7101757526397705\tweighted_loss: 0.7101757526397705\teps: 0.1\tb_decay: 3.904091491091499e-06\tLearning rate: 0.0009617319426784903\n",
      "episode: 39\tCurrent_score: 14.0\tAverage score: 6.125\tloss: 0.7875130772590637\tweighted_loss: 0.7875130772590637\teps: 0.1\tb_decay: 4.0041962007242304e-06\tLearning rate: 0.0009607702107358118\n",
      "episode: 40\tCurrent_score: 12.0\tAverage score: 6.268\tloss: 0.8360378742218018\tweighted_loss: 0.8360378742218018\teps: 0.1\tb_decay: 4.1043009003649544e-06\tLearning rate: 0.000959809440525076\n",
      "episode: 41\tCurrent_score: 3.0\tAverage score: 6.19\tloss: 0.8053236603736877\tweighted_loss: 0.8053236603736877\teps: 0.1\tb_decay: 4.204405589902649e-06\tLearning rate: 0.0009588496310845509\n",
      "episode: 42\tCurrent_score: 10.0\tAverage score: 6.279\tloss: 0.7878278493881226\tweighted_loss: 0.7878278493881226\teps: 0.1\tb_decay: 4.304510269448336e-06\tLearning rate: 0.0009578907814534664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 43\tCurrent_score: 14.0\tAverage score: 6.455\tloss: 0.7859475016593933\tweighted_loss: 0.7859475016593933\teps: 0.1\tb_decay: 4.404614939002016e-06\tLearning rate: 0.0009569328906720129\n",
      "episode: 44\tCurrent_score: 8.0\tAverage score: 6.489\tloss: 0.8552645444869995\tweighted_loss: 0.8552645444869995\teps: 0.1\tb_decay: 4.504719598452667e-06\tLearning rate: 0.0009559759577813409\n",
      "episode: 45\tCurrent_score: 11.0\tAverage score: 6.587\tloss: 0.9403565526008606\tweighted_loss: 0.9403565526008606\teps: 0.1\tb_decay: 4.60482424791131e-06\tLearning rate: 0.0009550199818235595\n",
      "episode: 46\tCurrent_score: 12.0\tAverage score: 6.702\tloss: 0.8982782363891602\tweighted_loss: 0.8982782363891602\teps: 0.1\tb_decay: 4.704928887377946e-06\tLearning rate: 0.0009540649618417359\n",
      "episode: 47\tCurrent_score: 13.0\tAverage score: 6.833\tloss: 0.8875873684883118\tweighted_loss: 0.8875873684883118\teps: 0.1\tb_decay: 4.805033516852575e-06\tLearning rate: 0.0009531108968798942\n",
      "episode: 48\tCurrent_score: 8.0\tAverage score: 6.857\tloss: 0.8724250197410583\tweighted_loss: 0.8724250197410583\teps: 0.1\tb_decay: 4.905138136224174e-06\tLearning rate: 0.0009521577859830143\n",
      "episode: 49\tCurrent_score: 14.0\tAverage score: 7.0\tloss: 0.8293006420135498\tweighted_loss: 0.8293006420135498\teps: 0.1\tb_decay: 5.0052427457147886e-06\tLearning rate: 0.0009512056281970313\n",
      "episode: 50\tCurrent_score: 9.0\tAverage score: 7.039\tloss: 0.8217598795890808\tweighted_loss: 0.8217598795890808\teps: 0.1\tb_decay: 5.1053473451023734e-06\tLearning rate: 0.0009502544225688343\n",
      "episode: 51\tCurrent_score: 5.0\tAverage score: 7.0\tloss: 0.9359492063522339\tweighted_loss: 0.9359492063522339\teps: 0.1\tb_decay: 5.205451934386929e-06\tLearning rate: 0.0009493041681462655\n",
      "episode: 52\tCurrent_score: 7.0\tAverage score: 7.0\tloss: 0.9015172123908997\tweighted_loss: 0.9015172123908997\teps: 0.1\tb_decay: 5.305556513790499e-06\tLearning rate: 0.0009483548639781192\n",
      "episode: 53\tCurrent_score: 5.0\tAverage score: 6.963\tloss: 1.0730245113372803\tweighted_loss: 1.0730245113372803\teps: 0.1\tb_decay: 5.40566108309104e-06\tLearning rate: 0.0009474065091141411\n",
      "episode: 54\tCurrent_score: 10.0\tAverage score: 7.018\tloss: 0.8380301594734192\tweighted_loss: 0.8380301594734192\teps: 0.1\tb_decay: 5.505765642399574e-06\tLearning rate: 0.0009464591026050269\n",
      "episode: 55\tCurrent_score: 9.0\tAverage score: 7.054\tloss: 0.9823639988899231\tweighted_loss: 0.9823639988899231\teps: 0.1\tb_decay: 5.605870191605078e-06\tLearning rate: 0.0009455126435024218\n",
      "episode: 56\tCurrent_score: 7.0\tAverage score: 7.053\tloss: 0.9166366457939148\tweighted_loss: 0.9166366457939148\teps: 0.1\tb_decay: 5.705974730929597e-06\tLearning rate: 0.0009445671308589194\n",
      "episode: 57\tCurrent_score: 13.0\tAverage score: 7.155\tloss: 1.0100681781768799\tweighted_loss: 1.0100681781768799\teps: 0.1\tb_decay: 5.806079260151087e-06\tLearning rate: 0.0009436225637280605\n",
      "episode: 58\tCurrent_score: 11.0\tAverage score: 7.22\tloss: 0.865157425403595\tweighted_loss: 0.865157425403595\teps: 0.1\tb_decay: 5.906183779269547e-06\tLearning rate: 0.0009426789411643324\n",
      "episode: 59\tCurrent_score: 8.0\tAverage score: 7.233\tloss: 1.1626948118209839\tweighted_loss: 1.1626948118209839\teps: 0.1\tb_decay: 6.006288288507022e-06\tLearning rate: 0.0009417362622231681\n",
      "episode: 60\tCurrent_score: 13.0\tAverage score: 7.328\tloss: 0.8980329632759094\tweighted_loss: 0.8980329632759094\teps: 0.1\tb_decay: 6.106392787641468e-06\tLearning rate: 0.0009407945259609449\n",
      "episode: 61\tCurrent_score: 12.0\tAverage score: 7.403\tloss: 1.0283788442611694\tweighted_loss: 1.0283788442611694\teps: 0.1\tb_decay: 6.206497276783907e-06\tLearning rate: 0.000939853731434984\n",
      "episode: 62\tCurrent_score: 10.0\tAverage score: 7.444\tloss: 1.0351866483688354\tweighted_loss: 1.0351866483688354\teps: 0.1\tb_decay: 6.306601755934338e-06\tLearning rate: 0.000938913877703549\n",
      "episode: 63\tCurrent_score: 12.0\tAverage score: 7.516\tloss: 0.9824460744857788\tweighted_loss: 0.9824460744857788\teps: 0.1\tb_decay: 6.406706225092762e-06\tLearning rate: 0.0009379749638258455\n",
      "episode: 64\tCurrent_score: 16.0\tAverage score: 7.646\tloss: 1.0286188125610352\tweighted_loss: 1.0286188125610352\teps: 0.1\tb_decay: 6.5068106841481566e-06\tLearning rate: 0.0009370369888620196\n",
      "episode: 65\tCurrent_score: 15.0\tAverage score: 7.758\tloss: 0.8580121994018555\tweighted_loss: 0.8580121994018555\teps: 0.1\tb_decay: 6.606915133211544e-06\tLearning rate: 0.0009360999518731576\n",
      "episode: 66\tCurrent_score: 9.0\tAverage score: 7.776\tloss: 0.963550329208374\tweighted_loss: 0.963550329208374\teps: 0.1\tb_decay: 6.707019572282924e-06\tLearning rate: 0.0009351638519212844\n",
      "episode: 67\tCurrent_score: 17.0\tAverage score: 7.912\tloss: 1.0716506242752075\tweighted_loss: 1.0716506242752075\teps: 0.1\tb_decay: 6.807124001251275e-06\tLearning rate: 0.0009342286880693632\n",
      "episode: 68\tCurrent_score: 10.0\tAverage score: 7.942\tloss: 1.001975178718567\tweighted_loss: 1.001975178718567\teps: 0.1\tb_decay: 6.907228420227618e-06\tLearning rate: 0.0009332944593812938\n",
      "episode: 69\tCurrent_score: 5.0\tAverage score: 7.9\tloss: 1.0416009426116943\tweighted_loss: 1.0416009426116943\teps: 0.1\tb_decay: 7.007332829211954e-06\tLearning rate: 0.0009323611649219125\n",
      "episode: 70\tCurrent_score: 16.0\tAverage score: 8.014\tloss: 0.9835777282714844\tweighted_loss: 0.9835777282714844\teps: 0.1\tb_decay: 7.107437228204283e-06\tLearning rate: 0.0009314288037569906\n",
      "episode: 71\tCurrent_score: 7.0\tAverage score: 8.0\tloss: 0.9902788400650024\tweighted_loss: 0.9902788400650024\teps: 0.1\tb_decay: 7.2075416170935824e-06\tLearning rate: 0.0009304973749532337\n",
      "episode: 72\tCurrent_score: 10.0\tAverage score: 8.027\tloss: 0.8881160616874695\tweighted_loss: 0.8881160616874695\teps: 0.1\tb_decay: 7.307645996101897e-06\tLearning rate: 0.0009295668775782805\n",
      "episode: 73\tCurrent_score: 1.0\tAverage score: 7.932\tloss: 1.1322861909866333\tweighted_loss: 1.1322861909866333\teps: 0.1\tb_decay: 7.407750365007182e-06\tLearning rate: 0.0009286373107007022\n",
      "episode: 74\tCurrent_score: 8.0\tAverage score: 7.933\tloss: 1.0747644901275635\tweighted_loss: 1.0747644901275635\teps: 0.1\tb_decay: 7.507854723809437e-06\tLearning rate: 0.0009277086733900015\n",
      "episode: 75\tCurrent_score: 12.0\tAverage score: 7.987\tloss: 1.1409955024719238\tweighted_loss: 1.1409955024719238\teps: 0.1\tb_decay: 7.607959072730708e-06\tLearning rate: 0.0009267809647166115\n",
      "episode: 76\tCurrent_score: 10.0\tAverage score: 8.013\tloss: 1.1888710260391235\tweighted_loss: 1.1888710260391235\teps: 0.1\tb_decay: 7.708063411548949e-06\tLearning rate: 0.0009258541837518949\n",
      "episode: 77\tCurrent_score: 10.0\tAverage score: 8.038\tloss: 1.1010699272155762\tweighted_loss: 1.1010699272155762\teps: 0.1\tb_decay: 7.808167740375183e-06\tLearning rate: 0.0009249283295681431\n",
      "episode: 78\tCurrent_score: 14.0\tAverage score: 8.114\tloss: 1.0866117477416992\tweighted_loss: 1.0866117477416992\teps: 0.1\tb_decay: 7.908272059098387e-06\tLearning rate: 0.0009240034012385749\n",
      "episode: 79\tCurrent_score: 12.0\tAverage score: 8.162\tloss: 1.28127920627594\tweighted_loss: 1.28127920627594\teps: 0.1\tb_decay: 8.008376367940606e-06\tLearning rate: 0.0009230793978373363\n",
      "episode: 80\tCurrent_score: 18.0\tAverage score: 8.284\tloss: 1.1891669034957886\tweighted_loss: 1.1891669034957886\teps: 0.1\tb_decay: 8.108480666679796e-06\tLearning rate: 0.0009221563184394989\n",
      "episode: 81\tCurrent_score: 11.0\tAverage score: 8.317\tloss: 1.1433345079421997\tweighted_loss: 1.1433345079421997\teps: 0.1\tb_decay: 8.208584955315956e-06\tLearning rate: 0.0009212341621210594\n",
      "episode: 82\tCurrent_score: 15.0\tAverage score: 8.398\tloss: 1.0991616249084473\tweighted_loss: 1.0991616249084473\teps: 0.1\tb_decay: 8.308689234071132e-06\tLearning rate: 0.0009203129279589383\n",
      "episode: 83\tCurrent_score: 5.0\tAverage score: 8.357\tloss: 1.2665858268737793\tweighted_loss: 1.2665858268737793\teps: 0.1\tb_decay: 8.408793502723277e-06\tLearning rate: 0.0009193926150309794\n",
      "episode: 84\tCurrent_score: 10.0\tAverage score: 8.376\tloss: 1.1110987663269043\tweighted_loss: 1.1110987663269043\teps: 0.1\tb_decay: 8.508897761383416e-06\tLearning rate: 0.0009184732224159483\n",
      "episode: 85\tCurrent_score: 4.0\tAverage score: 8.326\tloss: 1.3306015729904175\tweighted_loss: 1.3306015729904175\teps: 0.1\tb_decay: 8.609002010051547e-06\tLearning rate: 0.0009175547491935324\n",
      "episode: 86\tCurrent_score: 9.0\tAverage score: 8.333\tloss: 1.0359764099121094\tweighted_loss: 1.0359764099121094\teps: 0.1\tb_decay: 8.709106248727672e-06\tLearning rate: 0.0009166371944443389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 87\tCurrent_score: 12.0\tAverage score: 8.375\tloss: 1.280084252357483\tweighted_loss: 1.280084252357483\teps: 0.1\tb_decay: 8.809210477300766e-06\tLearning rate: 0.0009157205572498945\n",
      "episode: 88\tCurrent_score: 13.0\tAverage score: 8.427\tloss: 1.4308832883834839\tweighted_loss: 1.4308832883834839\teps: 0.1\tb_decay: 8.909314695881854e-06\tLearning rate: 0.0009148048366926446\n",
      "episode: 89\tCurrent_score: 2.0\tAverage score: 8.356\tloss: 1.2428315877914429\tweighted_loss: 1.2428315877914429\teps: 0.1\tb_decay: 9.009418904470934e-06\tLearning rate: 0.000913890031855952\n",
      "episode: 90\tCurrent_score: 17.0\tAverage score: 8.451\tloss: 1.1793500185012817\tweighted_loss: 1.1793500185012817\teps: 0.1\tb_decay: 9.109523102956985e-06\tLearning rate: 0.000912976141824096\n",
      "episode: 91\tCurrent_score: 15.0\tAverage score: 8.522\tloss: 1.3036915063858032\tweighted_loss: 1.3036915063858032\teps: 0.1\tb_decay: 9.209627291451028e-06\tLearning rate: 0.0009120631656822719\n",
      "episode: 92\tCurrent_score: 13.0\tAverage score: 8.57\tloss: 1.522406816482544\tweighted_loss: 1.522406816482544\teps: 0.1\tb_decay: 9.309731469953064e-06\tLearning rate: 0.0009111511025165896\n",
      "episode: 93\tCurrent_score: 10.0\tAverage score: 8.585\tloss: 1.1412771940231323\tweighted_loss: 1.1412771940231323\teps: 0.1\tb_decay: 9.409835638463093e-06\tLearning rate: 0.000910239951414073\n",
      "episode: 94\tCurrent_score: 12.0\tAverage score: 8.621\tloss: 1.1879513263702393\tweighted_loss: 1.1879513263702393\teps: 0.1\tb_decay: 9.509939796870093e-06\tLearning rate: 0.0009093297114626589\n",
      "episode: 95\tCurrent_score: 12.0\tAverage score: 8.656\tloss: 1.7061116695404053\tweighted_loss: 1.7061116695404053\teps: 0.1\tb_decay: 9.610043945396107e-06\tLearning rate: 0.0009084203817511963\n",
      "episode: 96\tCurrent_score: 11.0\tAverage score: 8.68\tloss: 1.3932464122772217\tweighted_loss: 1.3932464122772217\teps: 0.1\tb_decay: 9.710148083819092e-06\tLearning rate: 0.000907511961369445\n",
      "episode: 97\tCurrent_score: 13.0\tAverage score: 8.724\tloss: 1.1577011346817017\tweighted_loss: 1.1577011346817017\teps: 0.1\tb_decay: 9.810252212139048e-06\tLearning rate: 0.0009066044494080756\n",
      "episode: 98\tCurrent_score: 10.0\tAverage score: 8.737\tloss: 1.5660101175308228\tweighted_loss: 1.5660101175308228\teps: 0.1\tb_decay: 9.910356330578018e-06\tLearning rate: 0.0009056978449586675\n",
      "episode: 99\tCurrent_score: 12.0\tAverage score: 8.77\tloss: 1.1636903285980225\tweighted_loss: 1.1636903285980225\teps: 0.1\tb_decay: 1.001046043891396e-05\tLearning rate: 0.0009047921471137089\n",
      "episode: 100\tCurrent_score: 14.0\tAverage score: 8.9\tloss: 1.8077900409698486\tweighted_loss: 1.8077900409698486\teps: 0.1\tb_decay: 1.0110564537257893e-05\tLearning rate: 0.0009038873549665952\n",
      "episode: 101\tCurrent_score: 10.0\tAverage score: 8.99\tloss: 1.1255338191986084\tweighted_loss: 1.1255338191986084\teps: 0.1\tb_decay: 1.0210668625498798e-05\tLearning rate: 0.0009029834676116286\n",
      "episode: 102\tCurrent_score: 12.0\tAverage score: 9.11\tloss: 1.1677474975585938\tweighted_loss: 1.1677474975585938\teps: 0.1\tb_decay: 1.0310772703858717e-05\tLearning rate: 0.000902080484144017\n",
      "episode: 103\tCurrent_score: 11.0\tAverage score: 9.2\tloss: 1.5312491655349731\tweighted_loss: 1.5312491655349731\teps: 0.1\tb_decay: 1.0410876772115607e-05\tLearning rate: 0.000901178403659873\n",
      "episode: 104\tCurrent_score: 13.0\tAverage score: 9.32\tloss: 1.1927151679992676\tweighted_loss: 1.1927151679992676\teps: 0.1\tb_decay: 1.051098083038049e-05\tLearning rate: 0.0009002772252562131\n",
      "episode: 105\tCurrent_score: 6.0\tAverage score: 9.37\tloss: 1.5037107467651367\tweighted_loss: 1.5037107467651367\teps: 0.1\tb_decay: 1.0611084878542343e-05\tLearning rate: 0.0008993769480309569\n",
      "episode: 106\tCurrent_score: 15.0\tAverage score: 9.49\tloss: 1.414069652557373\tweighted_loss: 1.414069652557373\teps: 0.1\tb_decay: 1.0711188916712189e-05\tLearning rate: 0.0008984775710829259\n",
      "episode: 107\tCurrent_score: 8.0\tAverage score: 9.56\tloss: 1.2752338647842407\tweighted_loss: 1.2752338647842407\teps: 0.1\tb_decay: 1.0811292944890027e-05\tLearning rate: 0.000897579093511843\n",
      "episode: 108\tCurrent_score: 6.0\tAverage score: 9.6\tloss: 1.4029810428619385\tweighted_loss: 1.4029810428619385\teps: 0.1\tb_decay: 1.0911396963075859e-05\tLearning rate: 0.0008966815144183311\n",
      "episode: 109\tCurrent_score: 12.0\tAverage score: 9.68\tloss: 1.6304258108139038\tweighted_loss: 1.6304258108139038\teps: 0.1\tb_decay: 1.1011500971269683e-05\tLearning rate: 0.0008957848329039128\n",
      "episode: 110\tCurrent_score: 8.0\tAverage score: 9.75\tloss: 1.3585073947906494\tweighted_loss: 1.3585073947906494\teps: 0.1\tb_decay: 1.1111604969360478e-05\tLearning rate: 0.0008948890480710088\n",
      "episode: 111\tCurrent_score: 10.0\tAverage score: 9.82\tloss: 1.2460857629776\tweighted_loss: 1.2460857629776\teps: 0.1\tb_decay: 1.1211708957459265e-05\tLearning rate: 0.0008939941590229378\n",
      "episode: 112\tCurrent_score: 13.0\tAverage score: 9.88\tloss: 2.233048439025879\tweighted_loss: 2.233048439025879\teps: 0.1\tb_decay: 1.1311812935566046e-05\tLearning rate: 0.0008931001648639148\n",
      "episode: 113\tCurrent_score: 15.0\tAverage score: 10.0\tloss: 1.471747875213623\tweighted_loss: 1.471747875213623\teps: 0.1\tb_decay: 1.1411916903569796e-05\tLearning rate: 0.0008922070646990509\n",
      "episode: 114\tCurrent_score: 16.0\tAverage score: 10.14\tloss: 1.6134285926818848\tweighted_loss: 1.6134285926818848\teps: 0.1\tb_decay: 1.1512020861692562e-05\tLearning rate: 0.0008913148576343518\n",
      "episode: 115\tCurrent_score: 13.0\tAverage score: 10.2\tloss: 1.2407135963439941\tweighted_loss: 1.2407135963439941\teps: 0.1\tb_decay: 1.1612124809601276e-05\tLearning rate: 0.0008904235427767174\n",
      "episode: 116\tCurrent_score: 5.0\tAverage score: 10.16\tloss: 1.980042576789856\tweighted_loss: 1.980042576789856\teps: 0.1\tb_decay: 1.1712228747629005e-05\tLearning rate: 0.0008895331192339407\n",
      "episode: 117\tCurrent_score: 3.0\tAverage score: 10.12\tloss: 1.5300372838974\tweighted_loss: 1.5300372838974\teps: 0.1\tb_decay: 1.1812332675664727e-05\tLearning rate: 0.0008886435861147067\n",
      "episode: 118\tCurrent_score: 8.0\tAverage score: 10.1\tloss: 1.4189214706420898\tweighted_loss: 1.4189214706420898\teps: 0.1\tb_decay: 1.191243659359742e-05\tLearning rate: 0.000887754942528592\n",
      "episode: 119\tCurrent_score: 17.0\tAverage score: 10.23\tloss: 1.491323471069336\tweighted_loss: 1.491323471069336\teps: 0.1\tb_decay: 1.2012540501538105e-05\tLearning rate: 0.0008868671875860634\n",
      "episode: 120\tCurrent_score: 10.0\tAverage score: 10.21\tloss: 1.785274863243103\tweighted_loss: 1.785274863243103\teps: 0.1\tb_decay: 1.211264439937576e-05\tLearning rate: 0.0008859803203984774\n",
      "episode: 121\tCurrent_score: 7.0\tAverage score: 10.25\tloss: 2.2156970500946045\tweighted_loss: 2.2156970500946045\teps: 0.1\tb_decay: 1.2212748287332431e-05\tLearning rate: 0.0008850943400780789\n",
      "episode: 122\tCurrent_score: 12.0\tAverage score: 10.32\tloss: 1.726280927658081\tweighted_loss: 1.726280927658081\teps: 0.1\tb_decay: 1.2312852165186072e-05\tLearning rate: 0.0008842092457380008\n",
      "episode: 123\tCurrent_score: 8.0\tAverage score: 10.31\tloss: 1.4491029977798462\tweighted_loss: 1.4491029977798462\teps: 0.1\tb_decay: 1.2412956033047706e-05\tLearning rate: 0.0008833250364922628\n",
      "episode: 124\tCurrent_score: 11.0\tAverage score: 10.36\tloss: 2.0108022689819336\tweighted_loss: 2.0108022689819336\teps: 0.1\tb_decay: 1.251305989080631e-05\tLearning rate: 0.0008824417114557706\n",
      "episode: 125\tCurrent_score: 12.0\tAverage score: 10.39\tloss: 1.6188918352127075\tweighted_loss: 1.6188918352127075\teps: 0.1\tb_decay: 1.261316373868393e-05\tLearning rate: 0.0008815592697443149\n",
      "episode: 126\tCurrent_score: 11.0\tAverage score: 10.4\tloss: 1.6502790451049805\tweighted_loss: 1.6502790451049805\teps: 0.1\tb_decay: 1.271326757645852e-05\tLearning rate: 0.0008806777104745705\n",
      "episode: 127\tCurrent_score: 5.0\tAverage score: 10.32\tloss: 1.86948561668396\tweighted_loss: 1.86948561668396\teps: 0.1\tb_decay: 1.2813371404241103e-05\tLearning rate: 0.000879797032764096\n",
      "episode: 128\tCurrent_score: 14.0\tAverage score: 10.31\tloss: 1.7024614810943604\tweighted_loss: 1.7024614810943604\teps: 0.1\tb_decay: 1.2913475221920656e-05\tLearning rate: 0.0008789172357313319\n",
      "episode: 129\tCurrent_score: 8.0\tAverage score: 10.3\tloss: 1.7546510696411133\tweighted_loss: 1.7546510696411133\teps: 0.1\tb_decay: 1.3013579029719224e-05\tLearning rate: 0.0008780383184956006\n",
      "episode: 130\tCurrent_score: 9.0\tAverage score: 10.31\tloss: 1.5611016750335693\tweighted_loss: 1.5611016750335693\teps: 0.1\tb_decay: 1.3113682827414763e-05\tLearning rate: 0.000877160280177105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 131\tCurrent_score: 12.0\tAverage score: 10.31\tloss: 1.53775954246521\tweighted_loss: 1.53775954246521\teps: 0.1\tb_decay: 1.3213786615118295e-05\tLearning rate: 0.0008762831198969279\n",
      "episode: 132\tCurrent_score: 3.0\tAverage score: 10.22\tloss: 2.2185890674591064\tweighted_loss: 2.2185890674591064\teps: 0.1\tb_decay: 1.3313890392718797e-05\tLearning rate: 0.000875406836777031\n",
      "episode: 133\tCurrent_score: 13.0\tAverage score: 10.28\tloss: 1.8494389057159424\tweighted_loss: 1.8494389057159424\teps: 0.1\tb_decay: 1.3413994160327292e-05\tLearning rate: 0.000874531429940254\n",
      "episode: 134\tCurrent_score: 12.0\tAverage score: 10.32\tloss: 1.6211614608764648\tweighted_loss: 1.6211614608764648\teps: 0.1\tb_decay: 1.351409791794378e-05\tLearning rate: 0.0008736568985103137\n",
      "episode: 135\tCurrent_score: 16.0\tAverage score: 10.42\tloss: 1.8883512020111084\tweighted_loss: 1.8883512020111084\teps: 0.1\tb_decay: 1.361420166556826e-05\tLearning rate: 0.0008727832416118034\n",
      "episode: 136\tCurrent_score: 11.0\tAverage score: 10.46\tloss: 1.7523661851882935\tweighted_loss: 1.7523661851882935\teps: 0.1\tb_decay: 1.3714305403200733e-05\tLearning rate: 0.0008719104583701916\n",
      "episode: 137\tCurrent_score: 8.0\tAverage score: 10.44\tloss: 1.448108434677124\tweighted_loss: 1.448108434677124\teps: 0.1\tb_decay: 1.3814409130730176e-05\tLearning rate: 0.0008710385479118214\n",
      "episode: 138\tCurrent_score: 10.0\tAverage score: 10.53\tloss: 1.4993414878845215\tweighted_loss: 1.4993414878845215\teps: 0.1\tb_decay: 1.3914512848267613e-05\tLearning rate: 0.0008701675093639096\n",
      "episode: 139\tCurrent_score: 8.0\tAverage score: 10.47\tloss: 1.6232569217681885\tweighted_loss: 1.6232569217681885\teps: 0.1\tb_decay: 1.4014616555813042e-05\tLearning rate: 0.0008692973418545456\n",
      "episode: 140\tCurrent_score: 7.0\tAverage score: 10.42\tloss: 1.7771331071853638\tweighted_loss: 1.7771331071853638\teps: 0.1\tb_decay: 1.4114720253255442e-05\tLearning rate: 0.0008684280445126911\n",
      "episode: 141\tCurrent_score: 13.0\tAverage score: 10.52\tloss: 1.6733988523483276\tweighted_loss: 1.6733988523483276\teps: 0.1\tb_decay: 1.4214823940705834e-05\tLearning rate: 0.0008675596164681784\n",
      "episode: 142\tCurrent_score: 9.0\tAverage score: 10.51\tloss: 1.5973623991012573\tweighted_loss: 1.5973623991012573\teps: 0.1\tb_decay: 1.431492761816422e-05\tLearning rate: 0.0008666920568517103\n",
      "episode: 143\tCurrent_score: 15.0\tAverage score: 10.52\tloss: 1.4061552286148071\tweighted_loss: 1.4061552286148071\teps: 0.1\tb_decay: 1.4415031285630597e-05\tLearning rate: 0.0008658253647948586\n",
      "episode: 144\tCurrent_score: 14.0\tAverage score: 10.58\tloss: 1.8040485382080078\tweighted_loss: 1.8040485382080078\teps: 0.1\tb_decay: 1.4515134942993946e-05\tLearning rate: 0.0008649595394300638\n",
      "episode: 145\tCurrent_score: 11.0\tAverage score: 10.58\tloss: 1.6171764135360718\tweighted_loss: 1.6171764135360718\teps: 0.1\tb_decay: 1.461523859047631e-05\tLearning rate: 0.0008640945798906337\n",
      "episode: 146\tCurrent_score: 16.0\tAverage score: 10.62\tloss: 1.6319835186004639\tweighted_loss: 1.6319835186004639\teps: 0.1\tb_decay: 1.4715342227744621e-05\tLearning rate: 0.0008632304853107431\n",
      "episode: 147\tCurrent_score: 8.0\tAverage score: 10.57\tloss: 2.123798131942749\tweighted_loss: 2.123798131942749\teps: 0.1\tb_decay: 1.4815445855131948e-05\tLearning rate: 0.0008623672548254323\n",
      "episode: 148\tCurrent_score: 9.0\tAverage score: 10.58\tloss: 1.914490818977356\tweighted_loss: 1.914490818977356\teps: 0.1\tb_decay: 1.4915549472416245e-05\tLearning rate: 0.0008615048875706069\n",
      "episode: 149\tCurrent_score: 16.0\tAverage score: 10.6\tloss: 1.7450954914093018\tweighted_loss: 1.7450954914093018\teps: 0.1\tb_decay: 1.5015653079819558e-05\tLearning rate: 0.0008606433826830363\n",
      "episode: 150\tCurrent_score: 4.0\tAverage score: 10.55\tloss: 1.6901137828826904\tweighted_loss: 1.6901137828826904\teps: 0.1\tb_decay: 1.5115756677008818e-05\tLearning rate: 0.0008597827393003533\n",
      "episode: 151\tCurrent_score: 10.0\tAverage score: 10.6\tloss: 1.4572199583053589\tweighted_loss: 1.4572199583053589\teps: 0.1\tb_decay: 1.5215860264317094e-05\tLearning rate: 0.0008589229565610529\n",
      "episode: 152\tCurrent_score: 15.0\tAverage score: 10.68\tloss: 1.7731364965438843\tweighted_loss: 1.7731364965438843\teps: 0.1\tb_decay: 1.531596384152234e-05\tLearning rate: 0.0008580640336044919\n",
      "episode: 153\tCurrent_score: 13.0\tAverage score: 10.76\tloss: 2.152440309524536\tweighted_loss: 2.152440309524536\teps: 0.1\tb_decay: 1.541606740873558e-05\tLearning rate: 0.0008572059695708874\n",
      "episode: 154\tCurrent_score: 9.0\tAverage score: 10.75\tloss: 1.430395483970642\tweighted_loss: 1.430395483970642\teps: 0.1\tb_decay: 1.551617096595681e-05\tLearning rate: 0.0008563487636013166\n",
      "episode: 155\tCurrent_score: 12.0\tAverage score: 10.78\tloss: 1.2951271533966064\tweighted_loss: 1.2951271533966064\teps: 0.1\tb_decay: 1.5616274513186035e-05\tLearning rate: 0.0008554924148377152\n",
      "episode: 156\tCurrent_score: 10.0\tAverage score: 10.81\tloss: 1.9590895175933838\tweighted_loss: 1.9590895175933838\teps: 0.1\tb_decay: 1.571637805031223e-05\tLearning rate: 0.0008546369224228774\n",
      "episode: 157\tCurrent_score: 13.0\tAverage score: 10.81\tloss: 1.6940491199493408\tweighted_loss: 1.6940491199493408\teps: 0.1\tb_decay: 1.5816481577446417e-05\tLearning rate: 0.0008537822855004545\n",
      "episode: 158\tCurrent_score: 9.0\tAverage score: 10.79\tloss: 1.8839366436004639\tweighted_loss: 1.8839366436004639\teps: 0.1\tb_decay: 1.5916585094588598e-05\tLearning rate: 0.0008529285032149541\n",
      "episode: 159\tCurrent_score: 10.0\tAverage score: 10.81\tloss: 1.9851619005203247\tweighted_loss: 1.9851619005203247\teps: 0.1\tb_decay: 1.601668860162775e-05\tLearning rate: 0.0008520755747117391\n",
      "episode: 160\tCurrent_score: 13.0\tAverage score: 10.81\tloss: 1.866379976272583\tweighted_loss: 1.866379976272583\teps: 0.1\tb_decay: 1.6116792098785915e-05\tLearning rate: 0.0008512234991370274\n",
      "episode: 161\tCurrent_score: 16.0\tAverage score: 10.85\tloss: 2.116034984588623\tweighted_loss: 2.116034984588623\teps: 0.1\tb_decay: 1.621689558584105e-05\tLearning rate: 0.0008503722756378904\n",
      "episode: 162\tCurrent_score: 14.0\tAverage score: 10.89\tloss: 1.7615374326705933\tweighted_loss: 1.7615374326705933\teps: 0.1\tb_decay: 1.6316999062793158e-05\tLearning rate: 0.0008495219033622525\n",
      "episode: 163\tCurrent_score: 8.0\tAverage score: 10.85\tloss: 2.1030495166778564\tweighted_loss: 2.1030495166778564\teps: 0.1\tb_decay: 1.641710252986428e-05\tLearning rate: 0.0008486723814588903\n",
      "episode: 164\tCurrent_score: 13.0\tAverage score: 10.82\tloss: 2.1661322116851807\tweighted_loss: 2.1661322116851807\teps: 0.1\tb_decay: 1.6517205986832373e-05\tLearning rate: 0.0008478237090774314\n",
      "episode: 165\tCurrent_score: 18.0\tAverage score: 10.85\tloss: 1.937843680381775\tweighted_loss: 1.937843680381775\teps: 0.1\tb_decay: 1.6617309433808458e-05\tLearning rate: 0.000846975885368354\n",
      "episode: 166\tCurrent_score: 15.0\tAverage score: 10.91\tloss: 1.6532691717147827\tweighted_loss: 1.6532691717147827\teps: 0.1\tb_decay: 1.6717412870792536e-05\tLearning rate: 0.0008461289094829856\n",
      "episode: 167\tCurrent_score: 17.0\tAverage score: 10.91\tloss: 1.749518871307373\tweighted_loss: 1.749518871307373\teps: 0.1\tb_decay: 1.6817516297673585e-05\tLearning rate: 0.0008452827805735026\n",
      "episode: 168\tCurrent_score: 7.0\tAverage score: 10.88\tloss: 1.7756068706512451\tweighted_loss: 1.7756068706512451\teps: 0.1\tb_decay: 1.6917619714562626e-05\tLearning rate: 0.000844437497792929\n",
      "episode: 169\tCurrent_score: 10.0\tAverage score: 10.93\tloss: 2.0334677696228027\tweighted_loss: 2.0334677696228027\teps: 0.1\tb_decay: 1.701772312145966e-05\tLearning rate: 0.0008435930602951361\n",
      "episode: 170\tCurrent_score: 12.0\tAverage score: 10.89\tloss: 1.9930201768875122\tweighted_loss: 1.9930201768875122\teps: 0.1\tb_decay: 1.7117826518364687e-05\tLearning rate: 0.0008427494672348409\n",
      "episode: 171\tCurrent_score: 11.0\tAverage score: 10.93\tloss: 1.716484546661377\tweighted_loss: 1.716484546661377\teps: 0.1\tb_decay: 1.7217929905166685e-05\tLearning rate: 0.0008419067177676061\n",
      "episode: 172\tCurrent_score: 5.0\tAverage score: 10.88\tloss: 1.754725456237793\tweighted_loss: 1.754725456237793\teps: 0.1\tb_decay: 1.7318033282087697e-05\tLearning rate: 0.0008410648110498385\n",
      "episode: 173\tCurrent_score: 7.0\tAverage score: 10.94\tloss: 2.3548803329467773\tweighted_loss: 2.3548803329467773\teps: 0.1\tb_decay: 1.7418136648794658e-05\tLearning rate: 0.0008402237462387886\n",
      "episode: 174\tCurrent_score: 15.0\tAverage score: 11.01\tloss: 2.4129230976104736\tweighted_loss: 2.4129230976104736\teps: 0.1\tb_decay: 1.7518240005620633e-05\tLearning rate: 0.0008393835224925498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 175\tCurrent_score: 10.0\tAverage score: 10.99\tloss: 2.089629888534546\tweighted_loss: 2.089629888534546\teps: 0.1\tb_decay: 1.761834335234358e-05\tLearning rate: 0.0008385441389700573\n",
      "episode: 176\tCurrent_score: 15.0\tAverage score: 11.04\tloss: 1.9405968189239502\tweighted_loss: 1.9405968189239502\teps: 0.1\tb_decay: 1.771844668918554e-05\tLearning rate: 0.0008377055948310873\n",
      "episode: 177\tCurrent_score: 15.0\tAverage score: 11.09\tloss: 2.391235828399658\tweighted_loss: 2.391235828399658\teps: 0.1\tb_decay: 1.781855001581345e-05\tLearning rate: 0.0008368678892362562\n",
      "episode: 178\tCurrent_score: 14.0\tAverage score: 11.09\tloss: 1.790279507637024\tweighted_loss: 1.790279507637024\teps: 0.1\tb_decay: 1.7918653332560375e-05\tLearning rate: 0.00083603102134702\n",
      "episode: 179\tCurrent_score: 9.0\tAverage score: 11.06\tloss: 2.1762118339538574\tweighted_loss: 2.1762118339538574\teps: 0.1\tb_decay: 1.801875663920427e-05\tLearning rate: 0.000835194990325673\n",
      "episode: 180\tCurrent_score: 9.0\tAverage score: 10.97\tloss: 1.8947227001190186\tweighted_loss: 1.8947227001190186\teps: 0.1\tb_decay: 1.8118859935856158e-05\tLearning rate: 0.0008343597953353473\n",
      "episode: 181\tCurrent_score: 13.0\tAverage score: 10.99\tloss: 2.037583827972412\tweighted_loss: 2.037583827972412\teps: 0.1\tb_decay: 1.8218963222516038e-05\tLearning rate: 0.0008335254355400119\n",
      "episode: 182\tCurrent_score: 13.0\tAverage score: 10.97\tloss: 2.317516565322876\tweighted_loss: 2.317516565322876\teps: 0.1\tb_decay: 1.831906649918391e-05\tLearning rate: 0.0008326919101044719\n",
      "episode: 183\tCurrent_score: 9.0\tAverage score: 11.01\tloss: 1.8293869495391846\tweighted_loss: 1.8293869495391846\teps: 0.1\tb_decay: 1.8419169765748755e-05\tLearning rate: 0.0008318592181943674\n",
      "episode: 184\tCurrent_score: 14.0\tAverage score: 11.05\tloss: 1.8704439401626587\tweighted_loss: 1.8704439401626587\teps: 0.1\tb_decay: 1.8519273022321592e-05\tLearning rate: 0.000831027358976173\n",
      "episode: 185\tCurrent_score: 10.0\tAverage score: 11.11\tloss: 2.355958938598633\tweighted_loss: 2.355958938598633\teps: 0.1\tb_decay: 1.861937626890242e-05\tLearning rate: 0.0008301963316171969\n",
      "episode: 186\tCurrent_score: 12.0\tAverage score: 11.14\tloss: 3.014108896255493\tweighted_loss: 3.014108896255493\teps: 0.1\tb_decay: 1.871947950538022e-05\tLearning rate: 0.0008293661352855797\n",
      "episode: 187\tCurrent_score: 7.0\tAverage score: 11.09\tloss: 2.174987554550171\tweighted_loss: 2.174987554550171\teps: 0.1\tb_decay: 1.8819582731977036e-05\tLearning rate: 0.0008285367691502942\n",
      "episode: 188\tCurrent_score: 13.0\tAverage score: 11.09\tloss: 1.8675956726074219\tweighted_loss: 1.8675956726074219\teps: 0.1\tb_decay: 1.89196859483598e-05\tLearning rate: 0.0008277082323811439\n",
      "episode: 189\tCurrent_score: 9.0\tAverage score: 11.16\tloss: 2.612746000289917\tweighted_loss: 2.612746000289917\teps: 0.1\tb_decay: 1.9019789154861577e-05\tLearning rate: 0.0008268805241487627\n",
      "episode: 190\tCurrent_score: 19.0\tAverage score: 11.18\tloss: 2.1411869525909424\tweighted_loss: 2.1411869525909424\teps: 0.1\tb_decay: 1.9119892351371348e-05\tLearning rate: 0.0008260536436246139\n",
      "episode: 191\tCurrent_score: 14.0\tAverage score: 11.17\tloss: 1.9778361320495605\tweighted_loss: 1.9778361320495605\teps: 0.1\tb_decay: 1.921999553777809e-05\tLearning rate: 0.0008252275899809893\n",
      "episode: 192\tCurrent_score: 9.0\tAverage score: 11.13\tloss: 2.0928027629852295\tweighted_loss: 2.0928027629852295\teps: 0.1\tb_decay: 1.9320098714192824e-05\tLearning rate: 0.0008244023623910083\n",
      "episode: 193\tCurrent_score: 13.0\tAverage score: 11.16\tloss: 2.1749298572540283\tweighted_loss: 2.1749298572540283\teps: 0.1\tb_decay: 1.942020188061555e-05\tLearning rate: 0.0008235779600286173\n",
      "episode: 194\tCurrent_score: 15.0\tAverage score: 11.19\tloss: 1.6595823764801025\tweighted_loss: 1.6595823764801025\teps: 0.1\tb_decay: 1.9520305036935248e-05\tLearning rate: 0.0008227543820685887\n",
      "episode: 195\tCurrent_score: 16.0\tAverage score: 11.23\tloss: 1.639406442642212\tweighted_loss: 1.639406442642212\teps: 0.1\tb_decay: 1.962040818326294e-05\tLearning rate: 0.0008219316276865201\n",
      "episode: 196\tCurrent_score: 11.0\tAverage score: 11.23\tloss: 2.311208963394165\tweighted_loss: 2.311208963394165\teps: 0.1\tb_decay: 1.972051131959862e-05\tLearning rate: 0.0008211096960588336\n",
      "episode: 197\tCurrent_score: 9.0\tAverage score: 11.19\tloss: 1.9507402181625366\tweighted_loss: 1.9507402181625366\teps: 0.1\tb_decay: 1.9820614445942297e-05\tLearning rate: 0.0008202885863627748\n",
      "episode: 198\tCurrent_score: 5.0\tAverage score: 11.14\tloss: 2.2418320178985596\tweighted_loss: 2.2418320178985596\teps: 0.1\tb_decay: 1.9920717562182944e-05\tLearning rate: 0.000819468297776412\n",
      "episode: 199\tCurrent_score: 9.0\tAverage score: 11.11\tloss: 2.422208547592163\tweighted_loss: 2.422208547592163\teps: 0.1\tb_decay: 2.0020820668431583e-05\tLearning rate: 0.0008186488294786356\n",
      "episode: 200\tCurrent_score: 17.0\tAverage score: 11.14\tloss: 1.9074064493179321\tweighted_loss: 1.9074064493179321\teps: 0.1\tb_decay: 2.0120923764688214e-05\tLearning rate: 0.000817830180649157\n",
      "episode: 201\tCurrent_score: 13.0\tAverage score: 11.17\tloss: 2.236865520477295\tweighted_loss: 2.236865520477295\teps: 0.1\tb_decay: 2.022102685095284e-05\tLearning rate: 0.0008170123504685078\n",
      "episode: 202\tCurrent_score: 13.0\tAverage score: 11.18\tloss: 2.0372486114501953\tweighted_loss: 2.0372486114501953\teps: 0.1\tb_decay: 2.0321129927114434e-05\tLearning rate: 0.0008161953381180393\n",
      "episode: 203\tCurrent_score: 12.0\tAverage score: 11.19\tloss: 2.8226804733276367\tweighted_loss: 2.8226804733276367\teps: 0.1\tb_decay: 2.0421232993284022e-05\tLearning rate: 0.0008153791427799213\n",
      "episode: 204\tCurrent_score: 12.0\tAverage score: 11.18\tloss: 1.9472455978393555\tweighted_loss: 1.9472455978393555\teps: 0.1\tb_decay: 2.0521336049461603e-05\tLearning rate: 0.0008145637636371414\n",
      "episode: 205\tCurrent_score: 10.0\tAverage score: 11.22\tloss: 2.185296058654785\tweighted_loss: 2.185296058654785\teps: 0.1\tb_decay: 2.0621439095536154e-05\tLearning rate: 0.0008137491998735043\n",
      "episode: 206\tCurrent_score: 12.0\tAverage score: 11.19\tloss: 1.8315868377685547\tweighted_loss: 1.8315868377685547\teps: 0.1\tb_decay: 2.072154213172972e-05\tLearning rate: 0.0008129354506736308\n",
      "episode: 207\tCurrent_score: 10.0\tAverage score: 11.21\tloss: 2.06524395942688\tweighted_loss: 2.06524395942688\teps: 0.1\tb_decay: 2.0821645157820257e-05\tLearning rate: 0.0008121225152229572\n",
      "episode: 208\tCurrent_score: 12.0\tAverage score: 11.27\tloss: 2.1283695697784424\tweighted_loss: 2.1283695697784424\teps: 0.1\tb_decay: 2.0921748173918786e-05\tLearning rate: 0.0008113103927077342\n",
      "episode: 209\tCurrent_score: 15.0\tAverage score: 11.3\tloss: 2.8064706325531006\tweighted_loss: 2.8064706325531006\teps: 0.1\tb_decay: 2.1021851179914286e-05\tLearning rate: 0.0008104990823150264\n",
      "episode: 210\tCurrent_score: 11.0\tAverage score: 11.33\tloss: 2.083357095718384\tweighted_loss: 2.083357095718384\teps: 0.1\tb_decay: 2.112195417591778e-05\tLearning rate: 0.0008096885832327114\n",
      "episode: 211\tCurrent_score: 14.0\tAverage score: 11.37\tloss: 1.9633641242980957\tweighted_loss: 1.9633641242980957\teps: 0.1\tb_decay: 2.1222057161929264e-05\tLearning rate: 0.0008088788946494787\n",
      "episode: 212\tCurrent_score: 14.0\tAverage score: 11.38\tloss: 2.1300995349884033\tweighted_loss: 2.1300995349884033\teps: 0.1\tb_decay: 2.1322160137948742e-05\tLearning rate: 0.0008080700157548292\n",
      "episode: 213\tCurrent_score: 15.0\tAverage score: 11.38\tloss: 1.7512179613113403\tweighted_loss: 1.7512179613113403\teps: 0.1\tb_decay: 2.1422263103976213e-05\tLearning rate: 0.0008072619457390744\n",
      "episode: 214\tCurrent_score: 8.0\tAverage score: 11.3\tloss: 3.1366770267486572\tweighted_loss: 3.1366770267486572\teps: 0.1\tb_decay: 2.1522366059900655e-05\tLearning rate: 0.0008064546837933353\n",
      "episode: 215\tCurrent_score: 16.0\tAverage score: 11.33\tloss: 2.5480496883392334\tweighted_loss: 2.5480496883392334\teps: 0.1\tb_decay: 2.162246900583309e-05\tLearning rate: 0.000805648229109542\n",
      "episode: 216\tCurrent_score: 18.0\tAverage score: 11.46\tloss: 2.590139389038086\tweighted_loss: 2.590139389038086\teps: 0.1\tb_decay: 2.1722571941773516e-05\tLearning rate: 0.0008048425808804324\n",
      "episode: 217\tCurrent_score: 9.0\tAverage score: 11.52\tloss: 1.5999494791030884\tweighted_loss: 1.5999494791030884\teps: 0.1\tb_decay: 2.1822674867610914e-05\tLearning rate: 0.0008040377382995519\n",
      "episode: 218\tCurrent_score: 7.0\tAverage score: 11.51\tloss: 1.750377893447876\tweighted_loss: 1.750377893447876\teps: 0.1\tb_decay: 2.1922777783456304e-05\tLearning rate: 0.0008032337005612523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 219\tCurrent_score: 11.0\tAverage score: 11.45\tloss: 2.0900073051452637\tweighted_loss: 2.0900073051452637\teps: 0.1\tb_decay: 2.2022880689309687e-05\tLearning rate: 0.0008024304668606911\n",
      "episode: 220\tCurrent_score: 11.0\tAverage score: 11.46\tloss: 2.212153911590576\tweighted_loss: 2.212153911590576\teps: 0.1\tb_decay: 2.2122983585171063e-05\tLearning rate: 0.0008016280363938304\n",
      "episode: 221\tCurrent_score: 11.0\tAverage score: 11.5\tloss: 1.6552040576934814\tweighted_loss: 1.6552040576934814\teps: 0.1\tb_decay: 2.222308647092941e-05\tLearning rate: 0.0008008264083574365\n",
      "episode: 222\tCurrent_score: 12.0\tAverage score: 11.5\tloss: 1.9566234350204468\tweighted_loss: 1.9566234350204468\teps: 0.1\tb_decay: 2.232318934669575e-05\tLearning rate: 0.0008000255819490791\n",
      "episode: 223\tCurrent_score: 9.0\tAverage score: 11.51\tloss: 2.3991317749023438\tweighted_loss: 2.3991317749023438\teps: 0.1\tb_decay: 2.242329221247008e-05\tLearning rate: 0.00079922555636713\n",
      "episode: 224\tCurrent_score: 12.0\tAverage score: 11.52\tloss: 2.2346320152282715\tweighted_loss: 2.2346320152282715\teps: 0.1\tb_decay: 2.2523395068252405e-05\tLearning rate: 0.0007984263308107629\n",
      "episode: 225\tCurrent_score: 11.0\tAverage score: 11.51\tloss: 2.3604679107666016\tweighted_loss: 2.3604679107666016\teps: 0.1\tb_decay: 2.26234979139317e-05\tLearning rate: 0.0007976279044799521\n",
      "episode: 226\tCurrent_score: 12.0\tAverage score: 11.52\tloss: 2.8567938804626465\tweighted_loss: 2.8567938804626465\teps: 0.1\tb_decay: 2.272360074973001e-05\tLearning rate: 0.0007968302765754722\n",
      "episode: 227\tCurrent_score: 7.0\tAverage score: 11.54\tloss: 1.91939377784729\tweighted_loss: 1.91939377784729\teps: 0.1\tb_decay: 2.282370357531427e-05\tLearning rate: 0.0007960334462988967\n",
      "episode: 228\tCurrent_score: 10.0\tAverage score: 11.5\tloss: 2.7525179386138916\tweighted_loss: 2.7525179386138916\teps: 0.1\tb_decay: 2.2923806391017543e-05\tLearning rate: 0.0007952374128525979\n",
      "episode: 229\tCurrent_score: 15.0\tAverage score: 11.57\tloss: 1.8364812135696411\tweighted_loss: 1.8364812135696411\teps: 0.1\tb_decay: 2.3023909196617787e-05\tLearning rate: 0.0007944421754397453\n",
      "episode: 230\tCurrent_score: 7.0\tAverage score: 11.55\tloss: 1.3300435543060303\tweighted_loss: 1.3300435543060303\teps: 0.1\tb_decay: 2.3124011992226023e-05\tLearning rate: 0.0007936477332643056\n",
      "episode: 231\tCurrent_score: 13.0\tAverage score: 11.56\tloss: 2.379971742630005\tweighted_loss: 2.379971742630005\teps: 0.1\tb_decay: 2.3224114777842253e-05\tLearning rate: 0.0007928540855310413\n",
      "episode: 232\tCurrent_score: 18.0\tAverage score: 11.71\tloss: 2.6330482959747314\tweighted_loss: 2.6330482959747314\teps: 0.1\tb_decay: 2.3324217553466475e-05\tLearning rate: 0.0007920612314455103\n",
      "episode: 233\tCurrent_score: 13.0\tAverage score: 11.71\tloss: 2.705533504486084\tweighted_loss: 2.705533504486084\teps: 0.1\tb_decay: 2.3424320318987668e-05\tLearning rate: 0.0007912691702140648\n",
      "episode: 234\tCurrent_score: 14.0\tAverage score: 11.73\tloss: 2.3730833530426025\tweighted_loss: 2.3730833530426025\teps: 0.1\tb_decay: 2.3524423074516854e-05\tLearning rate: 0.0007904779010438507\n",
      "episode: 235\tCurrent_score: 13.0\tAverage score: 11.7\tloss: 2.022243022918701\tweighted_loss: 2.022243022918701\teps: 0.1\tb_decay: 2.3624525820054032e-05\tLearning rate: 0.0007896874231428068\n",
      "episode: 236\tCurrent_score: 11.0\tAverage score: 11.7\tloss: 1.765943169593811\tweighted_loss: 1.765943169593811\teps: 0.1\tb_decay: 2.372462855548818e-05\tLearning rate: 0.000788897735719664\n",
      "episode: 237\tCurrent_score: 14.0\tAverage score: 11.76\tloss: 2.129606008529663\tweighted_loss: 2.129606008529663\teps: 0.1\tb_decay: 2.3824731281041345e-05\tLearning rate: 0.0007881088379839443\n",
      "episode: 238\tCurrent_score: 4.0\tAverage score: 11.7\tloss: 2.0224673748016357\tweighted_loss: 2.0224673748016357\teps: 0.1\tb_decay: 2.392483399649148e-05\tLearning rate: 0.0007873207291459604\n",
      "episode: 239\tCurrent_score: 10.0\tAverage score: 11.72\tloss: 2.4919610023498535\tweighted_loss: 2.4919610023498535\teps: 0.1\tb_decay: 2.4024936701949606e-05\tLearning rate: 0.0007865334084168144\n",
      "episode: 240\tCurrent_score: 6.0\tAverage score: 11.71\tloss: 1.9686039686203003\tweighted_loss: 1.9686039686203003\teps: 0.1\tb_decay: 2.4125039397304704e-05\tLearning rate: 0.0007857468750083976\n",
      "episode: 241\tCurrent_score: 12.0\tAverage score: 11.7\tloss: 3.0627450942993164\tweighted_loss: 3.0627450942993164\teps: 0.1\tb_decay: 2.4225142082667794e-05\tLearning rate: 0.0007849611281333892\n",
      "episode: 242\tCurrent_score: 8.0\tAverage score: 11.69\tloss: 2.3078346252441406\tweighted_loss: 2.3078346252441406\teps: 0.1\tb_decay: 2.4325244758038878e-05\tLearning rate: 0.0007841761670052559\n",
      "episode: 243\tCurrent_score: 13.0\tAverage score: 11.67\tloss: 2.975710153579712\tweighted_loss: 2.975710153579712\teps: 0.1\tb_decay: 2.4425347423417954e-05\tLearning rate: 0.0007833919908382507\n",
      "episode: 244\tCurrent_score: 14.0\tAverage score: 11.67\tloss: 2.6048758029937744\tweighted_loss: 2.6048758029937744\teps: 0.1\tb_decay: 2.4525450078694e-05\tLearning rate: 0.0007826085988474124\n",
      "episode: 245\tCurrent_score: 10.0\tAverage score: 11.66\tloss: 2.4079108238220215\tweighted_loss: 2.4079108238220215\teps: 0.1\tb_decay: 2.462555272408906e-05\tLearning rate: 0.000781825990248565\n",
      "episode: 246\tCurrent_score: 15.0\tAverage score: 11.65\tloss: 2.277939796447754\tweighted_loss: 2.277939796447754\teps: 0.1\tb_decay: 2.472565535927007e-05\tLearning rate: 0.0007810441642583164\n",
      "episode: 247\tCurrent_score: 16.0\tAverage score: 11.73\tloss: 2.114335060119629\tweighted_loss: 2.114335060119629\teps: 0.1\tb_decay: 2.4825757984570096e-05\tLearning rate: 0.0007802631200940581\n",
      "episode: 248\tCurrent_score: 15.0\tAverage score: 11.79\tloss: 2.5663347244262695\tweighted_loss: 2.5663347244262695\teps: 0.1\tb_decay: 2.4925860599878114e-05\tLearning rate: 0.000779482856973964\n",
      "episode: 249\tCurrent_score: 15.0\tAverage score: 11.78\tloss: 2.266275644302368\tweighted_loss: 2.266275644302368\teps: 0.1\tb_decay: 2.50259632050831e-05\tLearning rate: 0.00077870337411699\n",
      "episode: 250\tCurrent_score: 14.0\tAverage score: 11.88\tloss: 3.043459177017212\tweighted_loss: 3.043459177017212\teps: 0.1\tb_decay: 2.5126065800296082e-05\tLearning rate: 0.0007779246707428731\n",
      "episode: 251\tCurrent_score: 11.0\tAverage score: 11.89\tloss: 2.404266119003296\tweighted_loss: 2.404266119003296\teps: 0.1\tb_decay: 2.5226168385406034e-05\tLearning rate: 0.0007771467460721302\n",
      "episode: 252\tCurrent_score: 7.0\tAverage score: 11.81\tloss: 3.179940938949585\tweighted_loss: 3.179940938949585\teps: 0.1\tb_decay: 2.5326270960635e-05\tLearning rate: 0.0007763695993260581\n",
      "episode: 253\tCurrent_score: 11.0\tAverage score: 11.79\tloss: 1.8435214757919312\tweighted_loss: 1.8435214757919312\teps: 0.1\tb_decay: 2.5426373525760937e-05\tLearning rate: 0.0007755932297267321\n",
      "episode: 254\tCurrent_score: 17.0\tAverage score: 11.87\tloss: 1.7197482585906982\tweighted_loss: 1.7197482585906982\teps: 0.1\tb_decay: 2.5526476080894867e-05\tLearning rate: 0.0007748176364970054\n",
      "episode: 255\tCurrent_score: 12.0\tAverage score: 11.87\tloss: 2.1536290645599365\tweighted_loss: 2.1536290645599365\teps: 0.1\tb_decay: 2.5626578625925767e-05\tLearning rate: 0.0007740428188605084\n",
      "episode: 256\tCurrent_score: 16.0\tAverage score: 11.93\tloss: 2.603994846343994\tweighted_loss: 2.603994846343994\teps: 0.1\tb_decay: 2.5726681161075682e-05\tLearning rate: 0.000773268776041648\n",
      "episode: 257\tCurrent_score: 17.0\tAverage score: 11.97\tloss: 2.3528125286102295\tweighted_loss: 2.3528125286102295\teps: 0.1\tb_decay: 2.5826783686122567e-05\tLearning rate: 0.0007724955072656064\n",
      "episode: 258\tCurrent_score: 8.0\tAverage score: 11.96\tloss: 2.256720542907715\tweighted_loss: 2.256720542907715\teps: 0.1\tb_decay: 2.5926886201177446e-05\tLearning rate: 0.0007717230117583407\n",
      "episode: 259\tCurrent_score: 13.0\tAverage score: 11.99\tloss: 1.9833128452301025\tweighted_loss: 1.9833128452301025\teps: 0.1\tb_decay: 2.6026988706129295e-05\tLearning rate: 0.0007709512887465824\n",
      "episode: 260\tCurrent_score: 12.0\tAverage score: 11.98\tloss: 2.431825876235962\tweighted_loss: 2.431825876235962\teps: 0.1\tb_decay: 2.6127091201089137e-05\tLearning rate: 0.0007701803374578358\n",
      "episode: 261\tCurrent_score: 11.0\tAverage score: 11.93\tloss: 3.2973334789276123\tweighted_loss: 3.2973334789276123\teps: 0.1\tb_decay: 2.622719368605697e-05\tLearning rate: 0.000769410157120378\n",
      "episode: 262\tCurrent_score: 16.0\tAverage score: 11.95\tloss: 2.151167154312134\tweighted_loss: 2.151167154312134\teps: 0.1\tb_decay: 2.6327296161032798e-05\tLearning rate: 0.0007686407469632576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 263\tCurrent_score: 5.0\tAverage score: 11.92\tloss: 2.0983283519744873\tweighted_loss: 2.0983283519744873\teps: 0.1\tb_decay: 2.6427398626016618e-05\tLearning rate: 0.0007678721062162944\n",
      "episode: 264\tCurrent_score: 6.0\tAverage score: 11.85\tloss: 1.7293165922164917\tweighted_loss: 1.7293165922164917\teps: 0.1\tb_decay: 2.652750108089741e-05\tLearning rate: 0.0007671042341100781\n",
      "episode: 265\tCurrent_score: 14.0\tAverage score: 11.81\tloss: 3.315903663635254\tweighted_loss: 3.315903663635254\teps: 0.1\tb_decay: 2.6627603525786192e-05\tLearning rate: 0.000766337129875968\n",
      "episode: 266\tCurrent_score: 11.0\tAverage score: 11.77\tloss: 1.7424770593643188\tweighted_loss: 1.7424770593643188\teps: 0.1\tb_decay: 2.6727705960682968e-05\tLearning rate: 0.000765570792746092\n",
      "episode: 267\tCurrent_score: 11.0\tAverage score: 11.71\tloss: 3.0818846225738525\tweighted_loss: 3.0818846225738525\teps: 0.1\tb_decay: 2.6827808385476715e-05\tLearning rate: 0.0007648052219533459\n",
      "episode: 268\tCurrent_score: 11.0\tAverage score: 11.75\tloss: 1.6807117462158203\tweighted_loss: 1.6807117462158203\teps: 0.1\tb_decay: 2.6927910800389476e-05\tLearning rate: 0.0007640404167313926\n",
      "episode: 269\tCurrent_score: 14.0\tAverage score: 11.79\tloss: 2.745107412338257\tweighted_loss: 2.745107412338257\teps: 0.1\tb_decay: 2.7028013205088186e-05\tLearning rate: 0.0007632763763146612\n",
      "episode: 270\tCurrent_score: 11.0\tAverage score: 11.78\tloss: 2.685319185256958\tweighted_loss: 2.685319185256958\teps: 0.1\tb_decay: 2.712811559990591e-05\tLearning rate: 0.0007625130999383466\n",
      "episode: 271\tCurrent_score: 2.0\tAverage score: 11.69\tloss: 3.102403163909912\tweighted_loss: 3.102403163909912\teps: 0.1\tb_decay: 2.722821798473163e-05\tLearning rate: 0.0007617505868384082\n",
      "episode: 272\tCurrent_score: 16.0\tAverage score: 11.8\tloss: 2.6484010219573975\tweighted_loss: 2.6484010219573975\teps: 0.1\tb_decay: 2.7328320359454317e-05\tLearning rate: 0.0007609888362515698\n",
      "episode: 273\tCurrent_score: 13.0\tAverage score: 11.86\tloss: 2.545159339904785\tweighted_loss: 2.545159339904785\teps: 0.1\tb_decay: 2.7428422724184998e-05\tLearning rate: 0.0007602278474153183\n",
      "episode: 274\tCurrent_score: 15.0\tAverage score: 11.86\tloss: 3.347248077392578\tweighted_loss: 3.347248077392578\teps: 0.1\tb_decay: 2.752852507881265e-05\tLearning rate: 0.000759467619567903\n",
      "episode: 275\tCurrent_score: 10.0\tAverage score: 11.86\tloss: 2.8763017654418945\tweighted_loss: 2.8763017654418945\teps: 0.1\tb_decay: 2.7628627423559315e-05\tLearning rate: 0.0007587081519483351\n",
      "episode: 276\tCurrent_score: 10.0\tAverage score: 11.81\tloss: 2.2121636867523193\tweighted_loss: 2.2121636867523193\teps: 0.1\tb_decay: 2.7728729758202952e-05\tLearning rate: 0.0007579494437963867\n",
      "episode: 277\tCurrent_score: 14.0\tAverage score: 11.8\tloss: 2.6033143997192383\tweighted_loss: 2.6033143997192383\teps: 0.1\tb_decay: 2.7828832082854582e-05\tLearning rate: 0.0007571914943525904\n",
      "episode: 278\tCurrent_score: 12.0\tAverage score: 11.78\tloss: 2.432321071624756\tweighted_loss: 2.432321071624756\teps: 0.1\tb_decay: 2.7928934397514205e-05\tLearning rate: 0.0007564343028582378\n",
      "episode: 279\tCurrent_score: 7.0\tAverage score: 11.76\tloss: 3.0216712951660156\tweighted_loss: 3.0216712951660156\teps: 0.1\tb_decay: 2.8029036702070798e-05\tLearning rate: 0.0007556778685553796\n",
      "episode: 280\tCurrent_score: 4.0\tAverage score: 11.71\tloss: 3.115844488143921\tweighted_loss: 3.115844488143921\teps: 0.1\tb_decay: 2.8129138996635383e-05\tLearning rate: 0.0007549221906868242\n",
      "episode: 281\tCurrent_score: 12.0\tAverage score: 11.7\tloss: 2.8469338417053223\tweighted_loss: 2.8469338417053223\teps: 0.1\tb_decay: 2.8229241281207962e-05\tLearning rate: 0.0007541672684961374\n",
      "episode: 282\tCurrent_score: 12.0\tAverage score: 11.69\tloss: 3.5366463661193848\tweighted_loss: 3.5366463661193848\teps: 0.1\tb_decay: 2.8329343555788533e-05\tLearning rate: 0.0007534131012276413\n",
      "episode: 283\tCurrent_score: 15.0\tAverage score: 11.75\tloss: 2.2535758018493652\tweighted_loss: 2.2535758018493652\teps: 0.1\tb_decay: 2.8429445820266075e-05\tLearning rate: 0.0007526596881264136\n",
      "episode: 284\tCurrent_score: 11.0\tAverage score: 11.72\tloss: 3.1041438579559326\tweighted_loss: 3.1041438579559326\teps: 0.1\tb_decay: 2.852954807475161e-05\tLearning rate: 0.0007519070284382872\n",
      "episode: 285\tCurrent_score: 17.0\tAverage score: 11.79\tloss: 3.030221700668335\tweighted_loss: 3.030221700668335\teps: 0.1\tb_decay: 2.8629650319245137e-05\tLearning rate: 0.000751155121409849\n",
      "episode: 286\tCurrent_score: 9.0\tAverage score: 11.76\tloss: 2.3553431034088135\tweighted_loss: 2.3553431034088135\teps: 0.1\tb_decay: 2.8729752553635635e-05\tLearning rate: 0.0007504039662884391\n",
      "episode: 287\tCurrent_score: 7.0\tAverage score: 11.76\tloss: 2.5096704959869385\tweighted_loss: 2.5096704959869385\teps: 0.1\tb_decay: 2.8829854778145148e-05\tLearning rate: 0.0007496535623221506\n",
      "episode: 288\tCurrent_score: 10.0\tAverage score: 11.73\tloss: 2.8759355545043945\tweighted_loss: 2.8759355545043945\teps: 0.1\tb_decay: 2.892995699255163e-05\tLearning rate: 0.0007489039087598284\n",
      "episode: 289\tCurrent_score: 9.0\tAverage score: 11.73\tloss: 2.243669271469116\tweighted_loss: 2.243669271469116\teps: 0.1\tb_decay: 2.9030059196966107e-05\tLearning rate: 0.0007481550048510686\n",
      "episode: 290\tCurrent_score: 12.0\tAverage score: 11.66\tloss: 3.3041326999664307\tweighted_loss: 3.3041326999664307\teps: 0.1\tb_decay: 2.9130161391277554e-05\tLearning rate: 0.0007474068498462175\n",
      "episode: 291\tCurrent_score: 4.0\tAverage score: 11.56\tloss: 2.4844040870666504\tweighted_loss: 2.4844040870666504\teps: 0.1\tb_decay: 2.9230263575596993e-05\tLearning rate: 0.0007466594429963714\n",
      "episode: 292\tCurrent_score: 10.0\tAverage score: 11.57\tloss: 2.8227553367614746\tweighted_loss: 2.8227553367614746\teps: 0.1\tb_decay: 2.9330365749924425e-05\tLearning rate: 0.000745912783553375\n",
      "episode: 293\tCurrent_score: 12.0\tAverage score: 11.56\tloss: 3.108407735824585\tweighted_loss: 3.108407735824585\teps: 0.1\tb_decay: 2.943046791425985e-05\tLearning rate: 0.0007451668707698216\n",
      "episode: 294\tCurrent_score: 15.0\tAverage score: 11.56\tloss: 2.8336355686187744\tweighted_loss: 2.8336355686187744\teps: 0.1\tb_decay: 2.9530570068603268e-05\tLearning rate: 0.0007444217038990518\n",
      "episode: 295\tCurrent_score: 19.0\tAverage score: 11.59\tloss: 3.363982915878296\tweighted_loss: 3.363982915878296\teps: 0.1\tb_decay: 2.9630672212843656e-05\tLearning rate: 0.0007436772821951528\n",
      "episode: 296\tCurrent_score: 15.0\tAverage score: 11.63\tloss: 2.166574001312256\tweighted_loss: 2.166574001312256\teps: 0.1\tb_decay: 2.9730774347092037e-05\tLearning rate: 0.0007429336049129576\n",
      "episode: 297\tCurrent_score: 13.0\tAverage score: 11.67\tloss: 3.6710469722747803\tweighted_loss: 3.6710469722747803\teps: 0.1\tb_decay: 2.983087647134841e-05\tLearning rate: 0.0007421906713080446\n",
      "episode: 298\tCurrent_score: 10.0\tAverage score: 11.72\tloss: 3.6185545921325684\tweighted_loss: 3.6185545921325684\teps: 0.1\tb_decay: 2.9930978585501755e-05\tLearning rate: 0.0007414484806367366\n",
      "episode: 299\tCurrent_score: 7.0\tAverage score: 11.7\tloss: 2.4834227561950684\tweighted_loss: 2.4834227561950684\teps: 0.1\tb_decay: 3.0031080689663092e-05\tLearning rate: 0.0007407070321560999\n",
      "episode: 300\tCurrent_score: 10.0\tAverage score: 11.63\tloss: 2.2518417835235596\tweighted_loss: 2.2518417835235596\teps: 0.1\tb_decay: 3.0131182783832422e-05\tLearning rate: 0.0007399663251239438\n",
      "episode: 301\tCurrent_score: 12.0\tAverage score: 11.62\tloss: 2.6923744678497314\tweighted_loss: 2.6923744678497314\teps: 0.1\tb_decay: 3.0231284868009745e-05\tLearning rate: 0.0007392263587988199\n",
      "episode: 302\tCurrent_score: 11.0\tAverage score: 11.6\tloss: 2.433372735977173\tweighted_loss: 2.433372735977173\teps: 0.1\tb_decay: 3.0331386942084038e-05\tLearning rate: 0.0007384871324400211\n",
      "episode: 303\tCurrent_score: 6.0\tAverage score: 11.54\tloss: 2.4207763671875\tweighted_loss: 2.4207763671875\teps: 0.1\tb_decay: 3.0431489006277346e-05\tLearning rate: 0.0007377486453075811\n",
      "episode: 304\tCurrent_score: 9.0\tAverage score: 11.51\tloss: 2.5582895278930664\tweighted_loss: 2.5582895278930664\teps: 0.1\tb_decay: 3.0531591060367624e-05\tLearning rate: 0.0007370108966622736\n",
      "episode: 305\tCurrent_score: 14.0\tAverage score: 11.55\tloss: 2.8036322593688965\tweighted_loss: 2.8036322593688965\teps: 0.1\tb_decay: 3.0631693104354873e-05\tLearning rate: 0.0007362738857656113\n",
      "episode: 306\tCurrent_score: 11.0\tAverage score: 11.54\tloss: 1.8628652095794678\tweighted_loss: 1.8628652095794678\teps: 0.1\tb_decay: 3.073179513846114e-05\tLearning rate: 0.0007355376118798457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 307\tCurrent_score: 13.0\tAverage score: 11.57\tloss: 2.6991007328033447\tweighted_loss: 2.6991007328033447\teps: 0.1\tb_decay: 3.083189716246437e-05\tLearning rate: 0.0007348020742679658\n",
      "episode: 308\tCurrent_score: 7.0\tAverage score: 11.52\tloss: 3.940361499786377\tweighted_loss: 3.940361499786377\teps: 0.1\tb_decay: 3.09319991764756e-05\tLearning rate: 0.0007340672721936978\n",
      "episode: 309\tCurrent_score: 11.0\tAverage score: 11.48\tloss: 2.461336135864258\tweighted_loss: 2.461336135864258\teps: 0.1\tb_decay: 3.10321011803838e-05\tLearning rate: 0.0007333332049215041\n",
      "episode: 310\tCurrent_score: 11.0\tAverage score: 11.48\tloss: 3.4021410942077637\tweighted_loss: 3.4021410942077637\teps: 0.1\tb_decay: 3.113220317441101e-05\tLearning rate: 0.0007325998717165826\n",
      "episode: 311\tCurrent_score: 11.0\tAverage score: 11.45\tloss: 1.9861156940460205\tweighted_loss: 1.9861156940460205\teps: 0.1\tb_decay: 3.1232305158335194e-05\tLearning rate: 0.000731867271844866\n",
      "episode: 312\tCurrent_score: 17.0\tAverage score: 11.48\tloss: 1.8206976652145386\tweighted_loss: 1.8206976652145386\teps: 0.1\tb_decay: 3.133240713226737e-05\tLearning rate: 0.0007311354045730212\n",
      "episode: 313\tCurrent_score: 6.0\tAverage score: 11.39\tloss: 2.6916563510894775\tweighted_loss: 2.6916563510894775\teps: 0.1\tb_decay: 3.143250909609652e-05\tLearning rate: 0.0007304042691684482\n",
      "episode: 314\tCurrent_score: 11.0\tAverage score: 11.42\tloss: 2.721303701400757\tweighted_loss: 2.721303701400757\teps: 0.1\tb_decay: 3.1532611049933656e-05\tLearning rate: 0.0007296738648992797\n",
      "episode: 315\tCurrent_score: 16.0\tAverage score: 11.42\tloss: 3.0469183921813965\tweighted_loss: 3.0469183921813965\teps: 0.1\tb_decay: 3.163271299388981e-05\tLearning rate: 0.0007289441910343804\n",
      "episode: 316\tCurrent_score: 14.0\tAverage score: 11.38\tloss: 2.792147397994995\tweighted_loss: 2.792147397994995\teps: 0.1\tb_decay: 3.1732814927631914e-05\tLearning rate: 0.000728215246843346\n",
      "episode: 317\tCurrent_score: 16.0\tAverage score: 11.45\tloss: 2.4722135066986084\tweighted_loss: 2.4722135066986084\teps: 0.1\tb_decay: 3.183291685149303e-05\tLearning rate: 0.0007274870315965027\n",
      "episode: 318\tCurrent_score: 10.0\tAverage score: 11.48\tloss: 2.352238416671753\tweighted_loss: 2.352238416671753\teps: 0.1\tb_decay: 3.193301876525112e-05\tLearning rate: 0.0007267595445649062\n",
      "episode: 319\tCurrent_score: 15.0\tAverage score: 11.52\tloss: 2.78937029838562\tweighted_loss: 2.78937029838562\teps: 0.1\tb_decay: 3.20331206690172e-05\tLearning rate: 0.0007260327850203413\n",
      "episode: 320\tCurrent_score: 8.0\tAverage score: 11.49\tloss: 2.7082595825195312\tweighted_loss: 2.7082595825195312\teps: 0.1\tb_decay: 3.2133222562791275e-05\tLearning rate: 0.000725306752235321\n",
      "episode: 321\tCurrent_score: 16.0\tAverage score: 11.54\tloss: 2.374169111251831\tweighted_loss: 2.374169111251831\teps: 0.1\tb_decay: 3.223332444657334e-05\tLearning rate: 0.0007245814454830857\n",
      "episode: 322\tCurrent_score: 15.0\tAverage score: 11.57\tloss: 1.9528305530548096\tweighted_loss: 1.9528305530548096\teps: 0.1\tb_decay: 3.233342632025238e-05\tLearning rate: 0.0007238568640376026\n",
      "episode: 323\tCurrent_score: 13.0\tAverage score: 11.61\tloss: 2.7051727771759033\tweighted_loss: 2.7051727771759033\teps: 0.1\tb_decay: 3.243352818393941e-05\tLearning rate: 0.000723133007173565\n",
      "episode: 324\tCurrent_score: 16.0\tAverage score: 11.65\tloss: 2.894408941268921\tweighted_loss: 2.894408941268921\teps: 0.1\tb_decay: 3.253363003763443e-05\tLearning rate: 0.0007224098741663914\n",
      "episode: 325\tCurrent_score: 14.0\tAverage score: 11.68\tloss: 2.6934287548065186\tweighted_loss: 2.6934287548065186\teps: 0.1\tb_decay: 3.2633731881226424e-05\tLearning rate: 0.000721687464292225\n",
      "episode: 326\tCurrent_score: 12.0\tAverage score: 11.68\tloss: 2.7909791469573975\tweighted_loss: 2.7909791469573975\teps: 0.1\tb_decay: 3.273383371482641e-05\tLearning rate: 0.0007209657768279328\n",
      "episode: 327\tCurrent_score: 12.0\tAverage score: 11.73\tloss: 2.3834633827209473\tweighted_loss: 2.3834633827209473\teps: 0.1\tb_decay: 3.283393553843439e-05\tLearning rate: 0.0007202448110511048\n",
      "episode: 328\tCurrent_score: 9.0\tAverage score: 11.72\tloss: 2.6016573905944824\tweighted_loss: 2.6016573905944824\teps: 0.1\tb_decay: 3.293403735205036e-05\tLearning rate: 0.0007195245662400537\n",
      "episode: 329\tCurrent_score: 15.0\tAverage score: 11.72\tloss: 2.513683795928955\tweighted_loss: 2.513683795928955\teps: 0.1\tb_decay: 3.30341391555633e-05\tLearning rate: 0.0007188050416738136\n",
      "episode: 330\tCurrent_score: 4.0\tAverage score: 11.69\tloss: 2.484832763671875\tweighted_loss: 2.484832763671875\teps: 0.1\tb_decay: 3.313424094919526e-05\tLearning rate: 0.0007180862366321398\n",
      "episode: 331\tCurrent_score: 8.0\tAverage score: 11.64\tloss: 3.0074973106384277\tweighted_loss: 3.0074973106384277\teps: 0.1\tb_decay: 3.323434273272419e-05\tLearning rate: 0.0007173681503955077\n",
      "episode: 332\tCurrent_score: 14.0\tAverage score: 11.6\tloss: 2.847041130065918\tweighted_loss: 2.847041130065918\teps: 0.1\tb_decay: 3.3334444506150085e-05\tLearning rate: 0.0007166507822451122\n",
      "episode: 333\tCurrent_score: 20.0\tAverage score: 11.67\tloss: 2.1857826709747314\tweighted_loss: 2.1857826709747314\teps: 0.1\tb_decay: 3.3434546269695e-05\tLearning rate: 0.0007159341314628671\n",
      "episode: 334\tCurrent_score: 10.0\tAverage score: 11.63\tloss: 2.179675579071045\tweighted_loss: 2.179675579071045\teps: 0.1\tb_decay: 3.353464802313688e-05\tLearning rate: 0.0007152181973314041\n",
      "episode: 335\tCurrent_score: 13.0\tAverage score: 11.63\tloss: 2.1755564212799072\tweighted_loss: 2.1755564212799072\teps: 0.1\tb_decay: 3.363474976658676e-05\tLearning rate: 0.0007145029791340728\n",
      "episode: 336\tCurrent_score: 15.0\tAverage score: 11.67\tloss: 2.959909677505493\tweighted_loss: 2.959909677505493\teps: 0.1\tb_decay: 3.3734851499933605e-05\tLearning rate: 0.0007137884761549386\n",
      "episode: 337\tCurrent_score: 8.0\tAverage score: 11.61\tloss: 3.101375102996826\tweighted_loss: 3.101375102996826\teps: 0.1\tb_decay: 3.3834953223399467e-05\tLearning rate: 0.0007130746876787837\n",
      "episode: 338\tCurrent_score: 3.0\tAverage score: 11.6\tloss: 2.8962695598602295\tweighted_loss: 2.8962695598602295\teps: 0.1\tb_decay: 3.39350549367623e-05\tLearning rate: 0.0007123616129911049\n",
      "episode: 339\tCurrent_score: 7.0\tAverage score: 11.57\tloss: 2.556936264038086\tweighted_loss: 2.556936264038086\teps: 0.1\tb_decay: 3.4035156640133124e-05\tLearning rate: 0.0007116492513781138\n",
      "episode: 340\tCurrent_score: 12.0\tAverage score: 11.63\tloss: 2.4785335063934326\tweighted_loss: 2.4785335063934326\teps: 0.1\tb_decay: 3.413525833340092e-05\tLearning rate: 0.0007109376021267357\n",
      "episode: 341\tCurrent_score: 14.0\tAverage score: 11.65\tloss: 2.779581308364868\tweighted_loss: 2.779581308364868\teps: 0.1\tb_decay: 3.423536001678773e-05\tLearning rate: 0.000710226664524609\n",
      "episode: 342\tCurrent_score: 11.0\tAverage score: 11.68\tloss: 2.7875311374664307\tweighted_loss: 2.7875311374664307\teps: 0.1\tb_decay: 3.433546169007151e-05\tLearning rate: 0.0007095164378600843\n",
      "episode: 343\tCurrent_score: 6.0\tAverage score: 11.61\tloss: 3.298494338989258\tweighted_loss: 3.298494338989258\teps: 0.1\tb_decay: 3.4435563353363285e-05\tLearning rate: 0.0007088069214222242\n",
      "episode: 344\tCurrent_score: 16.0\tAverage score: 11.63\tloss: 2.5632286071777344\tweighted_loss: 2.5632286071777344\teps: 0.1\tb_decay: 3.453566500655203e-05\tLearning rate: 0.000708098114500802\n",
      "episode: 345\tCurrent_score: 13.0\tAverage score: 11.66\tloss: 2.7236859798431396\tweighted_loss: 2.7236859798431396\teps: 0.1\tb_decay: 3.463576664974877e-05\tLearning rate: 0.0007073900163863012\n",
      "episode: 346\tCurrent_score: 8.0\tAverage score: 11.59\tloss: 3.1757566928863525\tweighted_loss: 3.1757566928863525\teps: 0.1\tb_decay: 3.473586828306452e-05\tLearning rate: 0.0007066826263699148\n",
      "episode: 347\tCurrent_score: 15.0\tAverage score: 11.58\tloss: 2.463350772857666\tweighted_loss: 2.463350772857666\teps: 0.1\tb_decay: 3.483596990616622e-05\tLearning rate: 0.000705975943743545\n",
      "episode: 348\tCurrent_score: 15.0\tAverage score: 11.58\tloss: 2.427034854888916\tweighted_loss: 2.427034854888916\teps: 0.1\tb_decay: 3.4936071519386935e-05\tLearning rate: 0.0007052699677998015\n",
      "episode: 349\tCurrent_score: 10.0\tAverage score: 11.53\tloss: 3.7249112129211426\tweighted_loss: 3.7249112129211426\teps: 0.1\tb_decay: 3.503617312250462e-05\tLearning rate: 0.0007045646978320017\n",
      "episode: 350\tCurrent_score: 11.0\tAverage score: 11.5\tloss: 3.5542125701904297\tweighted_loss: 3.5542125701904297\teps: 0.1\tb_decay: 3.51362747156303e-05\tLearning rate: 0.0007038601331341697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 351\tCurrent_score: 11.0\tAverage score: 11.5\tloss: 2.4130473136901855\tweighted_loss: 2.4130473136901855\teps: 0.1\tb_decay: 3.523637629876397e-05\tLearning rate: 0.0007031562730010354\n",
      "episode: 352\tCurrent_score: 13.0\tAverage score: 11.56\tloss: 3.2241902351379395\tweighted_loss: 3.2241902351379395\teps: 0.1\tb_decay: 3.5336477871794614e-05\tLearning rate: 0.0007024531167280344\n",
      "episode: 353\tCurrent_score: 16.0\tAverage score: 11.61\tloss: 2.3601531982421875\tweighted_loss: 2.3601531982421875\teps: 0.1\tb_decay: 3.543657943494427e-05\tLearning rate: 0.0007017506636113063\n",
      "episode: 354\tCurrent_score: 8.0\tAverage score: 11.52\tloss: 2.0906429290771484\tweighted_loss: 2.0906429290771484\teps: 0.1\tb_decay: 3.55366809879909e-05\tLearning rate: 0.000701048912947695\n",
      "episode: 355\tCurrent_score: 14.0\tAverage score: 11.54\tloss: 3.415897846221924\tweighted_loss: 3.415897846221924\teps: 0.1\tb_decay: 3.5636782530934497e-05\tLearning rate: 0.0007003478640347473\n",
      "episode: 356\tCurrent_score: 12.0\tAverage score: 11.5\tloss: 3.832049608230591\tweighted_loss: 3.832049608230591\teps: 0.1\tb_decay: 3.573688406399711e-05\tLearning rate: 0.0006996475161707126\n",
      "episode: 357\tCurrent_score: 14.0\tAverage score: 11.47\tloss: 3.448256492614746\tweighted_loss: 3.448256492614746\teps: 0.1\tb_decay: 3.583698558695669e-05\tLearning rate: 0.0006989478686545419\n",
      "episode: 358\tCurrent_score: 18.0\tAverage score: 11.57\tloss: 2.693755626678467\tweighted_loss: 2.693755626678467\teps: 0.1\tb_decay: 3.593708709992427e-05\tLearning rate: 0.0006982489207858873\n",
      "episode: 359\tCurrent_score: 8.0\tAverage score: 11.52\tloss: 2.7422568798065186\tweighted_loss: 2.7422568798065186\teps: 0.1\tb_decay: 3.603718860289984e-05\tLearning rate: 0.0006975506718651013\n",
      "episode: 360\tCurrent_score: 12.0\tAverage score: 11.52\tloss: 2.0205090045928955\tweighted_loss: 2.0205090045928955\teps: 0.1\tb_decay: 3.613729009577238e-05\tLearning rate: 0.0006968531211932362\n",
      "episode: 361\tCurrent_score: 11.0\tAverage score: 11.52\tloss: 1.887127161026001\tweighted_loss: 1.887127161026001\teps: 0.1\tb_decay: 3.623739157865291e-05\tLearning rate: 0.0006961562680720429\n",
      "episode: 362\tCurrent_score: 14.0\tAverage score: 11.5\tloss: 2.667295455932617\tweighted_loss: 2.667295455932617\teps: 0.1\tb_decay: 3.6337493051541436e-05\tLearning rate: 0.0006954601118039709\n",
      "episode: 363\tCurrent_score: 12.0\tAverage score: 11.57\tloss: 2.296657085418701\tweighted_loss: 2.296657085418701\teps: 0.1\tb_decay: 3.6437594514437954e-05\tLearning rate: 0.0006947646516921669\n",
      "episode: 364\tCurrent_score: 12.0\tAverage score: 11.63\tloss: 3.735748767852783\tweighted_loss: 3.735748767852783\teps: 0.1\tb_decay: 3.653769596723144e-05\tLearning rate: 0.0006940698870404747\n",
      "episode: 365\tCurrent_score: 12.0\tAverage score: 11.61\tloss: 3.313164710998535\tweighted_loss: 3.313164710998535\teps: 0.1\tb_decay: 3.6637797410143946e-05\tLearning rate: 0.0006933758171534342\n",
      "episode: 366\tCurrent_score: 6.0\tAverage score: 11.56\tloss: 2.2875075340270996\tweighted_loss: 2.2875075340270996\teps: 0.1\tb_decay: 3.673789884295342e-05\tLearning rate: 0.0006926824413362808\n",
      "episode: 367\tCurrent_score: 9.0\tAverage score: 11.54\tloss: 2.353668212890625\tweighted_loss: 2.353668212890625\teps: 0.1\tb_decay: 3.6838000265659865e-05\tLearning rate: 0.0006919897588949446\n",
      "episode: 368\tCurrent_score: 16.0\tAverage score: 11.59\tloss: 2.2475390434265137\tweighted_loss: 2.2475390434265137\teps: 0.1\tb_decay: 3.6938101678485324e-05\tLearning rate: 0.0006912977691360496\n",
      "episode: 369\tCurrent_score: 15.0\tAverage score: 11.6\tloss: 2.702406644821167\tweighted_loss: 2.702406644821167\teps: 0.1\tb_decay: 3.7038203081207755e-05\tLearning rate: 0.0006906064713669135\n",
      "episode: 370\tCurrent_score: 14.0\tAverage score: 11.63\tloss: 3.530686616897583\tweighted_loss: 3.530686616897583\teps: 0.1\tb_decay: 3.713830447393818e-05\tLearning rate: 0.0006899158648955465\n",
      "episode: 371\tCurrent_score: 12.0\tAverage score: 11.73\tloss: 2.9878251552581787\tweighted_loss: 2.9878251552581787\teps: 0.1\tb_decay: 3.723840585656557e-05\tLearning rate: 0.000689225949030651\n",
      "episode: 372\tCurrent_score: 12.0\tAverage score: 11.69\tloss: 2.5124568939208984\tweighted_loss: 2.5124568939208984\teps: 0.1\tb_decay: 3.733850722920096e-05\tLearning rate: 0.0006885367230816203\n",
      "episode: 373\tCurrent_score: 11.0\tAverage score: 11.67\tloss: 2.748028039932251\tweighted_loss: 2.748028039932251\teps: 0.1\tb_decay: 3.743860859195536e-05\tLearning rate: 0.0006878481863585386\n",
      "episode: 374\tCurrent_score: 14.0\tAverage score: 11.66\tloss: 3.035728693008423\tweighted_loss: 3.035728693008423\teps: 0.1\tb_decay: 3.753870994449571e-05\tLearning rate: 0.0006871603381721801\n",
      "episode: 375\tCurrent_score: 14.0\tAverage score: 11.7\tloss: 2.67415714263916\tweighted_loss: 2.67415714263916\teps: 0.1\tb_decay: 3.763881128715507e-05\tLearning rate: 0.0006864731778340079\n",
      "episode: 376\tCurrent_score: 11.0\tAverage score: 11.71\tloss: 1.914465069770813\tweighted_loss: 1.914465069770813\teps: 0.1\tb_decay: 3.773891261971141e-05\tLearning rate: 0.0006857867046561739\n",
      "episode: 377\tCurrent_score: 16.0\tAverage score: 11.73\tloss: 3.112086296081543\tweighted_loss: 3.112086296081543\teps: 0.1\tb_decay: 3.7839013942275734e-05\tLearning rate: 0.0006851009179515177\n",
      "episode: 378\tCurrent_score: 16.0\tAverage score: 11.77\tloss: 2.233593225479126\tweighted_loss: 2.233593225479126\teps: 0.1\tb_decay: 3.7939115254848055e-05\tLearning rate: 0.0006844158170335661\n",
      "episode: 379\tCurrent_score: 10.0\tAverage score: 11.8\tloss: 3.0590341091156006\tweighted_loss: 3.0590341091156006\teps: 0.1\tb_decay: 3.803921655742837e-05\tLearning rate: 0.0006837314012165325\n",
      "episode: 380\tCurrent_score: 8.0\tAverage score: 11.84\tloss: 2.4783620834350586\tweighted_loss: 2.4783620834350586\teps: 0.1\tb_decay: 3.813931784990565e-05\tLearning rate: 0.0006830476698153159\n",
      "episode: 381\tCurrent_score: 14.0\tAverage score: 11.86\tloss: 2.5591299533843994\tweighted_loss: 2.5591299533843994\teps: 0.1\tb_decay: 3.823941913239093e-05\tLearning rate: 0.0006823646221455007\n",
      "episode: 382\tCurrent_score: 7.0\tAverage score: 11.81\tloss: 2.882445812225342\tweighted_loss: 2.882445812225342\teps: 0.1\tb_decay: 3.83395204048842e-05\tLearning rate: 0.0006816822575233551\n",
      "episode: 383\tCurrent_score: 13.0\tAverage score: 11.79\tloss: 2.363726854324341\tweighted_loss: 2.363726854324341\teps: 0.1\tb_decay: 3.843962166727444e-05\tLearning rate: 0.0006810005752658318\n",
      "episode: 384\tCurrent_score: 20.0\tAverage score: 11.88\tloss: 2.436764717102051\tweighted_loss: 2.436764717102051\teps: 0.1\tb_decay: 3.853972291978369e-05\tLearning rate: 0.0006803195746905659\n",
      "episode: 385\tCurrent_score: 10.0\tAverage score: 11.81\tloss: 2.9588069915771484\tweighted_loss: 2.9588069915771484\teps: 0.1\tb_decay: 3.863982416218992e-05\tLearning rate: 0.0006796392551158754\n",
      "episode: 386\tCurrent_score: 15.0\tAverage score: 11.87\tloss: 2.594529390335083\tweighted_loss: 2.594529390335083\teps: 0.1\tb_decay: 3.873992539449311e-05\tLearning rate: 0.0006789596158607594\n",
      "episode: 387\tCurrent_score: 16.0\tAverage score: 11.96\tloss: 3.372098922729492\tweighted_loss: 3.372098922729492\teps: 0.1\tb_decay: 3.8840026616915324e-05\tLearning rate: 0.0006782806562448987\n",
      "episode: 388\tCurrent_score: 8.0\tAverage score: 11.94\tloss: 3.031165599822998\tweighted_loss: 3.031165599822998\teps: 0.1\tb_decay: 3.8940127829234505e-05\tLearning rate: 0.0006776023755886537\n",
      "episode: 389\tCurrent_score: 13.0\tAverage score: 11.98\tloss: 3.348140001296997\tweighted_loss: 3.348140001296997\teps: 0.1\tb_decay: 3.904022903156168e-05\tLearning rate: 0.000676924773213065\n",
      "episode: 390\tCurrent_score: 13.0\tAverage score: 11.99\tloss: 2.1627919673919678\tweighted_loss: 2.1627919673919678\teps: 0.1\tb_decay: 3.9140330223896846e-05\tLearning rate: 0.000676247848439852\n",
      "episode: 391\tCurrent_score: 11.0\tAverage score: 12.06\tloss: 3.267113447189331\tweighted_loss: 3.267113447189331\teps: 0.1\tb_decay: 3.9240431406128984e-05\tLearning rate: 0.0006755716005914121\n",
      "episode: 392\tCurrent_score: 8.0\tAverage score: 12.04\tloss: 3.4216949939727783\tweighted_loss: 3.4216949939727783\teps: 0.1\tb_decay: 3.9340532578369114e-05\tLearning rate: 0.0006748960289908207\n",
      "episode: 393\tCurrent_score: 22.0\tAverage score: 12.14\tloss: 2.9765398502349854\tweighted_loss: 2.9765398502349854\teps: 0.1\tb_decay: 3.944063374061724e-05\tLearning rate: 0.0006742211329618299\n",
      "episode: 394\tCurrent_score: 18.0\tAverage score: 12.17\tloss: 2.281083583831787\tweighted_loss: 2.281083583831787\teps: 0.1\tb_decay: 3.954073489287335e-05\tLearning rate: 0.0006735469118288681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 395\tCurrent_score: 12.0\tAverage score: 12.1\tloss: 2.5023038387298584\tweighted_loss: 2.5023038387298584\teps: 0.1\tb_decay: 3.964083603502644e-05\tLearning rate: 0.0006728733649170392\n",
      "episode: 396\tCurrent_score: 8.0\tAverage score: 12.03\tloss: 2.9695751667022705\tweighted_loss: 2.9695751667022705\teps: 0.1\tb_decay: 3.974093716718752e-05\tLearning rate: 0.0006722004915521222\n",
      "episode: 397\tCurrent_score: 14.0\tAverage score: 12.04\tloss: 3.127594470977783\tweighted_loss: 3.127594470977783\teps: 0.1\tb_decay: 3.984103828935659e-05\tLearning rate: 0.0006715282910605701\n",
      "episode: 398\tCurrent_score: 23.0\tAverage score: 12.17\tloss: 2.0559566020965576\tweighted_loss: 2.0559566020965576\teps: 0.1\tb_decay: 3.9941139401533654e-05\tLearning rate: 0.0006708567627695095\n",
      "episode: 399\tCurrent_score: 14.0\tAverage score: 12.24\tloss: 3.256890058517456\tweighted_loss: 3.256890058517456\teps: 0.1\tb_decay: 4.004124050360769e-05\tLearning rate: 0.00067018590600674\n",
      "episode: 400\tCurrent_score: 12.0\tAverage score: 12.26\tloss: 2.636667490005493\tweighted_loss: 2.636667490005493\teps: 0.1\tb_decay: 4.014134159568972e-05\tLearning rate: 0.0006695157201007332\n",
      "episode: 401\tCurrent_score: 21.0\tAverage score: 12.35\tloss: 2.4700827598571777\tweighted_loss: 2.4700827598571777\teps: 0.1\tb_decay: 4.024144267777974e-05\tLearning rate: 0.0006688462043806325\n",
      "episode: 402\tCurrent_score: 14.0\tAverage score: 12.38\tloss: 2.825453996658325\tweighted_loss: 2.825453996658325\teps: 0.1\tb_decay: 4.034154374987775e-05\tLearning rate: 0.0006681773581762518\n",
      "episode: 403\tCurrent_score: 18.0\tAverage score: 12.5\tloss: 3.200901985168457\tweighted_loss: 3.200901985168457\teps: 0.1\tb_decay: 4.0441644811872735e-05\tLearning rate: 0.0006675091808180756\n",
      "episode: 404\tCurrent_score: 13.0\tAverage score: 12.54\tloss: 2.5281715393066406\tweighted_loss: 2.5281715393066406\teps: 0.1\tb_decay: 4.054174586387571e-05\tLearning rate: 0.0006668416716372576\n",
      "episode: 405\tCurrent_score: 15.0\tAverage score: 12.55\tloss: 2.772618055343628\tweighted_loss: 2.772618055343628\teps: 0.1\tb_decay: 4.064184690588668e-05\tLearning rate: 0.0006661748299656203\n",
      "episode: 406\tCurrent_score: 9.0\tAverage score: 12.53\tloss: 2.8460657596588135\tweighted_loss: 2.8460657596588135\teps: 0.1\tb_decay: 4.074194793790564e-05\tLearning rate: 0.0006655086551356547\n",
      "episode: 407\tCurrent_score: 11.0\tAverage score: 12.51\tloss: 3.065985918045044\tweighted_loss: 3.065985918045044\teps: 0.1\tb_decay: 4.0842048959821575e-05\tLearning rate: 0.000664843146480519\n",
      "episode: 408\tCurrent_score: 13.0\tAverage score: 12.57\tloss: 3.3635501861572266\tweighted_loss: 3.3635501861572266\teps: 0.1\tb_decay: 4.09421499717455e-05\tLearning rate: 0.0006641783033340385\n",
      "episode: 409\tCurrent_score: 16.0\tAverage score: 12.62\tloss: 3.3151767253875732\tweighted_loss: 3.3151767253875732\teps: 0.1\tb_decay: 4.104225097367742e-05\tLearning rate: 0.0006635141250307045\n",
      "episode: 410\tCurrent_score: 8.0\tAverage score: 12.59\tloss: 1.9196150302886963\tweighted_loss: 1.9196150302886963\teps: 0.1\tb_decay: 4.114235196561733e-05\tLearning rate: 0.0006628506109056738\n",
      "episode: 411\tCurrent_score: 8.0\tAverage score: 12.56\tloss: 3.596712350845337\tweighted_loss: 3.596712350845337\teps: 0.1\tb_decay: 4.124245294745421e-05\tLearning rate: 0.0006621877602947681\n",
      "episode: 412\tCurrent_score: 12.0\tAverage score: 12.51\tloss: 2.432040214538574\tweighted_loss: 2.432040214538574\teps: 0.1\tb_decay: 4.1342553919299085e-05\tLearning rate: 0.0006615255725344733\n",
      "episode: 413\tCurrent_score: 18.0\tAverage score: 12.63\tloss: 2.0451624393463135\tweighted_loss: 2.0451624393463135\teps: 0.1\tb_decay: 4.144265488115195e-05\tLearning rate: 0.0006608640469619388\n",
      "episode: 414\tCurrent_score: 15.0\tAverage score: 12.67\tloss: 2.8871097564697266\tweighted_loss: 2.8871097564697266\teps: 0.1\tb_decay: 4.154275583290179e-05\tLearning rate: 0.0006602031829149769\n",
      "episode: 415\tCurrent_score: 19.0\tAverage score: 12.7\tloss: 3.120730400085449\tweighted_loss: 3.120730400085449\teps: 0.1\tb_decay: 4.164285677465962e-05\tLearning rate: 0.0006595429797320619\n",
      "episode: 416\tCurrent_score: 7.0\tAverage score: 12.63\tloss: 3.266256809234619\tweighted_loss: 3.266256809234619\teps: 0.1\tb_decay: 4.174295770642544e-05\tLearning rate: 0.0006588834367523298\n",
      "episode: 417\tCurrent_score: 16.0\tAverage score: 12.63\tloss: 2.898955821990967\tweighted_loss: 2.898955821990967\teps: 0.1\tb_decay: 4.184305862819926e-05\tLearning rate: 0.0006582245533155775\n",
      "episode: 418\tCurrent_score: 17.0\tAverage score: 12.7\tloss: 2.884000301361084\tweighted_loss: 2.884000301361084\teps: 0.1\tb_decay: 4.194315953998107e-05\tLearning rate: 0.0006575663287622619\n",
      "episode: 419\tCurrent_score: 13.0\tAverage score: 12.68\tloss: 2.516145944595337\tweighted_loss: 2.516145944595337\teps: 0.1\tb_decay: 4.2043260441659847e-05\tLearning rate: 0.0006569087624334997\n",
      "episode: 420\tCurrent_score: 7.0\tAverage score: 12.67\tloss: 2.5716564655303955\tweighted_loss: 2.5716564655303955\teps: 0.1\tb_decay: 4.214336133334662e-05\tLearning rate: 0.0006562518536710662\n",
      "episode: 421\tCurrent_score: 13.0\tAverage score: 12.64\tloss: 2.792715072631836\tweighted_loss: 2.792715072631836\teps: 0.1\tb_decay: 4.224346221504138e-05\tLearning rate: 0.0006555956018173951\n",
      "episode: 422\tCurrent_score: 12.0\tAverage score: 12.61\tloss: 3.002535343170166\tweighted_loss: 3.002535343170166\teps: 0.1\tb_decay: 4.234356308663312e-05\tLearning rate: 0.0006549400062155777\n",
      "episode: 423\tCurrent_score: 8.0\tAverage score: 12.56\tloss: 2.5952377319335938\tweighted_loss: 2.5952377319335938\teps: 0.1\tb_decay: 4.2443663948232846e-05\tLearning rate: 0.0006542850662093621\n",
      "episode: 424\tCurrent_score: 14.0\tAverage score: 12.54\tloss: 2.7733068466186523\tweighted_loss: 2.7733068466186523\teps: 0.1\tb_decay: 4.2543764799840567e-05\tLearning rate: 0.0006536307811431528\n",
      "episode: 425\tCurrent_score: 10.0\tAverage score: 12.5\tloss: 2.6200952529907227\tweighted_loss: 2.6200952529907227\teps: 0.1\tb_decay: 4.264386564145628e-05\tLearning rate: 0.0006529771503620096\n",
      "episode: 426\tCurrent_score: 11.0\tAverage score: 12.49\tloss: 3.045626640319824\tweighted_loss: 3.045626640319824\teps: 0.1\tb_decay: 4.2743966472968964e-05\tLearning rate: 0.0006523241732116476\n",
      "episode: 427\tCurrent_score: 10.0\tAverage score: 12.47\tloss: 2.842617988586426\tweighted_loss: 2.842617988586426\teps: 0.1\tb_decay: 4.284406729448964e-05\tLearning rate: 0.000651671849038436\n",
      "episode: 428\tCurrent_score: 7.0\tAverage score: 12.45\tloss: 2.8346903324127197\tweighted_loss: 2.8346903324127197\teps: 0.1\tb_decay: 4.294416810601831e-05\tLearning rate: 0.0006510201771893975\n",
      "episode: 429\tCurrent_score: 12.0\tAverage score: 12.42\tloss: 2.615546226501465\tweighted_loss: 2.615546226501465\teps: 0.1\tb_decay: 4.304426890755497e-05\tLearning rate: 0.0006503691570122081\n",
      "episode: 430\tCurrent_score: 16.0\tAverage score: 12.54\tloss: 2.4846014976501465\tweighted_loss: 2.4846014976501465\teps: 0.1\tb_decay: 4.3144369698988605e-05\tLearning rate: 0.0006497187878551959\n",
      "episode: 431\tCurrent_score: 17.0\tAverage score: 12.63\tloss: 2.756641387939453\tweighted_loss: 2.756641387939453\teps: 0.1\tb_decay: 4.324447048043023e-05\tLearning rate: 0.0006490690690673407\n",
      "episode: 432\tCurrent_score: 12.0\tAverage score: 12.61\tloss: 3.2064337730407715\tweighted_loss: 3.2064337730407715\teps: 0.1\tb_decay: 4.334457125187985e-05\tLearning rate: 0.0006484199999982733\n",
      "episode: 433\tCurrent_score: 12.0\tAverage score: 12.53\tloss: 3.1563668251037598\tweighted_loss: 3.1563668251037598\teps: 0.1\tb_decay: 4.344467201333746e-05\tLearning rate: 0.0006477715799982751\n",
      "episode: 434\tCurrent_score: 6.0\tAverage score: 12.49\tloss: 3.0116639137268066\tweighted_loss: 3.0116639137268066\teps: 0.1\tb_decay: 4.354477276469204e-05\tLearning rate: 0.0006471238084182769\n",
      "episode: 435\tCurrent_score: 8.0\tAverage score: 12.44\tloss: 4.24107551574707\tweighted_loss: 4.24107551574707\teps: 0.1\tb_decay: 4.3644873506054616e-05\tLearning rate: 0.0006464766846098586\n",
      "episode: 436\tCurrent_score: 15.0\tAverage score: 12.44\tloss: 3.0764710903167725\tweighted_loss: 3.0764710903167725\teps: 0.1\tb_decay: 4.374497423742518e-05\tLearning rate: 0.0006458302079252488\n",
      "episode: 437\tCurrent_score: 12.0\tAverage score: 12.48\tloss: 2.415477991104126\tweighted_loss: 2.415477991104126\teps: 0.1\tb_decay: 4.384507495880374e-05\tLearning rate: 0.0006451843777173235\n",
      "episode: 438\tCurrent_score: 10.0\tAverage score: 12.55\tloss: 2.8950564861297607\tweighted_loss: 2.8950564861297607\teps: 0.1\tb_decay: 4.394517567007927e-05\tLearning rate: 0.0006445391933396061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 439\tCurrent_score: 16.0\tAverage score: 12.64\tloss: 3.5430192947387695\tweighted_loss: 3.5430192947387695\teps: 0.1\tb_decay: 4.4045276371362796e-05\tLearning rate: 0.0006438946541462666\n",
      "episode: 440\tCurrent_score: 6.0\tAverage score: 12.58\tloss: 2.1896417140960693\tweighted_loss: 2.1896417140960693\teps: 0.1\tb_decay: 4.414537706265431e-05\tLearning rate: 0.0006432507594921203\n",
      "episode: 441\tCurrent_score: 13.0\tAverage score: 12.57\tloss: 2.6119000911712646\tweighted_loss: 2.6119000911712646\teps: 0.1\tb_decay: 4.424547774395382e-05\tLearning rate: 0.0006426075087326282\n",
      "episode: 442\tCurrent_score: 16.0\tAverage score: 12.62\tloss: 3.5442917346954346\tweighted_loss: 3.5442917346954346\teps: 0.1\tb_decay: 4.43455784151503e-05\tLearning rate: 0.0006419649012238956\n",
      "episode: 443\tCurrent_score: 12.0\tAverage score: 12.68\tloss: 4.9354023933410645\tweighted_loss: 4.9354023933410645\teps: 0.1\tb_decay: 4.444567907635477e-05\tLearning rate: 0.0006413229363226717\n",
      "episode: 444\tCurrent_score: 15.0\tAverage score: 12.67\tloss: 2.373466730117798\tweighted_loss: 2.373466730117798\teps: 0.1\tb_decay: 4.4545779727567236e-05\tLearning rate: 0.000640681613386349\n",
      "episode: 445\tCurrent_score: 20.0\tAverage score: 12.74\tloss: 2.472841501235962\tweighted_loss: 2.472841501235962\teps: 0.1\tb_decay: 4.464588036867667e-05\tLearning rate: 0.0006400409317729626\n",
      "episode: 446\tCurrent_score: 15.0\tAverage score: 12.81\tloss: 3.1703033447265625\tweighted_loss: 3.1703033447265625\teps: 0.1\tb_decay: 4.474598099990512e-05\tLearning rate: 0.0006394008908411897\n",
      "episode: 447\tCurrent_score: 21.0\tAverage score: 12.87\tloss: 2.868366003036499\tweighted_loss: 2.868366003036499\teps: 0.1\tb_decay: 4.484608162103054e-05\tLearning rate: 0.0006387614899503485\n",
      "episode: 448\tCurrent_score: 16.0\tAverage score: 12.88\tloss: 3.4470345973968506\tweighted_loss: 3.4470345973968506\teps: 0.1\tb_decay: 4.4946182232052934e-05\tLearning rate: 0.0006381227284603981\n",
      "episode: 449\tCurrent_score: 7.0\tAverage score: 12.85\tloss: 4.7040510177612305\tweighted_loss: 4.7040510177612305\teps: 0.1\tb_decay: 4.504628283319434e-05\tLearning rate: 0.0006374846057319377\n",
      "episode: 450\tCurrent_score: 13.0\tAverage score: 12.87\tloss: 2.6305694580078125\tweighted_loss: 2.6305694580078125\teps: 0.1\tb_decay: 4.514638342423272e-05\tLearning rate: 0.0006368471211262058\n",
      "episode: 451\tCurrent_score: 11.0\tAverage score: 12.87\tloss: 3.3976380825042725\tweighted_loss: 3.3976380825042725\teps: 0.1\tb_decay: 4.5246484005279086e-05\tLearning rate: 0.0006362102740050796\n",
      "episode: 452\tCurrent_score: 14.0\tAverage score: 12.88\tloss: 2.603137969970703\tweighted_loss: 2.603137969970703\teps: 0.1\tb_decay: 4.534658457633345e-05\tLearning rate: 0.0006355740637310745\n",
      "episode: 453\tCurrent_score: 7.0\tAverage score: 12.79\tloss: 3.254286766052246\tweighted_loss: 3.254286766052246\teps: 0.1\tb_decay: 4.544668513728478e-05\tLearning rate: 0.0006349384896673435\n",
      "episode: 454\tCurrent_score: 7.0\tAverage score: 12.78\tloss: 2.9684600830078125\tweighted_loss: 2.9684600830078125\teps: 0.1\tb_decay: 4.554678568835513e-05\tLearning rate: 0.0006343035511776761\n",
      "episode: 455\tCurrent_score: 9.0\tAverage score: 12.73\tloss: 2.802588939666748\tweighted_loss: 2.802588939666748\teps: 0.1\tb_decay: 4.564688622932245e-05\tLearning rate: 0.0006336692476264984\n",
      "episode: 456\tCurrent_score: 17.0\tAverage score: 12.78\tloss: 2.581305503845215\tweighted_loss: 2.581305503845215\teps: 0.1\tb_decay: 4.5746986760186736e-05\tLearning rate: 0.0006330355783788719\n",
      "episode: 457\tCurrent_score: 17.0\tAverage score: 12.81\tloss: 2.5810399055480957\tweighted_loss: 2.5810399055480957\teps: 0.1\tb_decay: 4.584708728117004e-05\tLearning rate: 0.000632402542800493\n",
      "episode: 458\tCurrent_score: 19.0\tAverage score: 12.82\tloss: 2.0803511142730713\tweighted_loss: 2.0803511142730713\teps: 0.1\tb_decay: 4.5947187792050315e-05\tLearning rate: 0.0006317701402576925\n",
      "episode: 459\tCurrent_score: 14.0\tAverage score: 12.88\tloss: 2.402331590652466\tweighted_loss: 2.402331590652466\teps: 0.1\tb_decay: 4.604728829293858e-05\tLearning rate: 0.0006311383701174348\n",
      "episode: 460\tCurrent_score: 14.0\tAverage score: 12.9\tloss: 3.0400471687316895\tweighted_loss: 3.0400471687316895\teps: 0.1\tb_decay: 4.614738878372382e-05\tLearning rate: 0.0006305072317473174\n",
      "episode: 461\tCurrent_score: 7.0\tAverage score: 12.86\tloss: 2.455824851989746\tweighted_loss: 2.455824851989746\teps: 0.1\tb_decay: 4.624748926462807e-05\tLearning rate: 0.0006298767245155701\n",
      "episode: 462\tCurrent_score: 10.0\tAverage score: 12.82\tloss: 2.4577434062957764\tweighted_loss: 2.4577434062957764\teps: 0.1\tb_decay: 4.6347589735429295e-05\tLearning rate: 0.0006292468477910545\n",
      "episode: 463\tCurrent_score: 9.0\tAverage score: 12.79\tloss: 2.8499112129211426\tweighted_loss: 2.8499112129211426\teps: 0.1\tb_decay: 4.644769019623851e-05\tLearning rate: 0.0006286176009432634\n",
      "episode: 464\tCurrent_score: 12.0\tAverage score: 12.79\tloss: 3.164767026901245\tweighted_loss: 3.164767026901245\teps: 0.1\tb_decay: 4.654779064705572e-05\tLearning rate: 0.0006279889833423201\n",
      "episode: 465\tCurrent_score: 15.0\tAverage score: 12.82\tloss: 2.620425224304199\tweighted_loss: 2.620425224304199\teps: 0.1\tb_decay: 4.66478910877699e-05\tLearning rate: 0.0006273609943589778\n",
      "episode: 466\tCurrent_score: 13.0\tAverage score: 12.89\tloss: 3.2962985038757324\tweighted_loss: 3.2962985038757324\teps: 0.1\tb_decay: 4.674799151849207e-05\tLearning rate: 0.0006267336333646189\n",
      "episode: 467\tCurrent_score: 11.0\tAverage score: 12.91\tloss: 3.9837355613708496\tweighted_loss: 3.9837355613708496\teps: 0.1\tb_decay: 4.6848091939222236e-05\tLearning rate: 0.0006261068997312542\n",
      "episode: 468\tCurrent_score: 14.0\tAverage score: 12.89\tloss: 2.7109031677246094\tweighted_loss: 2.7109031677246094\teps: 0.1\tb_decay: 4.6948192349960394e-05\tLearning rate: 0.000625480792831523\n",
      "episode: 469\tCurrent_score: 15.0\tAverage score: 12.89\tloss: 2.4116363525390625\tweighted_loss: 2.4116363525390625\teps: 0.1\tb_decay: 4.704829275059552e-05\tLearning rate: 0.0006248553120386914\n",
      "episode: 470\tCurrent_score: 15.0\tAverage score: 12.9\tloss: 2.412191152572632\tweighted_loss: 2.412191152572632\teps: 0.1\tb_decay: 4.714839314123864e-05\tLearning rate: 0.0006242304567266527\n",
      "episode: 471\tCurrent_score: 12.0\tAverage score: 12.9\tloss: 3.7678444385528564\tweighted_loss: 3.7678444385528564\teps: 0.1\tb_decay: 4.7248493521889756e-05\tLearning rate: 0.000623606226269926\n",
      "episode: 472\tCurrent_score: 13.0\tAverage score: 12.91\tloss: 2.8922476768493652\tweighted_loss: 2.8922476768493652\teps: 0.1\tb_decay: 4.734859389243784e-05\tLearning rate: 0.0006229826200436561\n",
      "episode: 473\tCurrent_score: 16.0\tAverage score: 12.96\tloss: 3.3227858543395996\tweighted_loss: 3.3227858543395996\teps: 0.1\tb_decay: 4.744869425310494e-05\tLearning rate: 0.0006223596374236124\n",
      "episode: 474\tCurrent_score: 12.0\tAverage score: 12.94\tloss: 2.615333080291748\tweighted_loss: 2.615333080291748\teps: 0.1\tb_decay: 4.754879460366901e-05\tLearning rate: 0.0006217372777861888\n",
      "episode: 475\tCurrent_score: 12.0\tAverage score: 12.92\tloss: 2.6613433361053467\tweighted_loss: 2.6613433361053467\teps: 0.1\tb_decay: 4.764889494424107e-05\tLearning rate: 0.0006211155405084027\n",
      "episode: 476\tCurrent_score: 9.0\tAverage score: 12.9\tloss: 1.8296774625778198\tweighted_loss: 1.8296774625778198\teps: 0.1\tb_decay: 4.7748995274710104e-05\tLearning rate: 0.0006204944249678943\n",
      "episode: 477\tCurrent_score: 16.0\tAverage score: 12.9\tloss: 2.9883627891540527\tweighted_loss: 2.9883627891540527\teps: 0.1\tb_decay: 4.784909559529815e-05\tLearning rate: 0.0006198739305429264\n",
      "episode: 478\tCurrent_score: 9.0\tAverage score: 12.83\tloss: 2.84021258354187\tweighted_loss: 2.84021258354187\teps: 0.1\tb_decay: 4.794919590578317e-05\tLearning rate: 0.0006192540566123835\n",
      "episode: 479\tCurrent_score: 12.0\tAverage score: 12.85\tloss: 2.622994899749756\tweighted_loss: 2.622994899749756\teps: 0.1\tb_decay: 4.804929620616516e-05\tLearning rate: 0.000618634802555771\n",
      "episode: 480\tCurrent_score: 17.0\tAverage score: 12.94\tloss: 2.804461717605591\tweighted_loss: 2.804461717605591\teps: 0.1\tb_decay: 4.8149396496666164e-05\tLearning rate: 0.0006180161677532153\n",
      "episode: 481\tCurrent_score: 18.0\tAverage score: 12.98\tloss: 3.723928689956665\tweighted_loss: 3.723928689956665\teps: 0.1\tb_decay: 4.824949677706414e-05\tLearning rate: 0.0006173981515854621\n",
      "episode: 482\tCurrent_score: 10.0\tAverage score: 13.01\tloss: 3.574108123779297\tweighted_loss: 3.574108123779297\teps: 0.1\tb_decay: 4.8349597047470105e-05\tLearning rate: 0.0006167807534338766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 483\tCurrent_score: 14.0\tAverage score: 13.02\tloss: 2.9775891304016113\tweighted_loss: 2.9775891304016113\teps: 0.1\tb_decay: 4.8449697307884065e-05\tLearning rate: 0.0006161639726804428\n",
      "episode: 484\tCurrent_score: 11.0\tAverage score: 12.93\tloss: 2.3304600715637207\tweighted_loss: 2.3304600715637207\teps: 0.1\tb_decay: 4.8549797558194996e-05\tLearning rate: 0.0006155478087077624\n",
      "episode: 485\tCurrent_score: 14.0\tAverage score: 12.97\tloss: 3.876244068145752\tweighted_loss: 3.876244068145752\teps: 0.1\tb_decay: 4.864989779862494e-05\tLearning rate: 0.0006149322608990546\n",
      "episode: 486\tCurrent_score: 11.0\tAverage score: 12.93\tloss: 3.1762423515319824\tweighted_loss: 3.1762423515319824\teps: 0.1\tb_decay: 4.874999802895186e-05\tLearning rate: 0.0006143173286381556\n",
      "episode: 487\tCurrent_score: 12.0\tAverage score: 12.89\tloss: 2.805436611175537\tweighted_loss: 2.805436611175537\teps: 0.1\tb_decay: 4.8850098249175744e-05\tLearning rate: 0.0006137030113095175\n",
      "episode: 488\tCurrent_score: 13.0\tAverage score: 12.94\tloss: 2.1882588863372803\tweighted_loss: 2.1882588863372803\teps: 0.1\tb_decay: 4.8950198459518646e-05\tLearning rate: 0.000613089308298208\n",
      "episode: 489\tCurrent_score: 8.0\tAverage score: 12.89\tloss: 3.252988338470459\tweighted_loss: 3.252988338470459\teps: 0.1\tb_decay: 4.905029865975852e-05\tLearning rate: 0.0006124762189899098\n",
      "episode: 490\tCurrent_score: 10.0\tAverage score: 12.86\tloss: 3.073477268218994\tweighted_loss: 3.073477268218994\teps: 0.1\tb_decay: 4.915039885000638e-05\tLearning rate: 0.0006118637427709199\n",
      "episode: 491\tCurrent_score: 20.0\tAverage score: 12.95\tloss: 2.403632640838623\tweighted_loss: 2.403632640838623\teps: 0.1\tb_decay: 4.925049903026224e-05\tLearning rate: 0.0006112518790281489\n",
      "episode: 492\tCurrent_score: 17.0\tAverage score: 13.04\tloss: 3.8733038902282715\tweighted_loss: 3.8733038902282715\teps: 0.1\tb_decay: 4.935059920041507e-05\tLearning rate: 0.0006106406271491208\n",
      "episode: 493\tCurrent_score: 16.0\tAverage score: 12.98\tloss: 3.3984880447387695\tweighted_loss: 3.3984880447387695\teps: 0.1\tb_decay: 4.945069936057589e-05\tLearning rate: 0.0006100299865219716\n",
      "episode: 494\tCurrent_score: 3.0\tAverage score: 12.83\tloss: 3.2587687969207764\tweighted_loss: 3.2587687969207764\teps: 0.1\tb_decay: 4.95507995107447e-05\tLearning rate: 0.0006094199565354496\n",
      "episode: 495\tCurrent_score: 14.0\tAverage score: 12.85\tloss: 3.292769432067871\tweighted_loss: 3.292769432067871\teps: 0.1\tb_decay: 4.965089965092151e-05\tLearning rate: 0.0006088105365789142\n",
      "episode: 496\tCurrent_score: 9.0\tAverage score: 12.86\tloss: 3.4791643619537354\tweighted_loss: 3.4791643619537354\teps: 0.1\tb_decay: 4.9750999780995286e-05\tLearning rate: 0.0006082017260423352\n",
      "episode: 497\tCurrent_score: 12.0\tAverage score: 12.84\tloss: 1.9259052276611328\tweighted_loss: 1.9259052276611328\teps: 0.1\tb_decay: 4.985109990118808e-05\tLearning rate: 0.0006075935243162929\n",
      "episode: 498\tCurrent_score: 14.0\tAverage score: 12.75\tloss: 3.644473075866699\tweighted_loss: 3.644473075866699\teps: 0.1\tb_decay: 4.995120001116682e-05\tLearning rate: 0.0006069859307919766\n",
      "episode: 499\tCurrent_score: 11.0\tAverage score: 12.72\tloss: 3.8643388748168945\tweighted_loss: 3.8643388748168945\teps: 0.1\tb_decay: 5.0051300111264574e-05\tLearning rate: 0.0006063789448611846\n",
      "episode: 500\tCurrent_score: 14.0\tAverage score: 12.74\tloss: 2.890429735183716\tweighted_loss: 2.890429735183716\teps: 0.1\tb_decay: 5.01514002012593e-05\tLearning rate: 0.0006057725659163234\n",
      "episode: 501\tCurrent_score: 7.0\tAverage score: 12.6\tloss: 2.3403356075286865\tweighted_loss: 2.3403356075286865\teps: 0.1\tb_decay: 5.025150028137304e-05\tLearning rate: 0.0006051667933504072\n",
      "episode: 502\tCurrent_score: 9.0\tAverage score: 12.55\tloss: 2.0975914001464844\tweighted_loss: 2.0975914001464844\teps: 0.1\tb_decay: 5.035160035127273e-05\tLearning rate: 0.0006045616265570568\n",
      "episode: 503\tCurrent_score: 13.0\tAverage score: 12.5\tloss: 2.3192014694213867\tweighted_loss: 2.3192014694213867\teps: 0.1\tb_decay: 5.0451700411291434e-05\tLearning rate: 0.0006039570649304997\n",
      "episode: 504\tCurrent_score: 5.0\tAverage score: 12.42\tloss: 2.4156880378723145\tweighted_loss: 2.4156880378723145\teps: 0.1\tb_decay: 5.055180046120711e-05\tLearning rate: 0.0006033531078655692\n",
      "episode: 505\tCurrent_score: 18.0\tAverage score: 12.45\tloss: 4.005101203918457\tweighted_loss: 4.005101203918457\teps: 0.1\tb_decay: 5.06519005012418e-05\tLearning rate: 0.0006027497547577036\n",
      "episode: 506\tCurrent_score: 14.0\tAverage score: 12.5\tloss: 2.451404333114624\tweighted_loss: 2.451404333114624\teps: 0.1\tb_decay: 5.0752000531062436e-05\tLearning rate: 0.0006021470050029459\n",
      "episode: 507\tCurrent_score: 10.0\tAverage score: 12.49\tloss: 2.5330545902252197\tweighted_loss: 2.5330545902252197\teps: 0.1\tb_decay: 5.085210055100209e-05\tLearning rate: 0.000601544857997943\n",
      "episode: 508\tCurrent_score: 12.0\tAverage score: 12.48\tloss: 3.1381473541259766\tweighted_loss: 3.1381473541259766\teps: 0.1\tb_decay: 5.095220056083871e-05\tLearning rate: 0.000600943313139945\n",
      "episode: 509\tCurrent_score: 10.0\tAverage score: 12.42\tloss: 2.9162769317626953\tweighted_loss: 2.9162769317626953\teps: 0.1\tb_decay: 5.105230056068333e-05\tLearning rate: 0.000600342369826805\n",
      "episode: 510\tCurrent_score: 13.0\tAverage score: 12.47\tloss: 2.0521128177642822\tweighted_loss: 2.0521128177642822\teps: 0.1\tb_decay: 5.115240055053594e-05\tLearning rate: 0.0005997420274569782\n",
      "episode: 511\tCurrent_score: 17.0\tAverage score: 12.56\tloss: 3.084799289703369\tweighted_loss: 3.084799289703369\teps: 0.1\tb_decay: 5.125250053039654e-05\tLearning rate: 0.0005991422854295213\n",
      "episode: 512\tCurrent_score: 13.0\tAverage score: 12.57\tloss: 3.6120524406433105\tweighted_loss: 3.6120524406433105\teps: 0.1\tb_decay: 5.135260050015411e-05\tLearning rate: 0.0005985431431440917\n",
      "episode: 513\tCurrent_score: 8.0\tAverage score: 12.47\tloss: 3.01450252532959\tweighted_loss: 3.01450252532959\teps: 0.1\tb_decay: 5.1452700459919676e-05\tLearning rate: 0.0005979446000009477\n",
      "episode: 514\tCurrent_score: 12.0\tAverage score: 12.44\tloss: 3.834317922592163\tweighted_loss: 3.834317922592163\teps: 0.1\tb_decay: 5.1552800409693234e-05\tLearning rate: 0.0005973466554009467\n",
      "episode: 515\tCurrent_score: 9.0\tAverage score: 12.34\tloss: 2.530456781387329\tweighted_loss: 2.530456781387329\teps: 0.1\tb_decay: 5.165290034936376e-05\tLearning rate: 0.0005967493087455458\n",
      "episode: 516\tCurrent_score: 17.0\tAverage score: 12.44\tloss: 2.9930708408355713\tweighted_loss: 2.9930708408355713\teps: 0.1\tb_decay: 5.1753000279153305e-05\tLearning rate: 0.0005961525594368002\n",
      "episode: 517\tCurrent_score: 19.0\tAverage score: 12.47\tloss: 3.3667898178100586\tweighted_loss: 3.3667898178100586\teps: 0.1\tb_decay: 5.185310019883982e-05\tLearning rate: 0.0005955564068773634\n",
      "episode: 518\tCurrent_score: 15.0\tAverage score: 12.45\tloss: 3.1272616386413574\tweighted_loss: 3.1272616386413574\teps: 0.1\tb_decay: 5.1953200108534325e-05\tLearning rate: 0.0005949608504704861\n",
      "episode: 519\tCurrent_score: 15.0\tAverage score: 12.47\tloss: 3.4947948455810547\tweighted_loss: 3.4947948455810547\teps: 0.1\tb_decay: 5.20533000081258e-05\tLearning rate: 0.0005943658896200156\n",
      "episode: 520\tCurrent_score: 11.0\tAverage score: 12.51\tloss: 2.097522497177124\tweighted_loss: 2.097522497177124\teps: 0.1\tb_decay: 5.215339989772527e-05\tLearning rate: 0.0005937715237303955\n",
      "episode: 521\tCurrent_score: 17.0\tAverage score: 12.55\tloss: 3.387943983078003\tweighted_loss: 3.387943983078003\teps: 0.1\tb_decay: 5.2253499777332735e-05\tLearning rate: 0.0005931777522066651\n",
      "episode: 522\tCurrent_score: 9.0\tAverage score: 12.52\tloss: 2.5210788249969482\tweighted_loss: 2.5210788249969482\teps: 0.1\tb_decay: 5.235359964694819e-05\tLearning rate: 0.0005925845744544585\n",
      "episode: 523\tCurrent_score: 10.0\tAverage score: 12.54\tloss: 1.8982850313186646\tweighted_loss: 1.8982850313186646\teps: 0.1\tb_decay: 5.245369950657164e-05\tLearning rate: 0.000591991989880004\n",
      "episode: 524\tCurrent_score: 16.0\tAverage score: 12.56\tloss: 3.810014009475708\tweighted_loss: 3.810014009475708\teps: 0.1\tb_decay: 5.255379935609206e-05\tLearning rate: 0.000591399997890124\n",
      "episode: 525\tCurrent_score: 10.0\tAverage score: 12.56\tloss: 3.932971477508545\tweighted_loss: 3.932971477508545\teps: 0.1\tb_decay: 5.265389919562047e-05\tLearning rate: 0.0005908085978922338\n",
      "episode: 526\tCurrent_score: 15.0\tAverage score: 12.6\tloss: 3.0448074340820312\tweighted_loss: 3.0448074340820312\teps: 0.1\tb_decay: 5.275399902504585e-05\tLearning rate: 0.0005902177892943416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 527\tCurrent_score: 14.0\tAverage score: 12.64\tloss: 3.091005325317383\tweighted_loss: 3.091005325317383\teps: 0.1\tb_decay: 5.285409884459025e-05\tLearning rate: 0.0005896275715050472\n",
      "episode: 528\tCurrent_score: 11.0\tAverage score: 12.68\tloss: 2.6565210819244385\tweighted_loss: 2.6565210819244385\teps: 0.1\tb_decay: 5.2954198654031615e-05\tLearning rate: 0.0005890379439335422\n",
      "episode: 529\tCurrent_score: 15.0\tAverage score: 12.71\tloss: 3.015188694000244\tweighted_loss: 3.015188694000244\teps: 0.1\tb_decay: 5.3054298453480975e-05\tLearning rate: 0.0005884489059896086\n",
      "episode: 530\tCurrent_score: 10.0\tAverage score: 12.65\tloss: 3.164194107055664\tweighted_loss: 3.164194107055664\teps: 0.1\tb_decay: 5.315439824293833e-05\tLearning rate: 0.0005878604570836191\n",
      "episode: 531\tCurrent_score: 13.0\tAverage score: 12.61\tloss: 3.251633882522583\tweighted_loss: 3.251633882522583\teps: 0.1\tb_decay: 5.325449802229265e-05\tLearning rate: 0.0005872725966265354\n",
      "episode: 532\tCurrent_score: 3.0\tAverage score: 12.52\tloss: 2.856553316116333\tweighted_loss: 2.856553316116333\teps: 0.1\tb_decay: 5.335459779165497e-05\tLearning rate: 0.0005866853240299089\n",
      "episode: 533\tCurrent_score: 10.0\tAverage score: 12.5\tloss: 2.3288967609405518\tweighted_loss: 2.3288967609405518\teps: 0.1\tb_decay: 5.3454697551025276e-05\tLearning rate: 0.0005860986387058789\n",
      "episode: 534\tCurrent_score: 16.0\tAverage score: 12.6\tloss: 2.772897720336914\tweighted_loss: 2.772897720336914\teps: 0.1\tb_decay: 5.355479730040358e-05\tLearning rate: 0.0005855125400671731\n",
      "episode: 535\tCurrent_score: 22.0\tAverage score: 12.74\tloss: 2.750206232070923\tweighted_loss: 2.750206232070923\teps: 0.1\tb_decay: 5.365489703967885e-05\tLearning rate: 0.000584927027527106\n",
      "episode: 536\tCurrent_score: 9.0\tAverage score: 12.68\tloss: 2.540233850479126\tweighted_loss: 2.540233850479126\teps: 0.1\tb_decay: 5.3754996768962116e-05\tLearning rate: 0.0005843421004995789\n",
      "episode: 537\tCurrent_score: 18.0\tAverage score: 12.74\tloss: 3.0606369972229004\tweighted_loss: 3.0606369972229004\teps: 0.1\tb_decay: 5.385509648825337e-05\tLearning rate: 0.0005837577583990793\n",
      "episode: 538\tCurrent_score: 10.0\tAverage score: 12.74\tloss: 3.3857650756835938\tweighted_loss: 3.3857650756835938\teps: 0.1\tb_decay: 5.3955196197552624e-05\tLearning rate: 0.0005831740006406802\n",
      "episode: 539\tCurrent_score: 19.0\tAverage score: 12.77\tloss: 4.012222766876221\tweighted_loss: 4.012222766876221\teps: 0.1\tb_decay: 5.4055295896748845e-05\tLearning rate: 0.0005825908266400395\n",
      "episode: 540\tCurrent_score: 13.0\tAverage score: 12.84\tloss: 2.371584892272949\tweighted_loss: 2.371584892272949\teps: 0.1\tb_decay: 5.415539558595306e-05\tLearning rate: 0.0005820082358133995\n",
      "episode: 541\tCurrent_score: 9.0\tAverage score: 12.8\tloss: 2.9238860607147217\tweighted_loss: 2.9238860607147217\teps: 0.1\tb_decay: 5.4255495265165266e-05\tLearning rate: 0.0005814262275775861\n",
      "episode: 542\tCurrent_score: 11.0\tAverage score: 12.75\tloss: 2.652712106704712\tweighted_loss: 2.652712106704712\teps: 0.1\tb_decay: 5.4355594934385465e-05\tLearning rate: 0.0005808448013500086\n",
      "episode: 543\tCurrent_score: 16.0\tAverage score: 12.79\tloss: 2.74568247795105\tweighted_loss: 2.74568247795105\teps: 0.1\tb_decay: 5.4455694593502635e-05\tLearning rate: 0.0005802639565486586\n",
      "episode: 544\tCurrent_score: 14.0\tAverage score: 12.78\tloss: 3.7382984161376953\tweighted_loss: 3.7382984161376953\teps: 0.1\tb_decay: 5.45557942426278e-05\tLearning rate: 0.0005796836925921099\n",
      "episode: 545\tCurrent_score: 10.0\tAverage score: 12.68\tloss: 2.345607280731201\tweighted_loss: 2.345607280731201\teps: 0.1\tb_decay: 5.465589388176095e-05\tLearning rate: 0.0005791040088995177\n",
      "episode: 546\tCurrent_score: 17.0\tAverage score: 12.7\tloss: 2.2952373027801514\tweighted_loss: 2.2952373027801514\teps: 0.1\tb_decay: 5.47559935109021e-05\tLearning rate: 0.0005785249048906182\n",
      "episode: 547\tCurrent_score: 14.0\tAverage score: 12.63\tloss: 3.005873680114746\tweighted_loss: 3.005873680114746\teps: 0.1\tb_decay: 5.485609312994022e-05\tLearning rate: 0.0005779463799857276\n",
      "episode: 548\tCurrent_score: 21.0\tAverage score: 12.68\tloss: 2.5486254692077637\tweighted_loss: 2.5486254692077637\teps: 0.1\tb_decay: 5.495619273898633e-05\tLearning rate: 0.0005773684336057419\n",
      "episode: 549\tCurrent_score: 16.0\tAverage score: 12.77\tloss: 2.9282991886138916\tweighted_loss: 2.9282991886138916\teps: 0.1\tb_decay: 5.5056292338040436e-05\tLearning rate: 0.0005767910651721361\n",
      "episode: 550\tCurrent_score: 18.0\tAverage score: 12.82\tloss: 3.6112473011016846\tweighted_loss: 3.6112473011016846\teps: 0.1\tb_decay: 5.515639192710253e-05\tLearning rate: 0.000576214274106964\n",
      "episode: 551\tCurrent_score: 13.0\tAverage score: 12.84\tloss: 3.286910057067871\tweighted_loss: 3.286910057067871\teps: 0.1\tb_decay: 5.52564915060616e-05\tLearning rate: 0.000575638059832857\n",
      "episode: 552\tCurrent_score: 14.0\tAverage score: 12.84\tloss: 2.7712583541870117\tweighted_loss: 2.7712583541870117\teps: 0.1\tb_decay: 5.535659107502866e-05\tLearning rate: 0.0005750624217730242\n",
      "episode: 553\tCurrent_score: 15.0\tAverage score: 12.92\tloss: 3.4280200004577637\tweighted_loss: 3.4280200004577637\teps: 0.1\tb_decay: 5.5456690634003714e-05\tLearning rate: 0.0005744873593512512\n",
      "episode: 554\tCurrent_score: 7.0\tAverage score: 12.92\tloss: 3.6947543621063232\tweighted_loss: 3.6947543621063232\teps: 0.1\tb_decay: 5.555679018287574e-05\tLearning rate: 0.0005739128719918999\n",
      "episode: 555\tCurrent_score: 16.0\tAverage score: 12.99\tloss: 3.257964849472046\tweighted_loss: 3.257964849472046\teps: 0.1\tb_decay: 5.5656889721755753e-05\tLearning rate: 0.000573338959119908\n",
      "episode: 556\tCurrent_score: 11.0\tAverage score: 12.93\tloss: 3.1242377758026123\tweighted_loss: 3.1242377758026123\teps: 0.1\tb_decay: 5.575698925064376e-05\tLearning rate: 0.0005727656201607881\n",
      "episode: 557\tCurrent_score: 11.0\tAverage score: 12.87\tloss: 2.256711483001709\tweighted_loss: 2.256711483001709\teps: 0.1\tb_decay: 5.5857088769539764e-05\tLearning rate: 0.0005721928545406273\n",
      "episode: 558\tCurrent_score: 15.0\tAverage score: 12.83\tloss: 3.612149715423584\tweighted_loss: 3.612149715423584\teps: 0.1\tb_decay: 5.595718827844376e-05\tLearning rate: 0.0005716206616860867\n",
      "episode: 559\tCurrent_score: 10.0\tAverage score: 12.79\tloss: 3.819256067276001\tweighted_loss: 3.819256067276001\teps: 0.1\tb_decay: 5.6057287777244724e-05\tLearning rate: 0.0005710490410244006\n",
      "episode: 560\tCurrent_score: 10.0\tAverage score: 12.75\tloss: 2.4190874099731445\tweighted_loss: 2.4190874099731445\teps: 0.1\tb_decay: 5.615738726605368e-05\tLearning rate: 0.0005704779919833762\n",
      "episode: 561\tCurrent_score: 6.0\tAverage score: 12.74\tloss: 3.0576446056365967\tweighted_loss: 3.0576446056365967\teps: 0.1\tb_decay: 5.625748674487063e-05\tLearning rate: 0.0005699075139913928\n",
      "episode: 562\tCurrent_score: 13.0\tAverage score: 12.77\tloss: 3.559795379638672\tweighted_loss: 3.559795379638672\teps: 0.1\tb_decay: 5.6357586213584554e-05\tLearning rate: 0.0005693376064774013\n",
      "episode: 563\tCurrent_score: 14.0\tAverage score: 12.82\tloss: 2.2177817821502686\tweighted_loss: 2.2177817821502686\teps: 0.1\tb_decay: 5.645768567230647e-05\tLearning rate: 0.000568768268870924\n",
      "episode: 564\tCurrent_score: 10.0\tAverage score: 12.8\tloss: 3.762312412261963\tweighted_loss: 3.762312412261963\teps: 0.1\tb_decay: 5.6557785121036375e-05\tLearning rate: 0.0005681995006020531\n",
      "episode: 565\tCurrent_score: 8.0\tAverage score: 12.73\tloss: 2.753392457962036\tweighted_loss: 2.753392457962036\teps: 0.1\tb_decay: 5.6657884559774274e-05\tLearning rate: 0.000567631301101451\n",
      "episode: 566\tCurrent_score: 12.0\tAverage score: 12.72\tloss: 2.0546555519104004\tweighted_loss: 2.0546555519104004\teps: 0.1\tb_decay: 5.6757983988520166e-05\tLearning rate: 0.0005670636698003495\n",
      "episode: 567\tCurrent_score: 22.0\tAverage score: 12.83\tloss: 3.2663321495056152\tweighted_loss: 3.2663321495056152\teps: 0.1\tb_decay: 5.685808340716303e-05\tLearning rate: 0.0005664966061305492\n",
      "episode: 568\tCurrent_score: 15.0\tAverage score: 12.84\tloss: 3.069638967514038\tweighted_loss: 3.069638967514038\teps: 0.1\tb_decay: 5.6958182815813885e-05\tLearning rate: 0.0005659301095244186\n",
      "episode: 569\tCurrent_score: 20.0\tAverage score: 12.89\tloss: 2.704632043838501\tweighted_loss: 2.704632043838501\teps: 0.1\tb_decay: 5.705828221436171e-05\tLearning rate: 0.0005653641794148941\n",
      "episode: 570\tCurrent_score: 9.0\tAverage score: 12.83\tloss: 4.147747039794922\tweighted_loss: 4.147747039794922\teps: 0.1\tb_decay: 5.715838160302855e-05\tLearning rate: 0.0005647988152354792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 571\tCurrent_score: 12.0\tAverage score: 12.83\tloss: 2.9538073539733887\tweighted_loss: 2.9538073539733887\teps: 0.1\tb_decay: 5.7258480981592363e-05\tLearning rate: 0.0005642340164202437\n",
      "episode: 572\tCurrent_score: 12.0\tAverage score: 12.82\tloss: 4.067673206329346\tweighted_loss: 4.067673206329346\teps: 0.1\tb_decay: 5.735858035016417e-05\tLearning rate: 0.0005636697824038234\n",
      "episode: 573\tCurrent_score: 16.0\tAverage score: 12.82\tloss: 4.058019638061523\tweighted_loss: 4.058019638061523\teps: 0.1\tb_decay: 5.7458679708743965e-05\tLearning rate: 0.0005631061126214196\n",
      "episode: 574\tCurrent_score: 11.0\tAverage score: 12.81\tloss: 3.1980035305023193\tweighted_loss: 3.1980035305023193\teps: 0.1\tb_decay: 5.755877905722073e-05\tLearning rate: 0.0005625430065087983\n",
      "episode: 575\tCurrent_score: 13.0\tAverage score: 12.82\tloss: 3.6922857761383057\tweighted_loss: 3.6922857761383057\teps: 0.1\tb_decay: 5.765887839570549e-05\tLearning rate: 0.0005619804635022895\n",
      "episode: 576\tCurrent_score: 9.0\tAverage score: 12.82\tloss: 2.904904842376709\tweighted_loss: 2.904904842376709\teps: 0.1\tb_decay: 5.7758977724198246e-05\tLearning rate: 0.0005614184830387872\n",
      "episode: 577\tCurrent_score: 14.0\tAverage score: 12.8\tloss: 3.405350685119629\tweighted_loss: 3.405350685119629\teps: 0.1\tb_decay: 5.785907704269899e-05\tLearning rate: 0.0005608570645557484\n",
      "episode: 578\tCurrent_score: 9.0\tAverage score: 12.8\tloss: 3.2817463874816895\tweighted_loss: 3.2817463874816895\teps: 0.1\tb_decay: 5.795917635109671e-05\tLearning rate: 0.0005602962074911927\n",
      "episode: 579\tCurrent_score: 10.0\tAverage score: 12.78\tloss: 2.3935470581054688\tweighted_loss: 2.3935470581054688\teps: 0.1\tb_decay: 5.805927564950242e-05\tLearning rate: 0.0005597359112837015\n",
      "episode: 580\tCurrent_score: 18.0\tAverage score: 12.79\tloss: 3.3924038410186768\tweighted_loss: 3.3924038410186768\teps: 0.1\tb_decay: 5.815937493791612e-05\tLearning rate: 0.0005591761753724177\n",
      "episode: 581\tCurrent_score: 19.0\tAverage score: 12.8\tloss: 3.919264316558838\tweighted_loss: 3.919264316558838\teps: 0.1\tb_decay: 5.8259474216337814e-05\tLearning rate: 0.0005586169991970454\n",
      "episode: 582\tCurrent_score: 9.0\tAverage score: 12.79\tloss: 2.8644351959228516\tweighted_loss: 2.8644351959228516\teps: 0.1\tb_decay: 5.835957348465648e-05\tLearning rate: 0.0005580583821978483\n",
      "episode: 583\tCurrent_score: 13.0\tAverage score: 12.78\tloss: 3.4264190196990967\tweighted_loss: 3.4264190196990967\teps: 0.1\tb_decay: 5.845967274298314e-05\tLearning rate: 0.0005575003238156505\n",
      "episode: 584\tCurrent_score: 14.0\tAverage score: 12.81\tloss: 3.400233745574951\tweighted_loss: 3.400233745574951\teps: 0.1\tb_decay: 5.855977199131779e-05\tLearning rate: 0.0005569428234918348\n",
      "episode: 585\tCurrent_score: 7.0\tAverage score: 12.74\tloss: 3.1087985038757324\tweighted_loss: 3.1087985038757324\teps: 0.1\tb_decay: 5.865987122954941e-05\tLearning rate: 0.0005563858806683429\n",
      "episode: 586\tCurrent_score: 19.0\tAverage score: 12.82\tloss: 3.4096381664276123\tweighted_loss: 3.4096381664276123\teps: 0.1\tb_decay: 5.8759970457900046e-05\tLearning rate: 0.0005558294947876746\n",
      "episode: 587\tCurrent_score: 10.0\tAverage score: 12.8\tloss: 2.832493543624878\tweighted_loss: 2.832493543624878\teps: 0.1\tb_decay: 5.886006967614765e-05\tLearning rate: 0.0005552736652928869\n",
      "episode: 588\tCurrent_score: 12.0\tAverage score: 12.79\tloss: 4.42169713973999\tweighted_loss: 4.42169713973999\teps: 0.1\tb_decay: 5.896016888440325e-05\tLearning rate: 0.000554718391627594\n",
      "episode: 589\tCurrent_score: 12.0\tAverage score: 12.83\tloss: 3.0027475357055664\tweighted_loss: 3.0027475357055664\teps: 0.1\tb_decay: 5.906026808255582e-05\tLearning rate: 0.0005541636732359664\n",
      "episode: 590\tCurrent_score: 18.0\tAverage score: 12.91\tloss: 1.9039183855056763\tweighted_loss: 1.9039183855056763\teps: 0.1\tb_decay: 5.916036727082741e-05\tLearning rate: 0.0005536095095627305\n",
      "episode: 591\tCurrent_score: 9.0\tAverage score: 12.8\tloss: 3.570009231567383\tweighted_loss: 3.570009231567383\teps: 0.1\tb_decay: 5.926046644899596e-05\tLearning rate: 0.0005530559000531677\n",
      "episode: 592\tCurrent_score: 6.0\tAverage score: 12.69\tloss: 2.925400733947754\tweighted_loss: 2.925400733947754\teps: 0.1\tb_decay: 5.936056561706149e-05\tLearning rate: 0.0005525028441531146\n",
      "episode: 593\tCurrent_score: 11.0\tAverage score: 12.64\tloss: 2.7596871852874756\tweighted_loss: 2.7596871852874756\teps: 0.1\tb_decay: 5.946066477524603e-05\tLearning rate: 0.0005519503413089614\n",
      "episode: 594\tCurrent_score: 13.0\tAverage score: 12.74\tloss: 2.5090420246124268\tweighted_loss: 2.5090420246124268\teps: 0.1\tb_decay: 5.956076392332754e-05\tLearning rate: 0.0005513983909676524\n",
      "episode: 595\tCurrent_score: 18.0\tAverage score: 12.78\tloss: 2.8150696754455566\tweighted_loss: 2.8150696754455566\teps: 0.1\tb_decay: 5.9660863061417047e-05\tLearning rate: 0.0005508469925766847\n",
      "episode: 596\tCurrent_score: 14.0\tAverage score: 12.83\tloss: 2.455166816711426\tweighted_loss: 2.455166816711426\teps: 0.1\tb_decay: 5.9760962189514544e-05\tLearning rate: 0.0005502961455841081\n",
      "episode: 597\tCurrent_score: 15.0\tAverage score: 12.86\tloss: 2.4881672859191895\tweighted_loss: 2.4881672859191895\teps: 0.1\tb_decay: 5.986106130750901e-05\tLearning rate: 0.000549745849438524\n",
      "episode: 598\tCurrent_score: 14.0\tAverage score: 12.86\tloss: 3.1563074588775635\tweighted_loss: 3.1563074588775635\teps: 0.1\tb_decay: 5.9961160415622494e-05\tLearning rate: 0.0005491961035890855\n",
      "episode: 599\tCurrent_score: 13.0\tAverage score: 12.88\tloss: 3.1713614463806152\tweighted_loss: 3.1713614463806152\teps: 0.1\tb_decay: 6.006125951363295e-05\tLearning rate: 0.0005486469074854964\n",
      "episode: 600\tCurrent_score: 7.0\tAverage score: 12.81\tloss: 3.3180575370788574\tweighted_loss: 3.3180575370788574\teps: 0.1\tb_decay: 6.016135860154037e-05\tLearning rate: 0.0005480982605780109\n",
      "episode: 601\tCurrent_score: 16.0\tAverage score: 12.9\tloss: 3.7498350143432617\tweighted_loss: 3.7498350143432617\teps: 0.1\tb_decay: 6.026145767956681e-05\tLearning rate: 0.0005475501623174329\n",
      "episode: 602\tCurrent_score: 8.0\tAverage score: 12.89\tloss: 3.9715278148651123\tweighted_loss: 3.9715278148651123\teps: 0.1\tb_decay: 6.036155674749022e-05\tLearning rate: 0.0005470026121551154\n",
      "episode: 603\tCurrent_score: 17.0\tAverage score: 12.93\tloss: 3.074035167694092\tweighted_loss: 3.074035167694092\teps: 0.1\tb_decay: 6.046165580542162e-05\tLearning rate: 0.0005464556095429603\n",
      "episode: 604\tCurrent_score: 19.0\tAverage score: 13.07\tloss: 2.394334077835083\tweighted_loss: 2.394334077835083\teps: 0.1\tb_decay: 6.0561754853361016e-05\tLearning rate: 0.0005459091539334174\n",
      "episode: 605\tCurrent_score: 17.0\tAverage score: 13.06\tloss: 3.7368810176849365\tweighted_loss: 3.7368810176849365\teps: 0.1\tb_decay: 6.066185389119738e-05\tLearning rate: 0.0005453632447794839\n",
      "episode: 606\tCurrent_score: 9.0\tAverage score: 13.01\tloss: 1.561356544494629\tweighted_loss: 1.561356544494629\teps: 0.1\tb_decay: 6.076195291915276e-05\tLearning rate: 0.0005448178815347045\n",
      "episode: 607\tCurrent_score: 14.0\tAverage score: 13.05\tloss: 3.17704439163208\tweighted_loss: 3.17704439163208\teps: 0.1\tb_decay: 6.086205193689409e-05\tLearning rate: 0.0005442730636531697\n",
      "episode: 608\tCurrent_score: 17.0\tAverage score: 13.1\tloss: 2.4670751094818115\tweighted_loss: 2.4670751094818115\teps: 0.1\tb_decay: 6.0962150944754434e-05\tLearning rate: 0.0005437287905895165\n",
      "episode: 609\tCurrent_score: 9.0\tAverage score: 13.09\tloss: 2.9503917694091797\tweighted_loss: 2.9503917694091797\teps: 0.1\tb_decay: 6.106224994262277e-05\tLearning rate: 0.000543185061798927\n",
      "episode: 610\tCurrent_score: 11.0\tAverage score: 13.07\tloss: 3.8808531761169434\tweighted_loss: 3.8808531761169434\teps: 0.1\tb_decay: 6.116234893038808e-05\tLearning rate: 0.0005426418767371282\n",
      "episode: 611\tCurrent_score: 11.0\tAverage score: 13.01\tloss: 3.0442585945129395\tweighted_loss: 3.0442585945129395\teps: 0.1\tb_decay: 6.126244790816138e-05\tLearning rate: 0.000542099234860391\n",
      "episode: 612\tCurrent_score: 17.0\tAverage score: 13.05\tloss: 3.2521555423736572\tweighted_loss: 3.2521555423736572\teps: 0.1\tb_decay: 6.136254687583165e-05\tLearning rate: 0.0005415571356255306\n",
      "episode: 613\tCurrent_score: 20.0\tAverage score: 13.17\tloss: 3.4960010051727295\tweighted_loss: 3.4960010051727295\teps: 0.1\tb_decay: 6.146264583362093e-05\tLearning rate: 0.000541015578489905\n",
      "episode: 614\tCurrent_score: 11.0\tAverage score: 13.16\tloss: 2.7582411766052246\tweighted_loss: 2.7582411766052246\teps: 0.1\tb_decay: 6.156274478130719e-05\tLearning rate: 0.0005404745629114151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 615\tCurrent_score: 10.0\tAverage score: 13.17\tloss: 2.21235728263855\tweighted_loss: 2.21235728263855\teps: 0.1\tb_decay: 6.166284371900144e-05\tLearning rate: 0.0005399340883485037\n",
      "episode: 616\tCurrent_score: 10.0\tAverage score: 13.1\tloss: 2.464578866958618\tweighted_loss: 2.464578866958618\teps: 0.1\tb_decay: 6.176294264670368e-05\tLearning rate: 0.0005393941542601552\n",
      "episode: 617\tCurrent_score: 17.0\tAverage score: 13.08\tloss: 2.91471004486084\tweighted_loss: 2.91471004486084\teps: 0.1\tb_decay: 6.186304156430289e-05\tLearning rate: 0.0005388547601058951\n",
      "episode: 618\tCurrent_score: 10.0\tAverage score: 13.03\tloss: 3.0372183322906494\tweighted_loss: 3.0372183322906494\teps: 0.1\tb_decay: 6.19631404719101e-05\tLearning rate: 0.0005383159053457892\n",
      "episode: 619\tCurrent_score: 16.0\tAverage score: 13.04\tloss: 2.620516061782837\tweighted_loss: 2.620516061782837\teps: 0.1\tb_decay: 6.206323936952529e-05\tLearning rate: 0.0005377775894404433\n",
      "episode: 620\tCurrent_score: 18.0\tAverage score: 13.11\tloss: 2.365590810775757\tweighted_loss: 2.365590810775757\teps: 0.1\tb_decay: 6.216333825714848e-05\tLearning rate: 0.0005372398118510029\n",
      "episode: 621\tCurrent_score: 8.0\tAverage score: 13.02\tloss: 2.38443922996521\tweighted_loss: 2.38443922996521\teps: 0.1\tb_decay: 6.226343713466864e-05\tLearning rate: 0.0005367025720391518\n",
      "episode: 622\tCurrent_score: 11.0\tAverage score: 13.04\tloss: 3.459411382675171\tweighted_loss: 3.459411382675171\teps: 0.1\tb_decay: 6.23635360021968e-05\tLearning rate: 0.0005361658694671127\n",
      "episode: 623\tCurrent_score: 14.0\tAverage score: 13.08\tloss: 3.1506876945495605\tweighted_loss: 3.1506876945495605\teps: 0.1\tb_decay: 6.246363485973294e-05\tLearning rate: 0.0005356297035976456\n",
      "episode: 624\tCurrent_score: 12.0\tAverage score: 13.04\tloss: 2.9557344913482666\tweighted_loss: 2.9557344913482666\teps: 0.1\tb_decay: 6.256373370716606e-05\tLearning rate: 0.000535094073894048\n",
      "episode: 625\tCurrent_score: 16.0\tAverage score: 13.1\tloss: 2.5354981422424316\tweighted_loss: 2.5354981422424316\teps: 0.1\tb_decay: 6.266383254471819e-05\tLearning rate: 0.0005345589798201539\n",
      "episode: 626\tCurrent_score: 18.0\tAverage score: 13.13\tloss: 3.3502039909362793\tweighted_loss: 3.3502039909362793\teps: 0.1\tb_decay: 6.276393137216729e-05\tLearning rate: 0.0005340244208403337\n",
      "episode: 627\tCurrent_score: 12.0\tAverage score: 13.11\tloss: 2.016190767288208\tweighted_loss: 2.016190767288208\teps: 0.1\tb_decay: 6.286403018962439e-05\tLearning rate: 0.0005334903964194934\n",
      "episode: 628\tCurrent_score: 12.0\tAverage score: 13.12\tloss: 2.7102298736572266\tweighted_loss: 2.7102298736572266\teps: 0.1\tb_decay: 6.296412899697845e-05\tLearning rate: 0.000532956906023074\n",
      "episode: 629\tCurrent_score: 12.0\tAverage score: 13.09\tloss: 2.9159095287323\tweighted_loss: 2.9159095287323\teps: 0.1\tb_decay: 6.306422779445153e-05\tLearning rate: 0.0005324239491170509\n",
      "episode: 630\tCurrent_score: 15.0\tAverage score: 13.14\tloss: 4.012545108795166\tweighted_loss: 4.012545108795166\teps: 0.1\tb_decay: 6.316432658182158e-05\tLearning rate: 0.0005318915251679338\n",
      "episode: 631\tCurrent_score: 11.0\tAverage score: 13.12\tloss: 3.746440887451172\tweighted_loss: 3.746440887451172\teps: 0.1\tb_decay: 6.326442535919963e-05\tLearning rate: 0.0005313596336427659\n",
      "episode: 632\tCurrent_score: 13.0\tAverage score: 13.22\tloss: 2.8657734394073486\tweighted_loss: 2.8657734394073486\teps: 0.1\tb_decay: 6.336452412647464e-05\tLearning rate: 0.0005308282740091231\n",
      "episode: 633\tCurrent_score: 11.0\tAverage score: 13.23\tloss: 3.5724363327026367\tweighted_loss: 3.5724363327026367\teps: 0.1\tb_decay: 6.346462288375765e-05\tLearning rate: 0.000530297445735114\n",
      "episode: 634\tCurrent_score: 16.0\tAverage score: 13.23\tloss: 3.0109970569610596\tweighted_loss: 3.0109970569610596\teps: 0.1\tb_decay: 6.356472163104865e-05\tLearning rate: 0.0005297671482893788\n",
      "episode: 635\tCurrent_score: 16.0\tAverage score: 13.17\tloss: 2.603959321975708\tweighted_loss: 2.603959321975708\teps: 0.1\tb_decay: 6.366482036834764e-05\tLearning rate: 0.0005292373811410894\n",
      "episode: 636\tCurrent_score: 13.0\tAverage score: 13.21\tloss: 3.061150550842285\tweighted_loss: 3.061150550842285\teps: 0.1\tb_decay: 6.376491909565463e-05\tLearning rate: 0.0005287081437599483\n",
      "episode: 637\tCurrent_score: 5.0\tAverage score: 13.08\tloss: 2.935401678085327\tweighted_loss: 2.935401678085327\teps: 0.1\tb_decay: 6.386501781285858e-05\tLearning rate: 0.0005281794356161883\n",
      "episode: 638\tCurrent_score: 19.0\tAverage score: 13.17\tloss: 3.153986692428589\tweighted_loss: 3.153986692428589\teps: 0.1\tb_decay: 6.396511652007053e-05\tLearning rate: 0.0005276512561805722\n",
      "episode: 639\tCurrent_score: 11.0\tAverage score: 13.09\tloss: 2.9941904544830322\tweighted_loss: 2.9941904544830322\teps: 0.1\tb_decay: 6.406521521729047e-05\tLearning rate: 0.0005271236049243916\n",
      "episode: 640\tCurrent_score: 13.0\tAverage score: 13.09\tloss: 2.400883197784424\tweighted_loss: 2.400883197784424\teps: 0.1\tb_decay: 6.416531390440738e-05\tLearning rate: 0.0005265964813194672\n",
      "episode: 641\tCurrent_score: 12.0\tAverage score: 13.12\tloss: 2.695622444152832\tweighted_loss: 2.695622444152832\teps: 0.1\tb_decay: 6.426541258164331e-05\tLearning rate: 0.0005260698848381477\n",
      "episode: 642\tCurrent_score: 9.0\tAverage score: 13.1\tloss: 2.5988383293151855\tweighted_loss: 2.5988383293151855\teps: 0.1\tb_decay: 6.436551124877621e-05\tLearning rate: 0.0005255438149533095\n",
      "episode: 643\tCurrent_score: 18.0\tAverage score: 13.12\tloss: 2.624000072479248\tweighted_loss: 2.624000072479248\teps: 0.1\tb_decay: 6.446560990580608e-05\tLearning rate: 0.0005250182711383563\n",
      "episode: 644\tCurrent_score: 9.0\tAverage score: 13.07\tloss: 3.1570839881896973\tweighted_loss: 3.1570839881896973\teps: 0.1\tb_decay: 6.456570855295496e-05\tLearning rate: 0.000524493252867218\n",
      "episode: 645\tCurrent_score: 14.0\tAverage score: 13.11\tloss: 4.84519100189209\tweighted_loss: 4.84519100189209\teps: 0.1\tb_decay: 6.466580719000081e-05\tLearning rate: 0.0005239687596143507\n",
      "episode: 646\tCurrent_score: 5.0\tAverage score: 12.99\tloss: 2.543635368347168\tweighted_loss: 2.543635368347168\teps: 0.1\tb_decay: 6.476590581705466e-05\tLearning rate: 0.0005234447908547364\n",
      "episode: 647\tCurrent_score: 18.0\tAverage score: 13.03\tloss: 2.82108211517334\tweighted_loss: 2.82108211517334\teps: 0.1\tb_decay: 6.48660044341165e-05\tLearning rate: 0.0005229213460638816\n",
      "episode: 648\tCurrent_score: 16.0\tAverage score: 12.98\tloss: 3.4989805221557617\tweighted_loss: 3.4989805221557617\teps: 0.1\tb_decay: 6.496610304107531e-05\tLearning rate: 0.0005223984247178178\n",
      "episode: 649\tCurrent_score: 15.0\tAverage score: 12.97\tloss: 2.762284994125366\tweighted_loss: 2.762284994125366\teps: 0.1\tb_decay: 6.506620163804211e-05\tLearning rate: 0.0005218760262931\n",
      "episode: 650\tCurrent_score: 14.0\tAverage score: 12.93\tloss: 3.1089463233947754\tweighted_loss: 3.1089463233947754\teps: 0.1\tb_decay: 6.51663002250169e-05\tLearning rate: 0.0005213541502668068\n",
      "episode: 651\tCurrent_score: 16.0\tAverage score: 12.96\tloss: 2.971515655517578\tweighted_loss: 2.971515655517578\teps: 0.1\tb_decay: 6.526639880199969e-05\tLearning rate: 0.00052083279611654\n",
      "episode: 652\tCurrent_score: 18.0\tAverage score: 13.0\tloss: 2.4980742931365967\tweighted_loss: 2.4980742931365967\teps: 0.1\tb_decay: 6.536649736887945e-05\tLearning rate: 0.0005203119633204235\n",
      "episode: 653\tCurrent_score: 12.0\tAverage score: 12.97\tloss: 3.3958935737609863\tweighted_loss: 3.3958935737609863\teps: 0.1\tb_decay: 6.546659592587822e-05\tLearning rate: 0.000519791651357103\n",
      "episode: 654\tCurrent_score: 14.0\tAverage score: 13.04\tloss: 2.766620397567749\tweighted_loss: 2.766620397567749\teps: 0.1\tb_decay: 6.556669447277397e-05\tLearning rate: 0.0005192718597057459\n",
      "episode: 655\tCurrent_score: 15.0\tAverage score: 13.03\tloss: 3.8887641429901123\tweighted_loss: 3.8887641429901123\teps: 0.1\tb_decay: 6.566679300956668e-05\tLearning rate: 0.0005187525878460401\n",
      "episode: 656\tCurrent_score: 19.0\tAverage score: 13.11\tloss: 3.2127537727355957\tweighted_loss: 3.2127537727355957\teps: 0.1\tb_decay: 6.576689153647841e-05\tLearning rate: 0.0005182338352581941\n",
      "episode: 657\tCurrent_score: 13.0\tAverage score: 13.13\tloss: 3.458500862121582\tweighted_loss: 3.458500862121582\teps: 0.1\tb_decay: 6.586699005328711e-05\tLearning rate: 0.000517715601422936\n",
      "episode: 658\tCurrent_score: 10.0\tAverage score: 13.08\tloss: 2.657088279724121\tweighted_loss: 2.657088279724121\teps: 0.1\tb_decay: 6.59670885601038e-05\tLearning rate: 0.000517197885821513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 659\tCurrent_score: 17.0\tAverage score: 13.15\tloss: 4.231800079345703\tweighted_loss: 4.231800079345703\teps: 0.1\tb_decay: 6.606718705681747e-05\tLearning rate: 0.0005166806879356914\n",
      "episode: 660\tCurrent_score: 15.0\tAverage score: 13.2\tloss: 3.252017021179199\tweighted_loss: 3.252017021179199\teps: 0.1\tb_decay: 6.616728554365015e-05\tLearning rate: 0.0005161640072477557\n",
      "episode: 661\tCurrent_score: 9.0\tAverage score: 13.23\tloss: 4.153443813323975\tweighted_loss: 4.153443813323975\teps: 0.1\tb_decay: 6.62673840203798e-05\tLearning rate: 0.000515647843240508\n",
      "episode: 662\tCurrent_score: 14.0\tAverage score: 13.24\tloss: 2.992901563644409\tweighted_loss: 2.992901563644409\teps: 0.1\tb_decay: 6.636748248711744e-05\tLearning rate: 0.0005151321953972674\n",
      "episode: 663\tCurrent_score: 17.0\tAverage score: 13.27\tloss: 3.1090774536132812\tweighted_loss: 3.1090774536132812\teps: 0.1\tb_decay: 6.646758094386307e-05\tLearning rate: 0.0005146170632018702\n",
      "episode: 664\tCurrent_score: 9.0\tAverage score: 13.26\tloss: 3.0167272090911865\tweighted_loss: 3.0167272090911865\teps: 0.1\tb_decay: 6.656767939050567e-05\tLearning rate: 0.0005141024461386683\n",
      "episode: 665\tCurrent_score: 16.0\tAverage score: 13.34\tloss: 3.516738176345825\tweighted_loss: 3.516738176345825\teps: 0.1\tb_decay: 6.666777782715627e-05\tLearning rate: 0.0005135883436925297\n",
      "episode: 666\tCurrent_score: 12.0\tAverage score: 13.34\tloss: 3.0539557933807373\tweighted_loss: 3.0539557933807373\teps: 0.1\tb_decay: 6.676787625381486e-05\tLearning rate: 0.0005130747553488372\n",
      "episode: 667\tCurrent_score: 19.0\tAverage score: 13.31\tloss: 2.5557968616485596\tweighted_loss: 2.5557968616485596\teps: 0.1\tb_decay: 6.686797467037042e-05\tLearning rate: 0.0005125616805934883\n",
      "episode: 668\tCurrent_score: 12.0\tAverage score: 13.28\tloss: 2.7214763164520264\tweighted_loss: 2.7214763164520264\teps: 0.1\tb_decay: 6.6968073077045e-05\tLearning rate: 0.0005120491189128948\n",
      "episode: 669\tCurrent_score: 15.0\tAverage score: 13.23\tloss: 4.369515895843506\tweighted_loss: 4.369515895843506\teps: 0.1\tb_decay: 6.706817147361654e-05\tLearning rate: 0.000511537069793982\n",
      "episode: 670\tCurrent_score: 19.0\tAverage score: 13.33\tloss: 3.0302417278289795\tweighted_loss: 3.0302417278289795\teps: 0.1\tb_decay: 6.716826986019608e-05\tLearning rate: 0.000511025532724188\n",
      "episode: 671\tCurrent_score: 7.0\tAverage score: 13.28\tloss: 3.345242977142334\tweighted_loss: 3.345242977142334\teps: 0.1\tb_decay: 6.72683682366726e-05\tLearning rate: 0.0005105145071914638\n",
      "episode: 672\tCurrent_score: 20.0\tAverage score: 13.36\tloss: 3.632387638092041\tweighted_loss: 3.632387638092041\teps: 0.1\tb_decay: 6.736846660326812e-05\tLearning rate: 0.0005100039926842724\n",
      "episode: 673\tCurrent_score: 13.0\tAverage score: 13.33\tloss: 4.005926609039307\tweighted_loss: 4.005926609039307\teps: 0.1\tb_decay: 6.746856495976061e-05\tLearning rate: 0.0005094939886915882\n",
      "episode: 674\tCurrent_score: 8.0\tAverage score: 13.3\tloss: 2.1570322513580322\tweighted_loss: 2.1570322513580322\teps: 0.1\tb_decay: 6.75686633062611e-05\tLearning rate: 0.0005089844947028966\n",
      "episode: 675\tCurrent_score: 11.0\tAverage score: 13.28\tloss: 3.5285677909851074\tweighted_loss: 3.5285677909851074\teps: 0.1\tb_decay: 6.766876164265856e-05\tLearning rate: 0.0005084755102081937\n",
      "episode: 676\tCurrent_score: 14.0\tAverage score: 13.33\tloss: 3.145800828933716\tweighted_loss: 3.145800828933716\teps: 0.1\tb_decay: 6.776885996906401e-05\tLearning rate: 0.0005079670346979855\n",
      "episode: 677\tCurrent_score: 15.0\tAverage score: 13.34\tloss: 3.1172258853912354\tweighted_loss: 3.1172258853912354\teps: 0.1\tb_decay: 6.786895828558848e-05\tLearning rate: 0.0005074590676632876\n",
      "episode: 678\tCurrent_score: 11.0\tAverage score: 13.36\tloss: 3.8595454692840576\tweighted_loss: 3.8595454692840576\teps: 0.1\tb_decay: 6.796905659189889e-05\tLearning rate: 0.0005069516085956243\n",
      "episode: 679\tCurrent_score: 18.0\tAverage score: 13.44\tloss: 3.199244976043701\tweighted_loss: 3.199244976043701\teps: 0.1\tb_decay: 6.806915488832832e-05\tLearning rate: 0.0005064446569870287\n",
      "episode: 680\tCurrent_score: 12.0\tAverage score: 13.38\tloss: 3.2672946453094482\tweighted_loss: 3.2672946453094482\teps: 0.1\tb_decay: 6.816925317465472e-05\tLearning rate: 0.0005059382123300416\n",
      "episode: 681\tCurrent_score: 14.0\tAverage score: 13.33\tloss: 4.160721778869629\tweighted_loss: 4.160721778869629\teps: 0.1\tb_decay: 6.826935145098911e-05\tLearning rate: 0.0005054322741177116\n",
      "episode: 682\tCurrent_score: 14.0\tAverage score: 13.38\tloss: 3.1629788875579834\tweighted_loss: 3.1629788875579834\teps: 0.1\tb_decay: 6.83694497173315e-05\tLearning rate: 0.0005049268418435939\n",
      "episode: 683\tCurrent_score: 8.0\tAverage score: 13.33\tloss: 3.496070384979248\tweighted_loss: 3.496070384979248\teps: 0.1\tb_decay: 6.846954797368188e-05\tLearning rate: 0.0005044219150017503\n",
      "episode: 684\tCurrent_score: 11.0\tAverage score: 13.3\tloss: 3.366637706756592\tweighted_loss: 3.366637706756592\teps: 0.1\tb_decay: 6.856964621992923e-05\tLearning rate: 0.0005039174930867485\n",
      "episode: 685\tCurrent_score: 21.0\tAverage score: 13.44\tloss: 3.4689300060272217\tweighted_loss: 3.4689300060272217\teps: 0.1\tb_decay: 6.866974445618457e-05\tLearning rate: 0.0005034135755936618\n",
      "episode: 686\tCurrent_score: 11.0\tAverage score: 13.36\tloss: 3.3251583576202393\tweighted_loss: 3.3251583576202393\teps: 0.1\tb_decay: 6.87698426824479e-05\tLearning rate: 0.0005029101620180681\n",
      "episode: 687\tCurrent_score: 7.0\tAverage score: 13.33\tloss: 3.546144962310791\tweighted_loss: 3.546144962310791\teps: 0.1\tb_decay: 6.88699408986082e-05\tLearning rate: 0.00050240725185605\n",
      "episode: 688\tCurrent_score: 16.0\tAverage score: 13.37\tloss: 3.967949867248535\tweighted_loss: 3.967949867248535\teps: 0.1\tb_decay: 6.89700391047765e-05\tLearning rate: 0.0005019048446041939\n",
      "episode: 689\tCurrent_score: 8.0\tAverage score: 13.33\tloss: 4.146215438842773\tweighted_loss: 4.146215438842773\teps: 0.1\tb_decay: 6.90701373009528e-05\tLearning rate: 0.0005014029397595898\n",
      "episode: 690\tCurrent_score: 15.0\tAverage score: 13.3\tloss: 3.30502986907959\tweighted_loss: 3.30502986907959\teps: 0.1\tb_decay: 6.917023548713708e-05\tLearning rate: 0.0005009015368198302\n",
      "episode: 691\tCurrent_score: 13.0\tAverage score: 13.34\tloss: 3.4879229068756104\tweighted_loss: 3.4879229068756104\teps: 0.1\tb_decay: 6.927033366332935e-05\tLearning rate: 0.0005004006352830104\n",
      "episode: 692\tCurrent_score: 11.0\tAverage score: 13.39\tloss: 2.960313558578491\tweighted_loss: 2.960313558578491\teps: 0.1\tb_decay: 6.93704318294186e-05\tLearning rate: 0.0004999002346477273\n",
      "episode: 693\tCurrent_score: 17.0\tAverage score: 13.45\tloss: 2.892226219177246\tweighted_loss: 2.892226219177246\teps: 0.1\tb_decay: 6.947052998551584e-05\tLearning rate: 0.0004994003344130796\n",
      "episode: 694\tCurrent_score: 16.0\tAverage score: 13.48\tloss: 3.3782715797424316\tweighted_loss: 3.3782715797424316\teps: 0.1\tb_decay: 6.957062813151005e-05\tLearning rate: 0.0004989009340786664\n",
      "episode: 695\tCurrent_score: 11.0\tAverage score: 13.41\tloss: 2.777153968811035\tweighted_loss: 2.777153968811035\teps: 0.1\tb_decay: 6.967072626762327e-05\tLearning rate: 0.0004984020331445878\n",
      "episode: 696\tCurrent_score: 13.0\tAverage score: 13.4\tloss: 3.375380754470825\tweighted_loss: 3.375380754470825\teps: 0.1\tb_decay: 6.977082439363347e-05\tLearning rate: 0.0004979036311114432\n",
      "episode: 697\tCurrent_score: 12.0\tAverage score: 13.37\tloss: 2.760679244995117\tweighted_loss: 2.760679244995117\teps: 0.1\tb_decay: 6.987092250965166e-05\tLearning rate: 0.0004974057274803318\n",
      "episode: 698\tCurrent_score: 14.0\tAverage score: 13.37\tloss: 3.0483486652374268\tweighted_loss: 3.0483486652374268\teps: 0.1\tb_decay: 6.997102061567784e-05\tLearning rate: 0.0004969083217528514\n",
      "episode: 699\tCurrent_score: 17.0\tAverage score: 13.41\tloss: 3.2304563522338867\tweighted_loss: 3.2304563522338867\teps: 0.1\tb_decay: 7.007111871160099e-05\tLearning rate: 0.0004964114134310985\n",
      "episode: 700\tCurrent_score: 12.0\tAverage score: 13.46\tloss: 2.9271955490112305\tweighted_loss: 2.9271955490112305\teps: 0.1\tb_decay: 7.017121679753213e-05\tLearning rate: 0.0004959150020176674\n",
      "episode: 701\tCurrent_score: 19.0\tAverage score: 13.49\tloss: 3.559948682785034\tweighted_loss: 3.559948682785034\teps: 0.1\tb_decay: 7.027131487347127e-05\tLearning rate: 0.0004954190870156497\n",
      "episode: 702\tCurrent_score: 11.0\tAverage score: 13.52\tloss: 3.1104483604431152\tweighted_loss: 3.1104483604431152\teps: 0.1\tb_decay: 7.03714129394184e-05\tLearning rate: 0.000494923667928634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 703\tCurrent_score: 13.0\tAverage score: 13.48\tloss: 2.8517441749572754\tweighted_loss: 2.8517441749572754\teps: 0.1\tb_decay: 7.04715109952625e-05\tLearning rate: 0.0004944287442607054\n",
      "episode: 704\tCurrent_score: 13.0\tAverage score: 13.42\tloss: 3.398583173751831\tweighted_loss: 3.398583173751831\teps: 0.1\tb_decay: 7.057160904122561e-05\tLearning rate: 0.0004939343155164447\n",
      "episode: 705\tCurrent_score: 14.0\tAverage score: 13.39\tloss: 3.3085293769836426\tweighted_loss: 3.3085293769836426\teps: 0.1\tb_decay: 7.067170707697468e-05\tLearning rate: 0.0004934403812009283\n",
      "episode: 706\tCurrent_score: 15.0\tAverage score: 13.45\tloss: 1.8117642402648926\tweighted_loss: 1.8117642402648926\teps: 0.1\tb_decay: 7.077180510284276e-05\tLearning rate: 0.0004929469408197273\n",
      "episode: 707\tCurrent_score: 15.0\tAverage score: 13.46\tloss: 3.6008975505828857\tweighted_loss: 3.6008975505828857\teps: 0.1\tb_decay: 7.087190311871883e-05\tLearning rate: 0.0004924539938789076\n",
      "episode: 708\tCurrent_score: 21.0\tAverage score: 13.5\tloss: 4.9781999588012695\tweighted_loss: 4.9781999588012695\teps: 0.1\tb_decay: 7.097200112449187e-05\tLearning rate: 0.0004919615398850287\n",
      "episode: 709\tCurrent_score: 18.0\tAverage score: 13.59\tloss: 3.517808198928833\tweighted_loss: 3.517808198928833\teps: 0.1\tb_decay: 7.10720991202729e-05\tLearning rate: 0.0004914695783451436\n",
      "episode: 710\tCurrent_score: 14.0\tAverage score: 13.62\tloss: 2.628875970840454\tweighted_loss: 2.628875970840454\teps: 0.1\tb_decay: 7.117219710595091e-05\tLearning rate: 0.0004909781087667985\n",
      "episode: 711\tCurrent_score: 5.0\tAverage score: 13.56\tloss: 2.818870782852173\tweighted_loss: 2.818870782852173\teps: 0.1\tb_decay: 7.127229508174793e-05\tLearning rate: 0.0004904871306580317\n",
      "episode: 712\tCurrent_score: 11.0\tAverage score: 13.5\tloss: 3.4287192821502686\tweighted_loss: 3.4287192821502686\teps: 0.1\tb_decay: 7.137239304744192e-05\tLearning rate: 0.0004899966435273737\n",
      "episode: 713\tCurrent_score: 20.0\tAverage score: 13.5\tloss: 2.8204050064086914\tweighted_loss: 2.8204050064086914\teps: 0.1\tb_decay: 7.14724910031439e-05\tLearning rate: 0.0004895066468838463\n",
      "episode: 714\tCurrent_score: 18.0\tAverage score: 13.57\tloss: 2.7984583377838135\tweighted_loss: 2.7984583377838135\teps: 0.1\tb_decay: 7.157258894874285e-05\tLearning rate: 0.0004890171402369625\n",
      "episode: 715\tCurrent_score: 9.0\tAverage score: 13.56\tloss: 3.2403557300567627\tweighted_loss: 3.2403557300567627\teps: 0.1\tb_decay: 7.167268688446082e-05\tLearning rate: 0.0004885281230967255\n",
      "episode: 716\tCurrent_score: 13.0\tAverage score: 13.59\tloss: 3.142707586288452\tweighted_loss: 3.142707586288452\teps: 0.1\tb_decay: 7.177278481007576e-05\tLearning rate: 0.0004880395949736288\n",
      "episode: 717\tCurrent_score: 16.0\tAverage score: 13.58\tloss: 3.36418080329895\tweighted_loss: 3.36418080329895\teps: 0.1\tb_decay: 7.18728827256987e-05\tLearning rate: 0.0004875515553786552\n",
      "episode: 718\tCurrent_score: 12.0\tAverage score: 13.6\tloss: 4.218438625335693\tweighted_loss: 4.218438625335693\teps: 0.1\tb_decay: 7.19729806312186e-05\tLearning rate: 0.00048706400382327655\n",
      "episode: 719\tCurrent_score: 15.0\tAverage score: 13.59\tloss: 3.7064552307128906\tweighted_loss: 3.7064552307128906\teps: 0.1\tb_decay: 7.207307852674649e-05\tLearning rate: 0.0004865769398194533\n",
      "episode: 720\tCurrent_score: 19.0\tAverage score: 13.6\tloss: 1.6417497396469116\tweighted_loss: 1.6417497396469116\teps: 0.1\tb_decay: 7.21731764123934e-05\tLearning rate: 0.00048609036287963384\n",
      "episode: 721\tCurrent_score: 17.0\tAverage score: 13.69\tloss: 2.581469774246216\tweighted_loss: 2.581469774246216\teps: 0.1\tb_decay: 7.227327428782626e-05\tLearning rate: 0.0004856042725167542\n",
      "episode: 722\tCurrent_score: 7.0\tAverage score: 13.65\tloss: 3.1810860633850098\tweighted_loss: 3.1810860633850098\teps: 0.1\tb_decay: 7.237337215337813e-05\tLearning rate: 0.0004851186682442375\n",
      "episode: 723\tCurrent_score: 13.0\tAverage score: 13.64\tloss: 3.4581220149993896\tweighted_loss: 3.4581220149993896\teps: 0.1\tb_decay: 7.247347000882698e-05\tLearning rate: 0.00048463354957599327\n",
      "episode: 724\tCurrent_score: 9.0\tAverage score: 13.61\tloss: 3.4204742908477783\tweighted_loss: 3.4204742908477783\teps: 0.1\tb_decay: 7.257356785428382e-05\tLearning rate: 0.00048414891602641726\n",
      "episode: 725\tCurrent_score: 14.0\tAverage score: 13.59\tloss: 2.95701265335083\tweighted_loss: 2.95701265335083\teps: 0.1\tb_decay: 7.267366568974865e-05\tLearning rate: 0.00048366476711039086\n",
      "episode: 726\tCurrent_score: 17.0\tAverage score: 13.58\tloss: 2.653640031814575\tweighted_loss: 2.653640031814575\teps: 0.1\tb_decay: 7.277376351522147e-05\tLearning rate: 0.00048318110234328045\n",
      "episode: 727\tCurrent_score: 7.0\tAverage score: 13.53\tloss: 3.5675861835479736\tweighted_loss: 3.5675861835479736\teps: 0.1\tb_decay: 7.287386133059126e-05\tLearning rate: 0.0004826979212409372\n",
      "episode: 728\tCurrent_score: 13.0\tAverage score: 13.54\tloss: 3.2462058067321777\tweighted_loss: 3.2462058067321777\teps: 0.1\tb_decay: 7.297395913596905e-05\tLearning rate: 0.00048221522331969626\n",
      "episode: 729\tCurrent_score: 13.0\tAverage score: 13.55\tloss: 3.6635468006134033\tweighted_loss: 3.6635468006134033\teps: 0.1\tb_decay: 7.307405693135482e-05\tLearning rate: 0.0004817330080963766\n",
      "episode: 730\tCurrent_score: 16.0\tAverage score: 13.56\tloss: 4.100292205810547\tweighted_loss: 4.100292205810547\teps: 0.1\tb_decay: 7.317415471663757e-05\tLearning rate: 0.0004812512750882802\n",
      "episode: 731\tCurrent_score: 7.0\tAverage score: 13.52\tloss: 3.0028882026672363\tweighted_loss: 3.0028882026672363\teps: 0.1\tb_decay: 7.327425249203934e-05\tLearning rate: 0.0004807700238131919\n",
      "episode: 732\tCurrent_score: 14.0\tAverage score: 13.53\tloss: 3.1006264686584473\tweighted_loss: 3.1006264686584473\teps: 0.1\tb_decay: 7.337435025733807e-05\tLearning rate: 0.00048028925378937874\n",
      "episode: 733\tCurrent_score: 18.0\tAverage score: 13.6\tloss: 3.912346124649048\tweighted_loss: 3.912346124649048\teps: 0.1\tb_decay: 7.347444801253378e-05\tLearning rate: 0.00047980896453558934\n",
      "episode: 734\tCurrent_score: 12.0\tAverage score: 13.56\tloss: 3.4367854595184326\tweighted_loss: 3.4367854595184326\teps: 0.1\tb_decay: 7.35745457578485e-05\tLearning rate: 0.0004793291555710537\n",
      "episode: 735\tCurrent_score: 14.0\tAverage score: 13.54\tloss: 2.6383285522460938\tweighted_loss: 2.6383285522460938\teps: 0.1\tb_decay: 7.367464349306019e-05\tLearning rate: 0.00047884982641548265\n",
      "episode: 736\tCurrent_score: 16.0\tAverage score: 13.57\tloss: 3.5002124309539795\tweighted_loss: 3.5002124309539795\teps: 0.1\tb_decay: 7.377474121827987e-05\tLearning rate: 0.00047837097658906714\n",
      "episode: 737\tCurrent_score: 12.0\tAverage score: 13.64\tloss: 3.679309844970703\tweighted_loss: 3.679309844970703\teps: 0.1\tb_decay: 7.387483893350755e-05\tLearning rate: 0.0004778926056124781\n",
      "episode: 738\tCurrent_score: 17.0\tAverage score: 13.62\tloss: 3.124039649963379\tweighted_loss: 3.124039649963379\teps: 0.1\tb_decay: 7.397493663874322e-05\tLearning rate: 0.0004774147130068656\n",
      "episode: 739\tCurrent_score: 13.0\tAverage score: 13.64\tloss: 3.384396553039551\tweighted_loss: 3.384396553039551\teps: 0.1\tb_decay: 7.407503433387586e-05\tLearning rate: 0.0004769372982938587\n",
      "episode: 740\tCurrent_score: 9.0\tAverage score: 13.6\tloss: 2.7508022785186768\tweighted_loss: 2.7508022785186768\teps: 0.1\tb_decay: 7.417513201901649e-05\tLearning rate: 0.0004764603609955649\n",
      "episode: 741\tCurrent_score: 13.0\tAverage score: 13.61\tloss: 2.8740134239196777\tweighted_loss: 2.8740134239196777\teps: 0.1\tb_decay: 7.427522969416511e-05\tLearning rate: 0.00047598390063456934\n",
      "episode: 742\tCurrent_score: 18.0\tAverage score: 13.7\tloss: 2.590482234954834\tweighted_loss: 2.590482234954834\teps: 0.1\tb_decay: 7.437532735921071e-05\tLearning rate: 0.00047550791673393476\n",
      "episode: 743\tCurrent_score: 9.0\tAverage score: 13.61\tloss: 2.7334415912628174\tweighted_loss: 2.7334415912628174\teps: 0.1\tb_decay: 7.44754250142643e-05\tLearning rate: 0.0004750324088172008\n",
      "episode: 744\tCurrent_score: 18.0\tAverage score: 13.7\tloss: 2.6375532150268555\tweighted_loss: 2.6375532150268555\teps: 0.1\tb_decay: 7.457552265932588e-05\tLearning rate: 0.0004745573764083836\n",
      "episode: 745\tCurrent_score: 1.0\tAverage score: 13.57\tloss: 3.683915376663208\tweighted_loss: 3.683915376663208\teps: 0.1\tb_decay: 7.467562029439545e-05\tLearning rate: 0.0004740828190319752\n",
      "episode: 746\tCurrent_score: 19.0\tAverage score: 13.71\tloss: 2.479389190673828\tweighted_loss: 2.479389190673828\teps: 0.1\tb_decay: 7.4775717919362e-05\tLearning rate: 0.0004736087362129432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 747\tCurrent_score: 16.0\tAverage score: 13.69\tloss: 3.8723626136779785\tweighted_loss: 3.8723626136779785\teps: 0.1\tb_decay: 7.487581553444755e-05\tLearning rate: 0.00047313512747673025\n",
      "episode: 748\tCurrent_score: 9.0\tAverage score: 13.62\tloss: 3.207111120223999\tweighted_loss: 3.207111120223999\teps: 0.1\tb_decay: 7.497591313943008e-05\tLearning rate: 0.00047266199234925353\n",
      "episode: 749\tCurrent_score: 13.0\tAverage score: 13.6\tloss: 2.55133056640625\tweighted_loss: 2.55133056640625\teps: 0.1\tb_decay: 7.507601073430958e-05\tLearning rate: 0.0004721893303569043\n",
      "episode: 750\tCurrent_score: 13.0\tAverage score: 13.59\tloss: 2.8667476177215576\tweighted_loss: 2.8667476177215576\teps: 0.1\tb_decay: 7.51761083193081e-05\tLearning rate: 0.0004717171410265474\n",
      "episode: 751\tCurrent_score: 14.0\tAverage score: 13.57\tloss: 3.7809932231903076\tweighted_loss: 3.7809932231903076\teps: 0.1\tb_decay: 7.527620589420358e-05\tLearning rate: 0.00047124542388552083\n",
      "episode: 752\tCurrent_score: 18.0\tAverage score: 13.57\tloss: 2.5446863174438477\tweighted_loss: 2.5446863174438477\teps: 0.1\tb_decay: 7.537630345910706e-05\tLearning rate: 0.0004707741784616353\n",
      "episode: 753\tCurrent_score: 14.0\tAverage score: 13.59\tloss: 3.1342785358428955\tweighted_loss: 3.1342785358428955\teps: 0.1\tb_decay: 7.547640101390751e-05\tLearning rate: 0.00047030340428317366\n",
      "episode: 754\tCurrent_score: 18.0\tAverage score: 13.63\tloss: 3.067843198776245\tweighted_loss: 3.067843198776245\teps: 0.1\tb_decay: 7.557649855882698e-05\tLearning rate: 0.0004698331008788905\n",
      "episode: 755\tCurrent_score: 11.0\tAverage score: 13.59\tloss: 3.628770589828491\tweighted_loss: 3.628770589828491\teps: 0.1\tb_decay: 7.567659609364341e-05\tLearning rate: 0.0004693632677780116\n",
      "episode: 756\tCurrent_score: 20.0\tAverage score: 13.6\tloss: 3.5948779582977295\tweighted_loss: 3.5948779582977295\teps: 0.1\tb_decay: 7.577669361846784e-05\tLearning rate: 0.0004688939045102336\n",
      "episode: 757\tCurrent_score: 12.0\tAverage score: 13.59\tloss: 3.656754970550537\tweighted_loss: 3.656754970550537\teps: 0.1\tb_decay: 7.587679113330026e-05\tLearning rate: 0.00046842501060572335\n",
      "episode: 758\tCurrent_score: 14.0\tAverage score: 13.63\tloss: 2.6741786003112793\tweighted_loss: 2.6741786003112793\teps: 0.1\tb_decay: 7.597688863802965e-05\tLearning rate: 0.00046795658559511765\n",
      "episode: 759\tCurrent_score: 21.0\tAverage score: 13.67\tloss: 2.780263900756836\tweighted_loss: 2.780263900756836\teps: 0.1\tb_decay: 7.607698613276703e-05\tLearning rate: 0.00046748862900952254\n",
      "episode: 760\tCurrent_score: 16.0\tAverage score: 13.68\tloss: 3.57657790184021\tweighted_loss: 3.57657790184021\teps: 0.1\tb_decay: 7.617708361751241e-05\tLearning rate: 0.000467021140380513\n",
      "episode: 761\tCurrent_score: 14.0\tAverage score: 13.73\tloss: 3.0685131549835205\tweighted_loss: 3.0685131549835205\teps: 0.1\tb_decay: 7.627718109226578e-05\tLearning rate: 0.0004665541192401325\n",
      "episode: 762\tCurrent_score: 14.0\tAverage score: 13.73\tloss: 2.842003583908081\tweighted_loss: 2.842003583908081\teps: 0.1\tb_decay: 7.637727855691612e-05\tLearning rate: 0.00046608756512089237\n",
      "episode: 763\tCurrent_score: 14.0\tAverage score: 13.7\tloss: 3.272007703781128\tweighted_loss: 3.272007703781128\teps: 0.1\tb_decay: 7.647737601157445e-05\tLearning rate: 0.00046562147755577145\n",
      "episode: 764\tCurrent_score: 17.0\tAverage score: 13.78\tloss: 3.57373046875\tweighted_loss: 3.57373046875\teps: 0.1\tb_decay: 7.657747345624077e-05\tLearning rate: 0.00046515585607821567\n",
      "episode: 765\tCurrent_score: 16.0\tAverage score: 13.78\tloss: 2.3809680938720703\tweighted_loss: 2.3809680938720703\teps: 0.1\tb_decay: 7.667757089091509e-05\tLearning rate: 0.00046469070022213746\n",
      "episode: 766\tCurrent_score: 15.0\tAverage score: 13.81\tloss: 2.70161509513855\tweighted_loss: 2.70161509513855\teps: 0.1\tb_decay: 7.677766831548638e-05\tLearning rate: 0.0004642260095219153\n",
      "episode: 767\tCurrent_score: 17.0\tAverage score: 13.79\tloss: 3.184695243835449\tweighted_loss: 3.184695243835449\teps: 0.1\tb_decay: 7.687776573006566e-05\tLearning rate: 0.0004637617835123934\n",
      "episode: 768\tCurrent_score: 11.0\tAverage score: 13.78\tloss: 2.953171730041504\tweighted_loss: 2.953171730041504\teps: 0.1\tb_decay: 7.697786313465294e-05\tLearning rate: 0.000463298021728881\n",
      "episode: 769\tCurrent_score: 13.0\tAverage score: 13.76\tloss: 2.734673261642456\tweighted_loss: 2.734673261642456\teps: 0.1\tb_decay: 7.70779605292482e-05\tLearning rate: 0.0004628347237071521\n",
      "episode: 770\tCurrent_score: 17.0\tAverage score: 13.74\tloss: 3.203242540359497\tweighted_loss: 3.203242540359497\teps: 0.1\tb_decay: 7.717805791374044e-05\tLearning rate: 0.00046237188898344496\n",
      "episode: 771\tCurrent_score: 13.0\tAverage score: 13.8\tloss: 2.656517505645752\tweighted_loss: 2.656517505645752\teps: 0.1\tb_decay: 7.727815528824067e-05\tLearning rate: 0.0004619095170944615\n",
      "episode: 772\tCurrent_score: 10.0\tAverage score: 13.7\tloss: 3.212461233139038\tweighted_loss: 3.212461233139038\teps: 0.1\tb_decay: 7.737825265274889e-05\tLearning rate: 0.0004614476075773671\n",
      "episode: 773\tCurrent_score: 15.0\tAverage score: 13.72\tloss: 2.9274778366088867\tweighted_loss: 2.9274778366088867\teps: 0.1\tb_decay: 7.74783500072651e-05\tLearning rate: 0.00046098615996978973\n",
      "episode: 774\tCurrent_score: 10.0\tAverage score: 13.74\tloss: 2.5515975952148438\tweighted_loss: 2.5515975952148438\teps: 0.1\tb_decay: 7.757844735167829e-05\tLearning rate: 0.00046052517380981993\n",
      "episode: 775\tCurrent_score: 14.0\tAverage score: 13.77\tloss: 2.1172380447387695\tweighted_loss: 2.1172380447387695\teps: 0.1\tb_decay: 7.767854468609947e-05\tLearning rate: 0.00046006464863601013\n",
      "episode: 776\tCurrent_score: 3.0\tAverage score: 13.66\tloss: 3.8246827125549316\tweighted_loss: 3.8246827125549316\teps: 0.1\tb_decay: 7.777864201052864e-05\tLearning rate: 0.0004596045839873741\n",
      "episode: 777\tCurrent_score: 9.0\tAverage score: 13.6\tloss: 2.8257358074188232\tweighted_loss: 2.8257358074188232\teps: 0.1\tb_decay: 7.787873932485478e-05\tLearning rate: 0.0004591449794033867\n",
      "episode: 778\tCurrent_score: 16.0\tAverage score: 13.65\tloss: 2.93186616897583\tweighted_loss: 2.93186616897583\teps: 0.1\tb_decay: 7.797883662929994e-05\tLearning rate: 0.0004586858344239833\n",
      "episode: 779\tCurrent_score: 13.0\tAverage score: 13.6\tloss: 2.6542179584503174\tweighted_loss: 2.6542179584503174\teps: 0.1\tb_decay: 7.807893392364207e-05\tLearning rate: 0.00045822714858955935\n",
      "episode: 780\tCurrent_score: 12.0\tAverage score: 13.6\tloss: 2.5687386989593506\tweighted_loss: 2.5687386989593506\teps: 0.1\tb_decay: 7.817903120799219e-05\tLearning rate: 0.0004577689214409698\n",
      "episode: 781\tCurrent_score: 15.0\tAverage score: 13.61\tloss: 2.662858009338379\tweighted_loss: 2.662858009338379\teps: 0.1\tb_decay: 7.827912848223928e-05\tLearning rate: 0.0004573111525195288\n",
      "episode: 782\tCurrent_score: 18.0\tAverage score: 13.65\tloss: 3.6860604286193848\tweighted_loss: 3.6860604286193848\teps: 0.1\tb_decay: 7.837922574649436e-05\tLearning rate: 0.0004568538413670093\n",
      "episode: 783\tCurrent_score: 8.0\tAverage score: 13.65\tloss: 3.3291900157928467\tweighted_loss: 3.3291900157928467\teps: 0.1\tb_decay: 7.847932300075744e-05\tLearning rate: 0.0004563969875256423\n",
      "episode: 784\tCurrent_score: 12.0\tAverage score: 13.66\tloss: 3.3272886276245117\tweighted_loss: 3.3272886276245117\teps: 0.1\tb_decay: 7.857942024502851e-05\tLearning rate: 0.0004559405905381166\n",
      "episode: 785\tCurrent_score: 11.0\tAverage score: 13.56\tloss: 2.367891788482666\tweighted_loss: 2.367891788482666\teps: 0.1\tb_decay: 7.867951747930757e-05\tLearning rate: 0.0004554846499475785\n",
      "episode: 786\tCurrent_score: 17.0\tAverage score: 13.62\tloss: 3.201997756958008\tweighted_loss: 3.201997756958008\teps: 0.1\tb_decay: 7.87796147034836e-05\tLearning rate: 0.0004550291652976309\n",
      "episode: 787\tCurrent_score: 16.0\tAverage score: 13.71\tloss: 2.528034210205078\tweighted_loss: 2.528034210205078\teps: 0.1\tb_decay: 7.887971191766763e-05\tLearning rate: 0.0004545741361323333\n",
      "episode: 788\tCurrent_score: 13.0\tAverage score: 13.68\tloss: 3.423762559890747\tweighted_loss: 3.423762559890747\teps: 0.1\tb_decay: 7.897980912185965e-05\tLearning rate: 0.00045411956199620094\n",
      "episode: 789\tCurrent_score: 13.0\tAverage score: 13.73\tloss: 2.9757156372070312\tweighted_loss: 2.9757156372070312\teps: 0.1\tb_decay: 7.907990631594863e-05\tLearning rate: 0.00045366544243420474\n",
      "episode: 790\tCurrent_score: 13.0\tAverage score: 13.71\tloss: 3.3129594326019287\tweighted_loss: 3.3129594326019287\teps: 0.1\tb_decay: 7.918000350015664e-05\tLearning rate: 0.00045321177699177053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 791\tCurrent_score: 17.0\tAverage score: 13.75\tloss: 2.7725632190704346\tweighted_loss: 2.7725632190704346\teps: 0.1\tb_decay: 7.928010067426161e-05\tLearning rate: 0.0004527585652147788\n",
      "episode: 792\tCurrent_score: 9.0\tAverage score: 13.73\tloss: 3.2553248405456543\tweighted_loss: 3.2553248405456543\teps: 0.1\tb_decay: 7.938019783826356e-05\tLearning rate: 0.000452305806649564\n",
      "episode: 793\tCurrent_score: 9.0\tAverage score: 13.65\tloss: 3.024104595184326\tweighted_loss: 3.024104595184326\teps: 0.1\tb_decay: 7.948029499238451e-05\tLearning rate: 0.00045185350084291445\n",
      "episode: 794\tCurrent_score: 15.0\tAverage score: 13.64\tloss: 2.632863998413086\tweighted_loss: 2.632863998413086\teps: 0.1\tb_decay: 7.958039213640244e-05\tLearning rate: 0.00045140164734207153\n",
      "episode: 795\tCurrent_score: 14.0\tAverage score: 13.67\tloss: 2.792479991912842\tweighted_loss: 2.792479991912842\teps: 0.1\tb_decay: 7.968048927042837e-05\tLearning rate: 0.00045095024569472946\n",
      "episode: 796\tCurrent_score: 15.0\tAverage score: 13.69\tloss: 3.061236619949341\tweighted_loss: 3.061236619949341\teps: 0.1\tb_decay: 7.978058639446228e-05\tLearning rate: 0.00045049929544903474\n",
      "episode: 797\tCurrent_score: 5.0\tAverage score: 13.62\tloss: 3.075148105621338\tweighted_loss: 3.075148105621338\teps: 0.1\tb_decay: 7.988068350839317e-05\tLearning rate: 0.0004500487961535857\n",
      "episode: 798\tCurrent_score: 15.0\tAverage score: 13.63\tloss: 4.046383380889893\tweighted_loss: 4.046383380889893\teps: 0.1\tb_decay: 7.998078061244307e-05\tLearning rate: 0.0004495987473574321\n",
      "episode: 799\tCurrent_score: 14.0\tAverage score: 13.6\tloss: 3.6785149574279785\tweighted_loss: 3.6785149574279785\teps: 0.1\tb_decay: 8.008087770638994e-05\tLearning rate: 0.0004491491486100747\n",
      "episode: 800\tCurrent_score: 13.0\tAverage score: 13.61\tloss: 3.9063832759857178\tweighted_loss: 3.9063832759857178\teps: 0.1\tb_decay: 8.018097479023378e-05\tLearning rate: 0.0004486999994614646\n",
      "episode: 801\tCurrent_score: 13.0\tAverage score: 13.55\tloss: 3.0712459087371826\tweighted_loss: 3.0712459087371826\teps: 0.1\tb_decay: 8.028107186419664e-05\tLearning rate: 0.00044825129946200314\n",
      "episode: 802\tCurrent_score: 13.0\tAverage score: 13.57\tloss: 3.225849151611328\tweighted_loss: 3.225849151611328\teps: 0.1\tb_decay: 8.038116892805647e-05\tLearning rate: 0.00044780304816254116\n",
      "episode: 803\tCurrent_score: 7.0\tAverage score: 13.51\tloss: 3.009321928024292\tweighted_loss: 3.009321928024292\teps: 0.1\tb_decay: 8.048126598192429e-05\tLearning rate: 0.00044735524511437864\n",
      "episode: 804\tCurrent_score: 22.0\tAverage score: 13.6\tloss: 3.2653534412384033\tweighted_loss: 3.2653534412384033\teps: 0.1\tb_decay: 8.05813630258001e-05\tLearning rate: 0.00044690788986926424\n",
      "episode: 805\tCurrent_score: 9.0\tAverage score: 13.55\tloss: 2.991791009902954\tweighted_loss: 2.991791009902954\teps: 0.1\tb_decay: 8.068146005957288e-05\tLearning rate: 0.00044646098197939497\n",
      "episode: 806\tCurrent_score: 11.0\tAverage score: 13.51\tloss: 3.17168927192688\tweighted_loss: 3.17168927192688\teps: 0.1\tb_decay: 8.078155708335366e-05\tLearning rate: 0.00044601452099741557\n",
      "episode: 807\tCurrent_score: 21.0\tAverage score: 13.57\tloss: 3.7712900638580322\tweighted_loss: 3.7712900638580322\teps: 0.1\tb_decay: 8.088165409714243e-05\tLearning rate: 0.0004455685064764182\n",
      "episode: 808\tCurrent_score: 11.0\tAverage score: 13.47\tloss: 4.309269905090332\tweighted_loss: 4.309269905090332\teps: 0.1\tb_decay: 8.098175110093919e-05\tLearning rate: 0.0004451229379699418\n",
      "episode: 809\tCurrent_score: 11.0\tAverage score: 13.4\tloss: 2.228517770767212\tweighted_loss: 2.228517770767212\teps: 0.1\tb_decay: 8.108184809463292e-05\tLearning rate: 0.00044467781503197186\n",
      "episode: 810\tCurrent_score: 17.0\tAverage score: 13.43\tloss: 2.922589063644409\tweighted_loss: 2.922589063644409\teps: 0.1\tb_decay: 8.118194507844567e-05\tLearning rate: 0.0004442331372169399\n",
      "episode: 811\tCurrent_score: 15.0\tAverage score: 13.53\tloss: 3.162506580352783\tweighted_loss: 3.162506580352783\teps: 0.1\tb_decay: 8.128204205204437e-05\tLearning rate: 0.00044378890407972295\n",
      "episode: 812\tCurrent_score: 16.0\tAverage score: 13.58\tloss: 3.0192699432373047\tweighted_loss: 3.0192699432373047\teps: 0.1\tb_decay: 8.138213901576208e-05\tLearning rate: 0.0004433451151756432\n",
      "episode: 813\tCurrent_score: 13.0\tAverage score: 13.51\tloss: 3.191889762878418\tweighted_loss: 3.191889762878418\teps: 0.1\tb_decay: 8.148223596948778e-05\tLearning rate: 0.0004429017700604676\n",
      "episode: 814\tCurrent_score: 15.0\tAverage score: 13.48\tloss: 2.86698317527771\tweighted_loss: 2.86698317527771\teps: 0.1\tb_decay: 8.158233291311046e-05\tLearning rate: 0.00044245886829040714\n",
      "episode: 815\tCurrent_score: 14.0\tAverage score: 13.53\tloss: 2.286771059036255\tweighted_loss: 2.286771059036255\teps: 0.1\tb_decay: 8.168242984674112e-05\tLearning rate: 0.00044201640942211675\n",
      "episode: 816\tCurrent_score: 11.0\tAverage score: 13.51\tloss: 3.005964756011963\tweighted_loss: 3.005964756011963\teps: 0.1\tb_decay: 8.178252677026876e-05\tLearning rate: 0.0004415743930126946\n",
      "episode: 817\tCurrent_score: 12.0\tAverage score: 13.47\tloss: 3.740260362625122\tweighted_loss: 3.740260362625122\teps: 0.1\tb_decay: 8.188262368391541e-05\tLearning rate: 0.0004411328186196819\n",
      "episode: 818\tCurrent_score: 19.0\tAverage score: 13.54\tloss: 2.2223446369171143\tweighted_loss: 2.2223446369171143\teps: 0.1\tb_decay: 8.198272058745903e-05\tLearning rate: 0.00044069168580106226\n",
      "episode: 819\tCurrent_score: 22.0\tAverage score: 13.61\tloss: 3.205418348312378\tweighted_loss: 3.205418348312378\teps: 0.1\tb_decay: 8.208281748101065e-05\tLearning rate: 0.0004402509941152612\n",
      "episode: 820\tCurrent_score: 11.0\tAverage score: 13.53\tloss: 3.783686399459839\tweighted_loss: 3.783686399459839\teps: 0.1\tb_decay: 8.218291436445924e-05\tLearning rate: 0.00043981074312114595\n",
      "episode: 821\tCurrent_score: 17.0\tAverage score: 13.53\tloss: 3.4330251216888428\tweighted_loss: 3.4330251216888428\teps: 0.1\tb_decay: 8.228301123802684e-05\tLearning rate: 0.0004393709323780248\n",
      "episode: 822\tCurrent_score: 20.0\tAverage score: 13.66\tloss: 3.6258153915405273\tweighted_loss: 3.6258153915405273\teps: 0.1\tb_decay: 8.238310810149141e-05\tLearning rate: 0.00043893156144564674\n",
      "episode: 823\tCurrent_score: 10.0\tAverage score: 13.63\tloss: 3.5173027515411377\tweighted_loss: 3.5173027515411377\teps: 0.1\tb_decay: 8.248320495496397e-05\tLearning rate: 0.0004384926298842011\n",
      "episode: 824\tCurrent_score: 14.0\tAverage score: 13.68\tloss: 2.5857207775115967\tweighted_loss: 2.5857207775115967\teps: 0.1\tb_decay: 8.258330179833351e-05\tLearning rate: 0.00043805413725431686\n",
      "episode: 825\tCurrent_score: 10.0\tAverage score: 13.64\tloss: 3.5617785453796387\tweighted_loss: 3.5617785453796387\teps: 0.1\tb_decay: 8.268339863182206e-05\tLearning rate: 0.00043761608311706254\n",
      "episode: 826\tCurrent_score: 12.0\tAverage score: 13.59\tloss: 3.6704063415527344\tweighted_loss: 3.6704063415527344\teps: 0.1\tb_decay: 8.278349545520758e-05\tLearning rate: 0.00043717846703394546\n",
      "episode: 827\tCurrent_score: 16.0\tAverage score: 13.68\tloss: 2.792854070663452\tweighted_loss: 2.792854070663452\teps: 0.1\tb_decay: 8.288359226860109e-05\tLearning rate: 0.0004367412885669115\n",
      "episode: 828\tCurrent_score: 18.0\tAverage score: 13.73\tloss: 4.135672092437744\tweighted_loss: 4.135672092437744\teps: 0.1\tb_decay: 8.298368907189158e-05\tLearning rate: 0.0004363045472783446\n",
      "episode: 829\tCurrent_score: 15.0\tAverage score: 13.75\tloss: 3.9334239959716797\tweighted_loss: 3.9334239959716797\teps: 0.1\tb_decay: 8.308378586530107e-05\tLearning rate: 0.00043586824273106627\n",
      "episode: 830\tCurrent_score: 12.0\tAverage score: 13.71\tloss: 2.6983530521392822\tweighted_loss: 2.6983530521392822\teps: 0.1\tb_decay: 8.318388264860754e-05\tLearning rate: 0.00043543237448833517\n",
      "episode: 831\tCurrent_score: 9.0\tAverage score: 13.73\tloss: 4.67827844619751\tweighted_loss: 4.67827844619751\teps: 0.1\tb_decay: 8.3283979421922e-05\tLearning rate: 0.00043499694211384684\n",
      "episode: 832\tCurrent_score: 14.0\tAverage score: 13.73\tloss: 3.0905871391296387\tweighted_loss: 3.0905871391296387\teps: 0.1\tb_decay: 8.338407618513344e-05\tLearning rate: 0.000434561945171733\n",
      "episode: 833\tCurrent_score: 9.0\tAverage score: 13.64\tloss: 2.8899965286254883\tweighted_loss: 2.8899965286254883\teps: 0.1\tb_decay: 8.348417293846389e-05\tLearning rate: 0.0004341273832265613\n",
      "episode: 834\tCurrent_score: 8.0\tAverage score: 13.6\tloss: 2.1659390926361084\tweighted_loss: 2.1659390926361084\teps: 0.1\tb_decay: 8.35842696816913e-05\tLearning rate: 0.0004336932558433347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 835\tCurrent_score: 11.0\tAverage score: 13.57\tloss: 2.9255008697509766\tweighted_loss: 2.9255008697509766\teps: 0.1\tb_decay: 8.368436641492671e-05\tLearning rate: 0.00043325956258749137\n",
      "episode: 836\tCurrent_score: 16.0\tAverage score: 13.57\tloss: 3.4450793266296387\tweighted_loss: 3.4450793266296387\teps: 0.1\tb_decay: 8.37844631380591e-05\tLearning rate: 0.00043282630302490387\n",
      "episode: 837\tCurrent_score: 13.0\tAverage score: 13.58\tloss: 3.322396993637085\tweighted_loss: 3.322396993637085\teps: 0.1\tb_decay: 8.388455985119947e-05\tLearning rate: 0.000432393476721879\n",
      "episode: 838\tCurrent_score: 11.0\tAverage score: 13.52\tloss: 3.739213705062866\tweighted_loss: 3.739213705062866\teps: 0.1\tb_decay: 8.398465655434784e-05\tLearning rate: 0.0004319610832451571\n",
      "episode: 839\tCurrent_score: 15.0\tAverage score: 13.54\tloss: 2.1705617904663086\tweighted_loss: 2.1705617904663086\teps: 0.1\tb_decay: 8.40847532475042e-05\tLearning rate: 0.00043152912216191193\n",
      "episode: 840\tCurrent_score: 15.0\tAverage score: 13.6\tloss: 4.023300647735596\tweighted_loss: 4.023300647735596\teps: 0.1\tb_decay: 8.418484993066855e-05\tLearning rate: 0.00043109759303975003\n",
      "episode: 841\tCurrent_score: 15.0\tAverage score: 13.62\tloss: 3.4139246940612793\tweighted_loss: 3.4139246940612793\teps: 0.1\tb_decay: 8.428494660372987e-05\tLearning rate: 0.0004306664954467103\n",
      "episode: 842\tCurrent_score: 7.0\tAverage score: 13.51\tloss: 1.9904354810714722\tweighted_loss: 1.9904354810714722\teps: 0.1\tb_decay: 8.438504326679919e-05\tLearning rate: 0.0004302358289512636\n",
      "episode: 843\tCurrent_score: 15.0\tAverage score: 13.57\tloss: 3.432206392288208\tweighted_loss: 3.432206392288208\teps: 0.1\tb_decay: 8.44851399198765e-05\tLearning rate: 0.00042980559312231234\n",
      "episode: 844\tCurrent_score: 8.0\tAverage score: 13.47\tloss: 3.464806079864502\tweighted_loss: 3.464806079864502\teps: 0.1\tb_decay: 8.45852365629618e-05\tLearning rate: 0.00042937578752919004\n",
      "episode: 845\tCurrent_score: 17.0\tAverage score: 13.63\tloss: 3.0830564498901367\tweighted_loss: 3.0830564498901367\teps: 0.1\tb_decay: 8.468533319594407e-05\tLearning rate: 0.0004289464117416609\n",
      "episode: 846\tCurrent_score: 15.0\tAverage score: 13.59\tloss: 3.6754167079925537\tweighted_loss: 3.6754167079925537\teps: 0.1\tb_decay: 8.478542981893433e-05\tLearning rate: 0.00042851746532991924\n",
      "episode: 847\tCurrent_score: 18.0\tAverage score: 13.61\tloss: 2.8467226028442383\tweighted_loss: 2.8467226028442383\teps: 0.1\tb_decay: 8.488552643193259e-05\tLearning rate: 0.0004280889478645893\n",
      "episode: 848\tCurrent_score: 13.0\tAverage score: 13.65\tloss: 3.789911985397339\tweighted_loss: 3.789911985397339\teps: 0.1\tb_decay: 8.498562303482782e-05\tLearning rate: 0.0004276608589167247\n",
      "episode: 849\tCurrent_score: 6.0\tAverage score: 13.58\tloss: 3.5106170177459717\tweighted_loss: 3.5106170177459717\teps: 0.1\tb_decay: 8.508571962773104e-05\tLearning rate: 0.00042723319805780795\n",
      "episode: 850\tCurrent_score: 11.0\tAverage score: 13.56\tloss: 3.488415241241455\tweighted_loss: 3.488415241241455\teps: 0.1\tb_decay: 8.518581621075327e-05\tLearning rate: 0.00042680596485975014\n",
      "episode: 851\tCurrent_score: 16.0\tAverage score: 13.58\tloss: 2.7198193073272705\tweighted_loss: 2.7198193073272705\teps: 0.1\tb_decay: 8.528591278356146e-05\tLearning rate: 0.0004263791588948904\n",
      "episode: 852\tCurrent_score: 8.0\tAverage score: 13.48\tloss: 2.8312904834747314\tweighted_loss: 2.8312904834747314\teps: 0.1\tb_decay: 8.538600934648866e-05\tLearning rate: 0.0004259527797359955\n",
      "episode: 853\tCurrent_score: 15.0\tAverage score: 13.49\tloss: 2.8745524883270264\tweighted_loss: 2.8745524883270264\teps: 0.1\tb_decay: 8.548610589931283e-05\tLearning rate: 0.0004255268269562595\n",
      "episode: 854\tCurrent_score: 18.0\tAverage score: 13.49\tloss: 3.3411917686462402\tweighted_loss: 3.3411917686462402\teps: 0.1\tb_decay: 8.558620244214499e-05\tLearning rate: 0.00042510130012930324\n",
      "episode: 855\tCurrent_score: 11.0\tAverage score: 13.49\tloss: 2.4832911491394043\tweighted_loss: 2.4832911491394043\teps: 0.1\tb_decay: 8.568629897498514e-05\tLearning rate: 0.00042467619882917396\n",
      "episode: 856\tCurrent_score: 15.0\tAverage score: 13.44\tloss: 3.243752956390381\tweighted_loss: 3.243752956390381\teps: 0.1\tb_decay: 8.578639549772227e-05\tLearning rate: 0.00042425152263034476\n",
      "episode: 857\tCurrent_score: 14.0\tAverage score: 13.46\tloss: 4.094518184661865\tweighted_loss: 4.094518184661865\teps: 0.1\tb_decay: 8.588649201057841e-05\tLearning rate: 0.0004238272711077144\n",
      "episode: 858\tCurrent_score: 14.0\tAverage score: 13.46\tloss: 4.593729496002197\tweighted_loss: 4.593729496002197\teps: 0.1\tb_decay: 8.598658851333152e-05\tLearning rate: 0.00042340344383660667\n",
      "episode: 859\tCurrent_score: 19.0\tAverage score: 13.44\tloss: 2.394735336303711\tweighted_loss: 2.394735336303711\teps: 0.1\tb_decay: 8.60866850059816e-05\tLearning rate: 0.00042298004039277007\n",
      "episode: 860\tCurrent_score: 12.0\tAverage score: 13.4\tloss: 3.1052865982055664\tweighted_loss: 3.1052865982055664\teps: 0.1\tb_decay: 8.61867814887507e-05\tLearning rate: 0.0004225570603523773\n",
      "episode: 861\tCurrent_score: 12.0\tAverage score: 13.38\tloss: 3.4506583213806152\tweighted_loss: 3.4506583213806152\teps: 0.1\tb_decay: 8.628687796141676e-05\tLearning rate: 0.0004221345032920249\n",
      "episode: 862\tCurrent_score: 13.0\tAverage score: 13.37\tloss: 3.106646776199341\tweighted_loss: 3.106646776199341\teps: 0.1\tb_decay: 8.638697442409082e-05\tLearning rate: 0.0004217123687887329\n",
      "episode: 863\tCurrent_score: 20.0\tAverage score: 13.43\tloss: 2.837939739227295\tweighted_loss: 2.837939739227295\teps: 0.1\tb_decay: 8.648707087677288e-05\tLearning rate: 0.00042129065641994417\n",
      "episode: 864\tCurrent_score: 15.0\tAverage score: 13.41\tloss: 2.416238307952881\tweighted_loss: 2.416238307952881\teps: 0.1\tb_decay: 8.65871673193519e-05\tLearning rate: 0.0004208693657635242\n",
      "episode: 865\tCurrent_score: 12.0\tAverage score: 13.37\tloss: 2.7079591751098633\tweighted_loss: 2.7079591751098633\teps: 0.1\tb_decay: 8.668726375193891e-05\tLearning rate: 0.0004204484963977607\n",
      "episode: 866\tCurrent_score: 11.0\tAverage score: 13.33\tloss: 2.1665966510772705\tweighted_loss: 2.1665966510772705\teps: 0.1\tb_decay: 8.678736017453392e-05\tLearning rate: 0.00042002804790136297\n",
      "episode: 867\tCurrent_score: 14.0\tAverage score: 13.3\tloss: 3.489968776702881\tweighted_loss: 3.489968776702881\teps: 0.1\tb_decay: 8.688745658713692e-05\tLearning rate: 0.0004196080198534616\n",
      "episode: 868\tCurrent_score: 12.0\tAverage score: 13.31\tloss: 2.56610107421875\tweighted_loss: 2.56610107421875\teps: 0.1\tb_decay: 8.698755298974792e-05\tLearning rate: 0.00041918841183360815\n",
      "episode: 869\tCurrent_score: 15.0\tAverage score: 13.33\tloss: 3.734086036682129\tweighted_loss: 3.734086036682129\teps: 0.1\tb_decay: 8.708764938225588e-05\tLearning rate: 0.00041876922342177456\n",
      "episode: 870\tCurrent_score: 13.0\tAverage score: 13.29\tloss: 3.9473023414611816\tweighted_loss: 3.9473023414611816\teps: 0.1\tb_decay: 8.718774576477184e-05\tLearning rate: 0.00041835045419835276\n",
      "episode: 871\tCurrent_score: 15.0\tAverage score: 13.31\tloss: 3.3147542476654053\tweighted_loss: 3.3147542476654053\teps: 0.1\tb_decay: 8.728784213718477e-05\tLearning rate: 0.0004179321037441544\n",
      "episode: 872\tCurrent_score: 11.0\tAverage score: 13.32\tloss: 3.4467201232910156\tweighted_loss: 3.4467201232910156\teps: 0.1\tb_decay: 8.738793849971671e-05\tLearning rate: 0.0004175141716404103\n",
      "episode: 873\tCurrent_score: 20.0\tAverage score: 13.37\tloss: 4.431700706481934\tweighted_loss: 4.431700706481934\teps: 0.1\tb_decay: 8.748803485214562e-05\tLearning rate: 0.0004170966574687699\n",
      "episode: 874\tCurrent_score: 15.0\tAverage score: 13.42\tloss: 2.055522918701172\tweighted_loss: 2.055522918701172\teps: 0.1\tb_decay: 8.758813119458253e-05\tLearning rate: 0.00041667956081130114\n",
      "episode: 875\tCurrent_score: 12.0\tAverage score: 13.4\tloss: 3.429065465927124\tweighted_loss: 3.429065465927124\teps: 0.1\tb_decay: 8.768822752702743e-05\tLearning rate: 0.0004162628812504898\n",
      "episode: 876\tCurrent_score: 11.0\tAverage score: 13.48\tloss: 4.052386283874512\tweighted_loss: 4.052386283874512\teps: 0.1\tb_decay: 8.77883238493693e-05\tLearning rate: 0.0004158466183692393\n",
      "episode: 877\tCurrent_score: 12.0\tAverage score: 13.51\tloss: 4.259335517883301\tweighted_loss: 4.259335517883301\teps: 0.1\tb_decay: 8.788842016171916e-05\tLearning rate: 0.0004154307717508701\n",
      "episode: 878\tCurrent_score: 11.0\tAverage score: 13.46\tloss: 3.4529261589050293\tweighted_loss: 3.4529261589050293\teps: 0.1\tb_decay: 8.798851646407702e-05\tLearning rate: 0.0004150153409791192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 879\tCurrent_score: 11.0\tAverage score: 13.44\tloss: 4.285551071166992\tweighted_loss: 4.285551071166992\teps: 0.1\tb_decay: 8.808861275644286e-05\tLearning rate: 0.0004146003256381401\n",
      "episode: 880\tCurrent_score: 16.0\tAverage score: 13.48\tloss: 2.7300844192504883\tweighted_loss: 2.7300844192504883\teps: 0.1\tb_decay: 8.818870903870568e-05\tLearning rate: 0.000414185725312502\n",
      "episode: 881\tCurrent_score: 12.0\tAverage score: 13.45\tloss: 4.088649272918701\tweighted_loss: 4.088649272918701\teps: 0.1\tb_decay: 8.828880531097649e-05\tLearning rate: 0.0004137715395871895\n",
      "episode: 882\tCurrent_score: 5.0\tAverage score: 13.32\tloss: 2.826686382293701\tweighted_loss: 2.826686382293701\teps: 0.1\tb_decay: 8.83889015732553e-05\tLearning rate: 0.0004133577680476023\n",
      "episode: 883\tCurrent_score: 8.0\tAverage score: 13.32\tloss: 2.343529224395752\tweighted_loss: 2.343529224395752\teps: 0.1\tb_decay: 8.848899782554209e-05\tLearning rate: 0.0004129444102795547\n",
      "episode: 884\tCurrent_score: 17.0\tAverage score: 13.37\tloss: 3.7420847415924072\tweighted_loss: 3.7420847415924072\teps: 0.1\tb_decay: 8.858909406772586e-05\tLearning rate: 0.0004125314658692751\n",
      "episode: 885\tCurrent_score: 18.0\tAverage score: 13.44\tloss: 2.8074069023132324\tweighted_loss: 2.8074069023132324\teps: 0.1\tb_decay: 8.868919030002864e-05\tLearning rate: 0.00041211893440340583\n",
      "episode: 886\tCurrent_score: 12.0\tAverage score: 13.39\tloss: 3.511876344680786\tweighted_loss: 3.511876344680786\teps: 0.1\tb_decay: 8.878928652211737e-05\tLearning rate: 0.0004117068154690024\n",
      "episode: 887\tCurrent_score: 12.0\tAverage score: 13.35\tloss: 3.696784734725952\tweighted_loss: 3.696784734725952\teps: 0.1\tb_decay: 8.888938273432512e-05\tLearning rate: 0.0004112951086535334\n",
      "episode: 888\tCurrent_score: 21.0\tAverage score: 13.43\tloss: 3.969223976135254\tweighted_loss: 3.969223976135254\teps: 0.1\tb_decay: 8.898947893642983e-05\tLearning rate: 0.00041088381354487986\n",
      "episode: 889\tCurrent_score: 13.0\tAverage score: 13.43\tloss: 2.9001007080078125\tweighted_loss: 2.9001007080078125\teps: 0.1\tb_decay: 8.908957512865356e-05\tLearning rate: 0.000410472929731335\n",
      "episode: 890\tCurrent_score: 18.0\tAverage score: 13.48\tloss: 2.624174118041992\tweighted_loss: 2.624174118041992\teps: 0.1\tb_decay: 8.918967131066324e-05\tLearning rate: 0.00041006245680160364\n",
      "episode: 891\tCurrent_score: 14.0\tAverage score: 13.45\tloss: 3.8268754482269287\tweighted_loss: 3.8268754482269287\teps: 0.1\tb_decay: 8.928976748279194e-05\tLearning rate: 0.000409652394344802\n",
      "episode: 892\tCurrent_score: 15.0\tAverage score: 13.51\tloss: 4.0707197189331055\tweighted_loss: 4.0707197189331055\teps: 0.1\tb_decay: 8.93898636448176e-05\tLearning rate: 0.0004092427419504572\n",
      "episode: 893\tCurrent_score: 12.0\tAverage score: 13.54\tloss: 2.66915225982666\tweighted_loss: 2.66915225982666\teps: 0.1\tb_decay: 8.948995979696228e-05\tLearning rate: 0.0004088334992085068\n",
      "episode: 894\tCurrent_score: 16.0\tAverage score: 13.55\tloss: 3.1799542903900146\tweighted_loss: 3.1799542903900146\teps: 0.1\tb_decay: 8.959005593889291e-05\tLearning rate: 0.0004084246657092983\n",
      "episode: 895\tCurrent_score: 12.0\tAverage score: 13.53\tloss: 2.296056032180786\tweighted_loss: 2.296056032180786\teps: 0.1\tb_decay: 8.969015207094255e-05\tLearning rate: 0.000408016241043589\n",
      "episode: 896\tCurrent_score: 22.0\tAverage score: 13.6\tloss: 4.125249862670898\tweighted_loss: 4.125249862670898\teps: 0.1\tb_decay: 8.979024819288917e-05\tLearning rate: 0.0004076082248025454\n",
      "episode: 897\tCurrent_score: 13.0\tAverage score: 13.68\tloss: 4.000980377197266\tweighted_loss: 4.000980377197266\teps: 0.1\tb_decay: 8.98903443049548e-05\tLearning rate: 0.00040720061657774283\n",
      "episode: 898\tCurrent_score: 17.0\tAverage score: 13.7\tloss: 3.0227062702178955\tweighted_loss: 3.0227062702178955\teps: 0.1\tb_decay: 8.999044040680637e-05\tLearning rate: 0.0004067934159611651\n",
      "episode: 899\tCurrent_score: 15.0\tAverage score: 13.71\tloss: 3.318305730819702\tweighted_loss: 3.318305730819702\teps: 0.1\tb_decay: 9.009053649877696e-05\tLearning rate: 0.0004063866225452039\n",
      "episode: 900\tCurrent_score: 11.0\tAverage score: 13.69\tloss: 2.669194221496582\tweighted_loss: 2.669194221496582\teps: 0.1\tb_decay: 9.019063258064453e-05\tLearning rate: 0.0004059802359226587\n",
      "episode: 901\tCurrent_score: 9.0\tAverage score: 13.65\tloss: 4.156090259552002\tweighted_loss: 4.156090259552002\teps: 0.1\tb_decay: 9.029072865252008e-05\tLearning rate: 0.000405574255686736\n",
      "episode: 902\tCurrent_score: 9.0\tAverage score: 13.61\tloss: 4.7240986824035645\tweighted_loss: 4.7240986824035645\teps: 0.1\tb_decay: 9.039082471440363e-05\tLearning rate: 0.0004051686814310493\n",
      "episode: 903\tCurrent_score: 10.0\tAverage score: 13.64\tloss: 2.7117583751678467\tweighted_loss: 2.7117583751678467\teps: 0.1\tb_decay: 9.049092076629517e-05\tLearning rate: 0.00040476351274961825\n",
      "episode: 904\tCurrent_score: 12.0\tAverage score: 13.54\tloss: 2.6217126846313477\tweighted_loss: 2.6217126846313477\teps: 0.1\tb_decay: 9.059101680808368e-05\tLearning rate: 0.0004043587492368686\n",
      "episode: 905\tCurrent_score: 9.0\tAverage score: 13.54\tloss: 2.7173566818237305\tweighted_loss: 2.7173566818237305\teps: 0.1\tb_decay: 9.069111283988018e-05\tLearning rate: 0.00040395439048763175\n",
      "episode: 906\tCurrent_score: 16.0\tAverage score: 13.59\tloss: 2.1635305881500244\tweighted_loss: 2.1635305881500244\teps: 0.1\tb_decay: 9.079120886168468e-05\tLearning rate: 0.0004035504360971441\n",
      "episode: 907\tCurrent_score: 19.0\tAverage score: 13.57\tloss: 3.841275215148926\tweighted_loss: 3.841275215148926\teps: 0.1\tb_decay: 9.089130487349717e-05\tLearning rate: 0.00040314688566104695\n",
      "episode: 908\tCurrent_score: 5.0\tAverage score: 13.51\tloss: 4.606804847717285\tweighted_loss: 4.606804847717285\teps: 0.1\tb_decay: 9.099140087520663e-05\tLearning rate: 0.0004027437387753859\n",
      "episode: 909\tCurrent_score: 12.0\tAverage score: 13.52\tloss: 3.396707773208618\tweighted_loss: 3.396707773208618\teps: 0.1\tb_decay: 9.109149686692408e-05\tLearning rate: 0.00040234099503661056\n",
      "episode: 910\tCurrent_score: 14.0\tAverage score: 13.49\tloss: 2.0263259410858154\tweighted_loss: 2.0263259410858154\teps: 0.1\tb_decay: 9.119159284864953e-05\tLearning rate: 0.00040193865404157395\n",
      "episode: 911\tCurrent_score: 21.0\tAverage score: 13.55\tloss: 2.6174492835998535\tweighted_loss: 2.6174492835998535\teps: 0.1\tb_decay: 9.129168882027194e-05\tLearning rate: 0.0004015367153875324\n",
      "episode: 912\tCurrent_score: 15.0\tAverage score: 13.54\tloss: 3.239107131958008\tweighted_loss: 3.239107131958008\teps: 0.1\tb_decay: 9.139178478201337e-05\tLearning rate: 0.00040113517867214484\n",
      "episode: 913\tCurrent_score: 14.0\tAverage score: 13.55\tloss: 2.6318352222442627\tweighted_loss: 2.6318352222442627\teps: 0.1\tb_decay: 9.149188073365178e-05\tLearning rate: 0.0004007340434934727\n",
      "episode: 914\tCurrent_score: 20.0\tAverage score: 13.6\tloss: 2.9652111530303955\tweighted_loss: 2.9652111530303955\teps: 0.1\tb_decay: 9.159197667529817e-05\tLearning rate: 0.0004003333094499792\n",
      "episode: 915\tCurrent_score: 12.0\tAverage score: 13.58\tloss: 3.7508130073547363\tweighted_loss: 3.7508130073547363\teps: 0.1\tb_decay: 9.169207260684153e-05\tLearning rate: 0.0003999329761405292\n",
      "episode: 916\tCurrent_score: 7.0\tAverage score: 13.54\tloss: 4.1143269538879395\tweighted_loss: 4.1143269538879395\teps: 0.1\tb_decay: 9.179216852839289e-05\tLearning rate: 0.0003995330431643887\n",
      "episode: 917\tCurrent_score: 14.0\tAverage score: 13.56\tloss: 3.900465250015259\tweighted_loss: 3.900465250015259\teps: 0.1\tb_decay: 9.189226443995224e-05\tLearning rate: 0.0003991335101212243\n",
      "episode: 918\tCurrent_score: 15.0\tAverage score: 13.52\tloss: 3.313493490219116\tweighted_loss: 3.313493490219116\teps: 0.1\tb_decay: 9.199236034151959e-05\tLearning rate: 0.00039873437661110307\n",
      "episode: 919\tCurrent_score: 14.0\tAverage score: 13.44\tloss: 3.4076619148254395\tweighted_loss: 3.4076619148254395\teps: 0.1\tb_decay: 9.209245623309492e-05\tLearning rate: 0.000398335642234492\n",
      "episode: 920\tCurrent_score: 9.0\tAverage score: 13.42\tloss: 3.297283172607422\tweighted_loss: 3.297283172607422\teps: 0.1\tb_decay: 9.219255211456723e-05\tLearning rate: 0.0003979373065922575\n",
      "episode: 921\tCurrent_score: 10.0\tAverage score: 13.35\tloss: 2.9366188049316406\tweighted_loss: 2.9366188049316406\teps: 0.1\tb_decay: 9.229264798604753e-05\tLearning rate: 0.00039753936928566523\n",
      "episode: 922\tCurrent_score: 9.0\tAverage score: 13.24\tloss: 3.260951042175293\tweighted_loss: 3.260951042175293\teps: 0.1\tb_decay: 9.239274384753582e-05\tLearning rate: 0.00039714182991637954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 923\tCurrent_score: 13.0\tAverage score: 13.27\tloss: 4.02705717086792\tweighted_loss: 4.02705717086792\teps: 0.1\tb_decay: 9.249283969892108e-05\tLearning rate: 0.00039674468808646317\n",
      "episode: 924\tCurrent_score: 13.0\tAverage score: 13.26\tloss: 2.4448766708374023\tweighted_loss: 2.4448766708374023\teps: 0.1\tb_decay: 9.259293554042536e-05\tLearning rate: 0.0003963479433983767\n",
      "episode: 925\tCurrent_score: 14.0\tAverage score: 13.3\tloss: 3.25958514213562\tweighted_loss: 3.25958514213562\teps: 0.1\tb_decay: 9.26930313718266e-05\tLearning rate: 0.0003959515954549783\n",
      "episode: 926\tCurrent_score: 13.0\tAverage score: 13.31\tloss: 3.2213075160980225\tweighted_loss: 3.2213075160980225\teps: 0.1\tb_decay: 9.279312719312482e-05\tLearning rate: 0.00039555564385952333\n",
      "episode: 927\tCurrent_score: 7.0\tAverage score: 13.22\tloss: 3.132502794265747\tweighted_loss: 3.132502794265747\teps: 0.1\tb_decay: 9.289322300454206e-05\tLearning rate: 0.0003951600882156638\n",
      "episode: 928\tCurrent_score: 14.0\tAverage score: 13.18\tloss: 3.2924270629882812\tweighted_loss: 3.2924270629882812\teps: 0.1\tb_decay: 9.299331880585626e-05\tLearning rate: 0.00039476492812744814\n",
      "episode: 929\tCurrent_score: 20.0\tAverage score: 13.23\tloss: 3.4068784713745117\tweighted_loss: 3.4068784713745117\teps: 0.1\tb_decay: 9.309341459717846e-05\tLearning rate: 0.0003943701631993207\n",
      "episode: 930\tCurrent_score: 19.0\tAverage score: 13.3\tloss: 2.624842882156372\tweighted_loss: 2.624842882156372\teps: 0.1\tb_decay: 9.319351037850865e-05\tLearning rate: 0.0003939757930361214\n",
      "episode: 931\tCurrent_score: 14.0\tAverage score: 13.35\tloss: 3.8024744987487793\tweighted_loss: 3.8024744987487793\teps: 0.1\tb_decay: 9.329360614973581e-05\tLearning rate: 0.00039358181724308527\n",
      "episode: 932\tCurrent_score: 11.0\tAverage score: 13.32\tloss: 3.913722038269043\tweighted_loss: 3.913722038269043\teps: 0.1\tb_decay: 9.339370191108198e-05\tLearning rate: 0.00039318823542584217\n",
      "episode: 933\tCurrent_score: 19.0\tAverage score: 13.42\tloss: 3.640258312225342\tweighted_loss: 3.640258312225342\teps: 0.1\tb_decay: 9.349379766232513e-05\tLearning rate: 0.0003927950471904163\n",
      "episode: 934\tCurrent_score: 18.0\tAverage score: 13.52\tloss: 3.197690486907959\tweighted_loss: 3.197690486907959\teps: 0.1\tb_decay: 9.359389340346524e-05\tLearning rate: 0.0003924022521432259\n",
      "episode: 935\tCurrent_score: 14.0\tAverage score: 13.55\tloss: 3.1809966564178467\tweighted_loss: 3.1809966564178467\teps: 0.1\tb_decay: 9.369398913472438e-05\tLearning rate: 0.0003920098498910827\n",
      "episode: 936\tCurrent_score: 6.0\tAverage score: 13.45\tloss: 4.365303993225098\tweighted_loss: 4.365303993225098\teps: 0.1\tb_decay: 9.379408485588048e-05\tLearning rate: 0.00039161784004119164\n",
      "episode: 937\tCurrent_score: 16.0\tAverage score: 13.48\tloss: 4.073000907897949\tweighted_loss: 4.073000907897949\teps: 0.1\tb_decay: 9.389418056704457e-05\tLearning rate: 0.00039122622220115044\n",
      "episode: 938\tCurrent_score: 16.0\tAverage score: 13.53\tloss: 3.0719308853149414\tweighted_loss: 3.0719308853149414\teps: 0.1\tb_decay: 9.399427626821666e-05\tLearning rate: 0.0003908349959789493\n",
      "episode: 939\tCurrent_score: 15.0\tAverage score: 13.53\tloss: 2.9127960205078125\tweighted_loss: 2.9127960205078125\teps: 0.1\tb_decay: 9.409437195928572e-05\tLearning rate: 0.0003904441609829703\n",
      "episode: 940\tCurrent_score: 14.0\tAverage score: 13.52\tloss: 3.7309610843658447\tweighted_loss: 3.7309610843658447\teps: 0.1\tb_decay: 9.419446764047379e-05\tLearning rate: 0.00039005371682198736\n",
      "episode: 941\tCurrent_score: 10.0\tAverage score: 13.47\tloss: 1.744474172592163\tweighted_loss: 1.744474172592163\teps: 0.1\tb_decay: 9.429456331155883e-05\tLearning rate: 0.0003896636631051654\n",
      "episode: 942\tCurrent_score: 10.0\tAverage score: 13.5\tloss: 3.1071879863739014\tweighted_loss: 3.1071879863739014\teps: 0.1\tb_decay: 9.439465897254085e-05\tLearning rate: 0.00038927399944206024\n",
      "episode: 943\tCurrent_score: 11.0\tAverage score: 13.46\tloss: 4.147949695587158\tweighted_loss: 4.147949695587158\teps: 0.1\tb_decay: 9.449475462364187e-05\tLearning rate: 0.0003888847254426182\n",
      "episode: 944\tCurrent_score: 23.0\tAverage score: 13.61\tloss: 2.439455986022949\tweighted_loss: 2.439455986022949\teps: 0.1\tb_decay: 9.459485026463987e-05\tLearning rate: 0.00038849584071717555\n",
      "episode: 945\tCurrent_score: 14.0\tAverage score: 13.58\tloss: 2.3424413204193115\tweighted_loss: 2.3424413204193115\teps: 0.1\tb_decay: 9.469494589564587e-05\tLearning rate: 0.0003881073448764584\n",
      "episode: 946\tCurrent_score: 20.0\tAverage score: 13.63\tloss: 3.4983482360839844\tweighted_loss: 3.4983482360839844\teps: 0.1\tb_decay: 9.479504151665985e-05\tLearning rate: 0.00038771923753158193\n",
      "episode: 947\tCurrent_score: 12.0\tAverage score: 13.57\tloss: 3.630810260772705\tweighted_loss: 3.630810260772705\teps: 0.1\tb_decay: 9.48951371275708e-05\tLearning rate: 0.00038733151829405035\n",
      "episode: 948\tCurrent_score: 15.0\tAverage score: 13.59\tloss: 3.6667613983154297\tweighted_loss: 3.6667613983154297\teps: 0.1\tb_decay: 9.499523272848975e-05\tLearning rate: 0.0003869441867757563\n",
      "episode: 949\tCurrent_score: 12.0\tAverage score: 13.65\tloss: 3.4241700172424316\tweighted_loss: 3.4241700172424316\teps: 0.1\tb_decay: 9.50953283194167e-05\tLearning rate: 0.0003865572425889805\n",
      "episode: 950\tCurrent_score: 14.0\tAverage score: 13.68\tloss: 3.335475206375122\tweighted_loss: 3.335475206375122\teps: 0.1\tb_decay: 9.519542390035163e-05\tLearning rate: 0.00038617068534639153\n",
      "episode: 951\tCurrent_score: 10.0\tAverage score: 13.62\tloss: 2.530216693878174\tweighted_loss: 2.530216693878174\teps: 0.1\tb_decay: 9.529551947118353e-05\tLearning rate: 0.00038578451466104514\n",
      "episode: 952\tCurrent_score: 17.0\tAverage score: 13.71\tloss: 2.508362293243408\tweighted_loss: 2.508362293243408\teps: 0.1\tb_decay: 9.539561503213445e-05\tLearning rate: 0.00038539873014638407\n",
      "episode: 953\tCurrent_score: 13.0\tAverage score: 13.69\tloss: 2.130570411682129\tweighted_loss: 2.130570411682129\teps: 0.1\tb_decay: 9.549571058287132e-05\tLearning rate: 0.0003850133314162377\n",
      "episode: 954\tCurrent_score: 16.0\tAverage score: 13.67\tloss: 2.764512538909912\tweighted_loss: 2.764512538909912\teps: 0.1\tb_decay: 9.55958061237272e-05\tLearning rate: 0.0003846283180848214\n",
      "episode: 955\tCurrent_score: 13.0\tAverage score: 13.69\tloss: 3.311018228530884\tweighted_loss: 3.311018228530884\teps: 0.1\tb_decay: 9.569590165459108e-05\tLearning rate: 0.0003842436897667366\n",
      "episode: 956\tCurrent_score: 14.0\tAverage score: 13.68\tloss: 2.860401153564453\tweighted_loss: 2.860401153564453\teps: 0.1\tb_decay: 9.579599717535192e-05\tLearning rate: 0.00038385944607696986\n",
      "episode: 957\tCurrent_score: 16.0\tAverage score: 13.7\tloss: 3.117872476577759\tweighted_loss: 3.117872476577759\teps: 0.1\tb_decay: 9.589609268612076e-05\tLearning rate: 0.0003834755866308929\n",
      "episode: 958\tCurrent_score: 19.0\tAverage score: 13.75\tloss: 2.995314836502075\tweighted_loss: 2.995314836502075\teps: 0.1\tb_decay: 9.599618818678657e-05\tLearning rate: 0.00038309211104426197\n",
      "episode: 959\tCurrent_score: 15.0\tAverage score: 13.71\tloss: 2.3356375694274902\tweighted_loss: 2.3356375694274902\teps: 0.1\tb_decay: 9.609628367757139e-05\tLearning rate: 0.0003827090189332177\n",
      "episode: 960\tCurrent_score: 15.0\tAverage score: 13.74\tloss: 4.021719455718994\tweighted_loss: 4.021719455718994\teps: 0.1\tb_decay: 9.619637915825319e-05\tLearning rate: 0.00038232630991428445\n",
      "episode: 961\tCurrent_score: 10.0\tAverage score: 13.72\tloss: 2.5314602851867676\tweighted_loss: 2.5314602851867676\teps: 0.1\tb_decay: 9.629647462894297e-05\tLearning rate: 0.00038194398360437014\n",
      "episode: 962\tCurrent_score: 13.0\tAverage score: 13.72\tloss: 3.2692580223083496\tweighted_loss: 3.2692580223083496\teps: 0.1\tb_decay: 9.639657008952973e-05\tLearning rate: 0.00038156203962076576\n",
      "episode: 963\tCurrent_score: 16.0\tAverage score: 13.68\tloss: 2.522489070892334\tweighted_loss: 2.522489070892334\teps: 0.1\tb_decay: 9.64966655402355e-05\tLearning rate: 0.000381180477581145\n",
      "episode: 964\tCurrent_score: 16.0\tAverage score: 13.69\tloss: 3.653071880340576\tweighted_loss: 3.653071880340576\teps: 0.1\tb_decay: 9.659676098083825e-05\tLearning rate: 0.00038079929710356384\n",
      "episode: 965\tCurrent_score: 10.0\tAverage score: 13.67\tloss: 2.6219289302825928\tweighted_loss: 2.6219289302825928\teps: 0.1\tb_decay: 9.669685641144898e-05\tLearning rate: 0.00038041849780646027\n",
      "episode: 966\tCurrent_score: 20.0\tAverage score: 13.76\tloss: 2.867709159851074\tweighted_loss: 2.867709159851074\teps: 0.1\tb_decay: 9.679695183206771e-05\tLearning rate: 0.0003800380793086538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 967\tCurrent_score: 17.0\tAverage score: 13.79\tloss: 2.777008295059204\tweighted_loss: 2.777008295059204\teps: 0.1\tb_decay: 9.689704724258341e-05\tLearning rate: 0.00037965804122934514\n",
      "episode: 968\tCurrent_score: 18.0\tAverage score: 13.85\tloss: 2.3057565689086914\tweighted_loss: 2.3057565689086914\teps: 0.1\tb_decay: 9.69971426431071e-05\tLearning rate: 0.00037927838318811577\n",
      "episode: 969\tCurrent_score: 12.0\tAverage score: 13.82\tloss: 3.424884796142578\tweighted_loss: 3.424884796142578\teps: 0.1\tb_decay: 9.709723803363879e-05\tLearning rate: 0.00037889910480492763\n",
      "episode: 970\tCurrent_score: 16.0\tAverage score: 13.85\tloss: 3.086703300476074\tweighted_loss: 3.086703300476074\teps: 0.1\tb_decay: 9.719733341417847e-05\tLearning rate: 0.0003785202057001227\n",
      "episode: 971\tCurrent_score: 12.0\tAverage score: 13.82\tloss: 3.3801748752593994\tweighted_loss: 3.3801748752593994\teps: 0.1\tb_decay: 9.729742878461511e-05\tLearning rate: 0.0003781416854944226\n",
      "episode: 972\tCurrent_score: 19.0\tAverage score: 13.9\tloss: 3.6043829917907715\tweighted_loss: 3.6043829917907715\teps: 0.1\tb_decay: 9.739752414505976e-05\tLearning rate: 0.00037776354380892815\n",
      "episode: 973\tCurrent_score: 18.0\tAverage score: 13.88\tloss: 3.6155452728271484\tweighted_loss: 3.6155452728271484\teps: 0.1\tb_decay: 9.749761949551239e-05\tLearning rate: 0.0003773857802651192\n",
      "episode: 974\tCurrent_score: 19.0\tAverage score: 13.92\tloss: 2.8755884170532227\tweighted_loss: 2.8755884170532227\teps: 0.1\tb_decay: 9.759771483597302e-05\tLearning rate: 0.0003770083944848541\n",
      "episode: 975\tCurrent_score: 8.0\tAverage score: 13.88\tloss: 4.065011978149414\tweighted_loss: 4.065011978149414\teps: 0.1\tb_decay: 9.769781016633061e-05\tLearning rate: 0.00037663138609036925\n",
      "episode: 976\tCurrent_score: 14.0\tAverage score: 13.91\tloss: 4.19251012802124\tweighted_loss: 4.19251012802124\teps: 0.1\tb_decay: 9.77979054866962e-05\tLearning rate: 0.00037625475470427885\n",
      "episode: 977\tCurrent_score: 12.0\tAverage score: 13.91\tloss: 4.253173351287842\tweighted_loss: 4.253173351287842\teps: 0.1\tb_decay: 9.789800079706978e-05\tLearning rate: 0.0003758784999495746\n",
      "episode: 978\tCurrent_score: 12.0\tAverage score: 13.92\tloss: 3.6351242065429688\tweighted_loss: 3.6351242065429688\teps: 0.1\tb_decay: 9.799809609745136e-05\tLearning rate: 0.000375502621449625\n",
      "episode: 979\tCurrent_score: 15.0\tAverage score: 13.96\tloss: 3.818532705307007\tweighted_loss: 3.818532705307007\teps: 0.1\tb_decay: 9.80981913877299e-05\tLearning rate: 0.0003751271188281754\n",
      "episode: 980\tCurrent_score: 12.0\tAverage score: 13.92\tloss: 3.1729040145874023\tweighted_loss: 3.1729040145874023\teps: 0.1\tb_decay: 9.819828666801644e-05\tLearning rate: 0.00037475199170934723\n",
      "episode: 981\tCurrent_score: 10.0\tAverage score: 13.9\tloss: 2.9228014945983887\tweighted_loss: 2.9228014945983887\teps: 0.1\tb_decay: 9.829838193831097e-05\tLearning rate: 0.0003743772397176379\n",
      "episode: 982\tCurrent_score: 12.0\tAverage score: 13.97\tloss: 3.013141393661499\tweighted_loss: 3.013141393661499\teps: 0.1\tb_decay: 9.83984771986135e-05\tLearning rate: 0.00037400286247792026\n",
      "episode: 983\tCurrent_score: 13.0\tAverage score: 14.02\tloss: 4.857588291168213\tweighted_loss: 4.857588291168213\teps: 0.1\tb_decay: 9.8498572448813e-05\tLearning rate: 0.00037362885961544234\n",
      "episode: 984\tCurrent_score: 15.0\tAverage score: 14.0\tloss: 2.3982534408569336\tweighted_loss: 2.3982534408569336\teps: 0.1\tb_decay: 9.859866768902048e-05\tLearning rate: 0.0003732552307558269\n",
      "episode: 985\tCurrent_score: 15.0\tAverage score: 13.97\tloss: 2.9644734859466553\tweighted_loss: 2.9644734859466553\teps: 0.1\tb_decay: 9.869876291923596e-05\tLearning rate: 0.0003728819755250711\n",
      "episode: 986\tCurrent_score: 13.0\tAverage score: 13.98\tloss: 3.171096086502075\tweighted_loss: 3.171096086502075\teps: 0.1\tb_decay: 9.879885813945943e-05\tLearning rate: 0.000372509093549546\n",
      "episode: 987\tCurrent_score: 16.0\tAverage score: 14.02\tloss: 2.0695347785949707\tweighted_loss: 2.0695347785949707\teps: 0.1\tb_decay: 9.889895334957988e-05\tLearning rate: 0.0003721365844559965\n",
      "episode: 988\tCurrent_score: 16.0\tAverage score: 13.97\tloss: 3.1077187061309814\tweighted_loss: 3.1077187061309814\teps: 0.1\tb_decay: 9.899904854970831e-05\tLearning rate: 0.0003717644478715405\n",
      "episode: 989\tCurrent_score: 22.0\tAverage score: 14.06\tloss: 3.3490278720855713\tweighted_loss: 3.3490278720855713\teps: 0.1\tb_decay: 9.909914373984474e-05\tLearning rate: 0.00037139268342366896\n",
      "episode: 990\tCurrent_score: 10.0\tAverage score: 13.98\tloss: 3.2993340492248535\tweighted_loss: 3.2993340492248535\teps: 0.1\tb_decay: 9.919923891987814e-05\tLearning rate: 0.00037102129074024527\n",
      "episode: 991\tCurrent_score: 16.0\tAverage score: 14.0\tloss: 3.7668697834014893\tweighted_loss: 3.7668697834014893\teps: 0.1\tb_decay: 9.929933409003056e-05\tLearning rate: 0.000370650269449505\n",
      "episode: 992\tCurrent_score: 10.0\tAverage score: 13.95\tloss: 2.9698312282562256\tweighted_loss: 2.9698312282562256\teps: 0.1\tb_decay: 9.939942925007994e-05\tLearning rate: 0.0003702796191800555\n",
      "episode: 993\tCurrent_score: 14.0\tAverage score: 13.97\tloss: 3.6955325603485107\tweighted_loss: 3.6955325603485107\teps: 0.1\tb_decay: 9.949952440013732e-05\tLearning rate: 0.00036990933956087543\n",
      "episode: 994\tCurrent_score: 10.0\tAverage score: 13.91\tloss: 2.656686782836914\tweighted_loss: 2.656686782836914\teps: 0.1\tb_decay: 9.959961954009167e-05\tLearning rate: 0.0003695394302213146\n",
      "episode: 995\tCurrent_score: 17.0\tAverage score: 13.96\tloss: 2.561917304992676\tweighted_loss: 2.561917304992676\teps: 0.1\tb_decay: 9.969971467016503e-05\tLearning rate: 0.00036916989079109326\n",
      "episode: 996\tCurrent_score: 19.0\tAverage score: 13.93\tloss: 4.5477190017700195\tweighted_loss: 4.5477190017700195\teps: 0.1\tb_decay: 9.979980979013536e-05\tLearning rate: 0.00036880072090030215\n",
      "episode: 997\tCurrent_score: 13.0\tAverage score: 13.93\tloss: 4.362190246582031\tweighted_loss: 4.362190246582031\teps: 0.1\tb_decay: 9.989990490000267e-05\tLearning rate: 0.00036843192017940187\n",
      "episode: 998\tCurrent_score: 22.0\tAverage score: 13.98\tloss: 2.9576103687286377\tweighted_loss: 2.9576103687286377\teps: 0.1\tb_decay: 9.999999999998899e-05\tLearning rate: 0.00036806348825922246\n",
      "episode: 999\tCurrent_score: 14.0\tAverage score: 13.97\tloss: 2.9279770851135254\tweighted_loss: 2.9279770851135254\teps: 0.1\tb_decay: 0.00010010009508987228\tLearning rate: 0.0003676954247709632\n",
      "saving the network!\n",
      "The newtork has been saved!\n",
      "Check the checkpoints folder!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(NR_EPISODES):\n",
    "    \n",
    "    #-------------------- #\n",
    "    # Start a new episode #\n",
    "    #---------------------#\n",
    "    env_info = env.reset(train_mode=True)[brain_name] # get a new starting position\n",
    "    agent.new_episode()                               # inform the agent that we start a new episode\n",
    "    score_episode = 0                                 # set the score of this episode to 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        #---------------------------------------#\n",
    "        # Get the a state and perform an action #\n",
    "        #---------------------------------------#\n",
    "        state = env_info.vector_observations[0]        # get the current state\n",
    "        action = agent.act(state)                      # select an action from the agent\n",
    "        env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "        \n",
    "        \n",
    "        #-------------------------------------------#\n",
    "        # Unpack the new info after perf. an action #\n",
    "        #-------------------------------------------#\n",
    "        next_state = env_info.vector_observations[0]   # get the next state\n",
    "        reward = env_info.rewards[0]                   # get the reward\n",
    "        done = env_info.local_done[0]                  # see if episode has finished\n",
    "        \n",
    "        \n",
    "        #-----------------------------------------#\n",
    "        # store the step & learn if time is ready #\n",
    "        #-----------------------------------------#\n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "        \n",
    "        #------------------------------#\n",
    "        # update the state and rewards #\n",
    "        #------------------------------#\n",
    "        score_episode += reward                        # update the score with the rewards\n",
    "        state = next_state                             # update the state\n",
    "        \n",
    "        #------------------------------#\n",
    "        # Check if the episode is done #\n",
    "        #------------------------------#\n",
    "        if done:                                       # exit loop if episode finished\n",
    "            break\n",
    "\n",
    "    #-------------------#\n",
    "    # Update the scores #\n",
    "    #-------------------#\n",
    "    \n",
    "    # store the scores of the rolling window\n",
    "    score_window.append(score_episode)\n",
    "    \n",
    "    # store the average score of the rolling window\n",
    "    score.append(np.around(np.mean(score_window),3))      \n",
    "    \n",
    "    log = f\"episode: {i}\\tCurrent_score: {score_episode}\\tAverage score: {score[-1]}\\tloss: {agent.get_last_loss()}\\tweighted_loss: {agent.get_last_weighted_loss()}\\teps: {agent.get_epsilon()}\\tb_decay: {agent.get_b_decay()}\\tLearning rate: {agent.optimizer.param_groups[0]['lr']}\"\n",
    "    \n",
    "    print(log)\n",
    "    with open(agent_log_file, 'a') as file:\n",
    "        file.write(f'{log}\\n')\n",
    "        \n",
    "else:\n",
    "    agent.save_model_checkpoints()\n",
    "    copyfile(agent_log_file, agent_results_log_file)\n",
    "    pd.DataFrame(score, columns=[\"score\"]).to_csv(agent_results_file,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe8bba071d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe8bba5ab00>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(score, columns=[\"score\"])\n",
    "df['episode'] = df.index\n",
    "ax = df.plot(x ='episode', y='score', kind = 'scatter', style='g', linewidth=1.0, figsize=(16,10))\n",
    "ax.axhline(13, color='r')\n",
    "df.plot.line(x ='episode', y='score', ax=ax, style=':g', linewidth=1.0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
